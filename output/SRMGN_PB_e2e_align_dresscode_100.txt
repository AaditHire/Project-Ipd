/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023.04.09-11:05:55:100:[step-100/34000: 0.29%]--[loss-2.452618: wl-2.076169, gl-1.414533]--[lr-0.000050]--[ETA-8:49:29]
2023.04.09-11:07:31:200:[step-200/34000: 0.59%]--[loss-2.112397: wl-1.996042, gl-1.114376]--[lr-0.000050]--[ETA-9:00:35]
2023.04.09-11:09:08:300:[step-300/34000: 0.88%]--[loss-2.305079: wl-2.307614, gl-1.151272]--[lr-0.000050]--[ETA-8:55:21]
End of epoch 1 / 100: train_loss: 2.420 	 time: 339 sec
2023.04.09-11:10:55:60:[step-400/34000: 1.18%]--[loss-1.987493: wl-2.091768, gl-0.941609]--[lr-0.000050]--[ETA-9:16:55]
2023.04.09-11:12:32:160:[step-500/34000: 1.47%]--[loss-2.170752: wl-2.181472, gl-1.080016]--[lr-0.000050]--[ETA-8:52:34]
2023.04.09-11:14:10:260:[step-600/34000: 1.76%]--[loss-2.023448: wl-2.112195, gl-0.967351]--[lr-0.000050]--[ETA-8:54:18]
End of epoch 2 / 100: train_loss: 2.056 	 time: 340 sec
2023.04.09-11:16:09:20:[step-700/34000: 2.06%]--[loss-2.158046: wl-2.259251, gl-1.028420]--[lr-0.000050]--[ETA-8:53:18]
2023.04.09-11:17:47:120:[step-800/34000: 2.35%]--[loss-1.912827: wl-2.054655, gl-0.885500]--[lr-0.000050]--[ETA-9:00:42]
2023.04.09-11:19:24:220:[step-900/34000: 2.65%]--[loss-1.919958: wl-2.138386, gl-0.850765]--[lr-0.000050]--[ETA-9:07:24]
2023.04.09-11:21:01:320:[step-1000/34000: 2.94%]--[loss-1.990883: wl-2.092916, gl-0.944425]--[lr-0.000050]--[ETA-8:41:25]
End of epoch 3 / 100: train_loss: 1.982 	 time: 355 sec
2023.04.09-11:23:07:80:[step-1100/34000: 3.24%]--[loss-1.766056: wl-2.102803, gl-0.714655]--[lr-0.000050]--[ETA-8:56:17]
2023.04.09-11:24:48:180:[step-1200/34000: 3.53%]--[loss-1.766117: wl-2.007994, gl-0.762120]--[lr-0.000050]--[ETA-9:17:27]
2023.04.09-11:26:27:280:[step-1300/34000: 3.82%]--[loss-1.831615: wl-2.034436, gl-0.814397]--[lr-0.000050]--[ETA-8:41:36]
End of epoch 4 / 100: train_loss: 1.936 	 time: 365 sec
2023.04.09-11:28:39:40:[step-1400/34000: 4.12%]--[loss-2.037586: wl-2.347423, gl-0.863875]--[lr-0.000050]--[ETA-9:21:45]
2023.04.09-11:30:19:140:[step-1500/34000: 4.41%]--[loss-1.744351: wl-2.020321, gl-0.734190]--[lr-0.000050]--[ETA-8:50:05]
2023.04.09-11:31:57:240:[step-1600/34000: 4.71%]--[loss-2.105283: wl-2.102268, gl-1.054149]--[lr-0.000050]--[ETA-8:44:01]
2023.04.09-11:33:34:340:[step-1700/34000: 5.00%]--[loss-2.154646: wl-2.148585, gl-1.080353]--[lr-0.000050]--[ETA-2:35:41]
End of epoch 5 / 100: train_loss: 1.901 	 time: 369 sec
Saving the model at the end of epoch 5, iters 1700
2023.04.09-11:35:54:100:[step-1800/34000: 5.29%]--[loss-2.019037: wl-2.212149, gl-0.912962]--[lr-0.000050]--[ETA-8:51:05]
2023.04.09-11:37:34:200:[step-1900/34000: 5.59%]--[loss-1.880721: wl-2.312681, gl-0.724380]--[lr-0.000050]--[ETA-9:30:20]
2023.04.09-11:39:15:300:[step-2000/34000: 5.88%]--[loss-1.994046: wl-2.168722, gl-0.909685]--[lr-0.000050]--[ETA-8:54:03]
End of epoch 6 / 100: train_loss: 1.865 	 time: 381 sec
2023.04.09-11:41:34:60:[step-2100/34000: 6.18%]--[loss-1.855069: wl-2.081661, gl-0.814238]--[lr-0.000050]--[ETA-8:39:23]
2023.04.09-11:43:14:160:[step-2200/34000: 6.47%]--[loss-1.941166: wl-2.391419, gl-0.745457]--[lr-0.000050]--[ETA-8:42:57]
2023.04.09-11:44:54:260:[step-2300/34000: 6.76%]--[loss-1.799135: wl-2.156045, gl-0.721113]--[lr-0.000050]--[ETA-8:40:12]
End of epoch 7 / 100: train_loss: 1.843 	 time: 376 sec
2023.04.09-11:47:16:20:[step-2400/34000: 7.06%]--[loss-1.751784: wl-2.122765, gl-0.690401]--[lr-0.000050]--[ETA-8:42:50]
2023.04.09-11:48:58:120:[step-2500/34000: 7.35%]--[loss-1.814819: wl-2.144175, gl-0.742732]--[lr-0.000050]--[ETA-9:00:58]
2023.04.09-11:50:39:220:[step-2600/34000: 7.65%]--[loss-1.953826: wl-2.320526, gl-0.793563]--[lr-0.000050]--[ETA-8:42:21]
2023.04.09-11:52:19:320:[step-2700/34000: 7.94%]--[loss-1.716727: wl-2.075130, gl-0.679162]--[lr-0.000050]--[ETA-8:33:52]
End of epoch 8 / 100: train_loss: 1.822 	 time: 388 sec
2023.04.09-11:54:39:80:[step-2800/34000: 8.24%]--[loss-1.837628: wl-2.274637, gl-0.700310]--[lr-0.000050]--[ETA-8:27:38]
2023.04.09-11:56:19:180:[step-2900/34000: 8.53%]--[loss-1.783879: wl-2.177155, gl-0.695301]--[lr-0.000050]--[ETA-8:34:49]
2023.04.09-11:57:58:280:[step-3000/34000: 8.82%]--[loss-1.805092: wl-2.146991, gl-0.731597]--[lr-0.000050]--[ETA-8:28:42]
End of epoch 9 / 100: train_loss: 1.806 	 time: 376 sec
2023.04.09-12:00:16:40:[step-3100/34000: 9.12%]--[loss-1.771845: wl-2.162623, gl-0.690534]--[lr-0.000050]--[ETA-9:04:47]
2023.04.09-12:01:59:140:[step-3200/34000: 9.41%]--[loss-1.798084: wl-2.170861, gl-0.712653]--[lr-0.000050]--[ETA-8:15:01]
2023.04.09-12:03:39:240:[step-3300/34000: 9.71%]--[loss-1.873361: wl-2.207636, gl-0.769543]--[lr-0.000050]--[ETA-8:36:00]
2023.04.09-12:05:16:340:[step-3400/34000: 10.00%]--[loss-1.598499: wl-2.004442, gl-0.596278]--[lr-0.000050]--[ETA-2:22:04]
End of epoch 10 / 100: train_loss: 1.784 	 time: 381 sec
Saving the model at the end of epoch 10, iters 3400
2023.04.09-12:07:42:100:[step-3500/34000: 10.29%]--[loss-1.990833: wl-2.258769, gl-0.861449]--[lr-0.000050]--[ETA-8:12:20]
2023.04.09-12:09:21:200:[step-3600/34000: 10.59%]--[loss-1.693035: wl-2.017316, gl-0.684377]--[lr-0.000050]--[ETA-8:44:48]
2023.04.09-12:11:01:300:[step-3700/34000: 10.88%]--[loss-1.690178: wl-2.094513, gl-0.642922]--[lr-0.000050]--[ETA-8:25:02]
End of epoch 11 / 100: train_loss: 1.776 	 time: 380 sec
2023.04.09-12:13:21:60:[step-3800/34000: 11.18%]--[loss-1.929157: wl-2.198709, gl-0.829802]--[lr-0.000050]--[ETA-8:18:08]
2023.04.09-12:15:03:160:[step-3900/34000: 11.47%]--[loss-1.640742: wl-2.026201, gl-0.627641]--[lr-0.000050]--[ETA-8:25:22]
2023.04.09-12:16:44:260:[step-4000/34000: 11.76%]--[loss-1.768868: wl-2.164657, gl-0.686539]--[lr-0.000050]--[ETA-8:15:30]
End of epoch 12 / 100: train_loss: 1.755 	 time: 385 sec
2023.04.09-12:19:05:20:[step-4100/34000: 12.06%]--[loss-1.698865: wl-2.128785, gl-0.634472]--[lr-0.000050]--[ETA-8:33:53]
2023.04.09-12:20:45:120:[step-4200/34000: 12.35%]--[loss-1.858013: wl-2.166973, gl-0.774526]--[lr-0.000050]--[ETA-8:29:59]
2023.04.09-12:22:26:220:[step-4300/34000: 12.65%]--[loss-1.692252: wl-2.111202, gl-0.636651]--[lr-0.000050]--[ETA-8:11:37]
2023.04.09-12:24:04:320:[step-4400/34000: 12.94%]--[loss-1.850157: wl-2.273545, gl-0.713385]--[lr-0.000050]--[ETA-7:44:58]
End of epoch 13 / 100: train_loss: 1.747 	 time: 378 sec
2023.04.09-12:26:30:80:[step-4500/34000: 13.24%]--[loss-1.898410: wl-2.188298, gl-0.804261]--[lr-0.000050]--[ETA-8:05:59]
2023.04.09-12:28:12:180:[step-4600/34000: 13.53%]--[loss-1.725100: wl-2.087827, gl-0.681186]--[lr-0.000050]--[ETA-7:57:12]
2023.04.09-12:29:52:280:[step-4700/34000: 13.82%]--[loss-1.802720: wl-2.309500, gl-0.647970]--[lr-0.000050]--[ETA-8:11:29]
End of epoch 14 / 100: train_loss: 1.733 	 time: 388 sec
2023.04.09-12:32:10:40:[step-4800/34000: 14.12%]--[loss-1.724464: wl-2.112211, gl-0.668359]--[lr-0.000050]--[ETA-8:00:38]
2023.04.09-12:33:51:140:[step-4900/34000: 14.41%]--[loss-1.786316: wl-2.122173, gl-0.725230]--[lr-0.000050]--[ETA-7:54:59]
2023.04.09-12:35:31:240:[step-5000/34000: 14.71%]--[loss-1.661767: wl-1.993739, gl-0.664898]--[lr-0.000050]--[ETA-7:47:23]
2023.04.09-12:37:08:340:[step-5100/34000: 15.00%]--[loss-1.905265: wl-2.102032, gl-0.854249]--[lr-0.000050]--[ETA-2:41:15]
End of epoch 15 / 100: train_loss: 1.729 	 time: 377 sec
Saving the model at the end of epoch 15, iters 5100
2023.04.09-12:39:36:100:[step-5200/34000: 15.29%]--[loss-1.658602: wl-2.063261, gl-0.626971]--[lr-0.000050]--[ETA-8:21:32]
2023.04.09-12:41:17:200:[step-5300/34000: 15.59%]--[loss-1.629864: wl-2.046691, gl-0.606518]--[lr-0.000050]--[ETA-8:20:49]
2023.04.09-12:42:57:300:[step-5400/34000: 15.88%]--[loss-1.816081: wl-2.219860, gl-0.706152]--[lr-0.000050]--[ETA-7:58:46]
End of epoch 16 / 100: train_loss: 1.713 	 time: 387 sec
2023.04.09-12:45:21:60:[step-5500/34000: 16.18%]--[loss-1.644408: wl-2.104143, gl-0.592337]--[lr-0.000050]--[ETA-7:34:04]
2023.04.09-12:47:00:160:[step-5600/34000: 16.47%]--[loss-1.578204: wl-2.087615, gl-0.534397]--[lr-0.000050]--[ETA-7:45:34]
2023.04.09-12:48:39:260:[step-5700/34000: 16.76%]--[loss-1.696640: wl-2.087650, gl-0.652815]--[lr-0.000050]--[ETA-7:42:43]
End of epoch 17 / 100: train_loss: 1.713 	 time: 379 sec
2023.04.09-12:50:56:20:[step-5800/34000: 17.06%]--[loss-1.697551: wl-2.104344, gl-0.645379]--[lr-0.000050]--[ETA-7:37:46]
2023.04.09-12:52:39:120:[step-5900/34000: 17.35%]--[loss-1.590756: wl-2.099453, gl-0.541029]--[lr-0.000050]--[ETA-8:04:25]
2023.04.09-12:54:20:220:[step-6000/34000: 17.65%]--[loss-1.583940: wl-2.079863, gl-0.544009]--[lr-0.000050]--[ETA-7:43:28]
2023.04.09-12:55:59:320:[step-6100/34000: 17.94%]--[loss-1.596437: wl-2.107988, gl-0.542443]--[lr-0.000050]--[ETA-7:30:23]
End of epoch 18 / 100: train_loss: 1.689 	 time: 382 sec
2023.04.09-12:58:20:80:[step-6200/34000: 18.24%]--[loss-1.719441: wl-2.176746, gl-0.631068]--[lr-0.000050]--[ETA-7:54:25]
2023.04.09-13:00:01:180:[step-6300/34000: 18.53%]--[loss-1.593311: wl-2.035602, gl-0.575509]--[lr-0.000050]--[ETA-7:51:22]
2023.04.09-13:01:41:280:[step-6400/34000: 18.82%]--[loss-1.660385: wl-2.198621, gl-0.561074]--[lr-0.000050]--[ETA-7:50:03]
End of epoch 19 / 100: train_loss: 1.674 	 time: 379 sec
2023.04.09-13:04:05:40:[step-6500/34000: 19.12%]--[loss-1.707658: wl-2.201208, gl-0.607054]--[lr-0.000050]--[ETA-7:54:15]
2023.04.09-13:05:47:140:[step-6600/34000: 19.41%]--[loss-1.611974: wl-2.085275, gl-0.569336]--[lr-0.000050]--[ETA-7:58:14]
2023.04.09-13:07:27:240:[step-6700/34000: 19.71%]--[loss-1.704439: wl-2.222327, gl-0.593276]--[lr-0.000050]--[ETA-7:57:44]
2023.04.09-13:09:05:340:[step-6800/34000: 20.00%]--[loss-1.584342: wl-1.970890, gl-0.598896]--[lr-0.000050]--[ETA-2:06:51]
End of epoch 20 / 100: train_loss: 1.664 	 time: 387 sec
Saving the model at the end of epoch 20, iters 6800
2023.04.09-13:11:27:100:[step-6900/34000: 20.29%]--[loss-1.720762: wl-2.120976, gl-0.660274]--[lr-0.000050]--[ETA-7:25:34]
2023.04.09-13:13:06:200:[step-7000/34000: 20.59%]--[loss-1.702518: wl-2.148069, gl-0.628484]--[lr-0.000050]--[ETA-7:29:05]
2023.04.09-13:14:45:300:[step-7100/34000: 20.88%]--[loss-1.781229: wl-2.225840, gl-0.668310]--[lr-0.000050]--[ETA-7:26:46]
End of epoch 21 / 100: train_loss: 1.663 	 time: 376 sec
2023.04.09-13:17:09:60:[step-7200/34000: 21.18%]--[loss-1.672023: wl-2.128830, gl-0.607608]--[lr-0.000050]--[ETA-7:36:09]
2023.04.09-13:18:50:160:[step-7300/34000: 21.47%]--[loss-1.681639: wl-2.083068, gl-0.640105]--[lr-0.000050]--[ETA-7:17:59]
2023.04.09-13:20:31:260:[step-7400/34000: 21.76%]--[loss-1.679823: wl-2.155123, gl-0.602261]--[lr-0.000050]--[ETA-7:29:31]
End of epoch 22 / 100: train_loss: 1.665 	 time: 387 sec
2023.04.09-13:22:55:20:[step-7500/34000: 22.06%]--[loss-1.726052: wl-2.164302, gl-0.643901]--[lr-0.000050]--[ETA-7:31:49]
2023.04.09-13:24:35:120:[step-7600/34000: 22.35%]--[loss-1.671638: wl-2.138173, gl-0.602552]--[lr-0.000050]--[ETA-7:26:19]
2023.04.09-13:26:14:220:[step-7700/34000: 22.65%]--[loss-1.669195: wl-2.155405, gl-0.591493]--[lr-0.000050]--[ETA-7:10:10]
2023.04.09-13:27:53:320:[step-7800/34000: 22.94%]--[loss-1.687332: wl-2.128341, gl-0.623162]--[lr-0.000050]--[ETA-6:54:16]
End of epoch 23 / 100: train_loss: 1.652 	 time: 380 sec
2023.04.09-13:30:19:80:[step-7900/34000: 23.24%]--[loss-1.731239: wl-2.213921, gl-0.624279]--[lr-0.000050]--[ETA-7:11:38]
2023.04.09-13:32:01:180:[step-8000/34000: 23.53%]--[loss-1.590115: wl-2.061663, gl-0.559283]--[lr-0.000050]--[ETA-7:26:29]
2023.04.09-13:33:41:280:[step-8100/34000: 23.82%]--[loss-1.552576: wl-2.007673, gl-0.548740]--[lr-0.000050]--[ETA-7:01:25]
End of epoch 24 / 100: train_loss: 1.642 	 time: 388 sec
2023.04.09-13:35:59:40:[step-8200/34000: 24.12%]--[loss-1.582042: wl-2.076045, gl-0.544020]--[lr-0.000050]--[ETA-7:13:40]
2023.04.09-13:37:41:140:[step-8300/34000: 24.41%]--[loss-1.571606: wl-2.103438, gl-0.519888]--[lr-0.000050]--[ETA-7:29:04]
2023.04.09-13:39:19:240:[step-8400/34000: 24.71%]--[loss-1.552468: wl-2.015240, gl-0.544848]--[lr-0.000050]--[ETA-6:57:06]
2023.04.09-13:40:56:340:[step-8500/34000: 25.00%]--[loss-2.393645: wl-1.929403, gl-1.428944]--[lr-0.000050]--[ETA-1:52:27]
End of epoch 25 / 100: train_loss: 1.634 	 time: 376 sec
Saving the model at the end of epoch 25, iters 8500
2023.04.09-13:43:23:100:[step-8600/34000: 25.29%]--[loss-1.671340: wl-2.204372, gl-0.569154]--[lr-0.000050]--[ETA-7:01:58]
2023.04.09-13:45:05:200:[step-8700/34000: 25.59%]--[loss-1.632843: wl-2.214351, gl-0.525667]--[lr-0.000050]--[ETA-7:16:55]
2023.04.09-13:46:45:300:[step-8800/34000: 25.88%]--[loss-1.656792: wl-2.088516, gl-0.612534]--[lr-0.000050]--[ETA-6:56:56]
End of epoch 26 / 100: train_loss: 1.625 	 time: 386 sec
2023.04.09-13:49:04:60:[step-8900/34000: 26.18%]--[loss-1.606074: wl-2.143318, gl-0.534415]--[lr-0.000050]--[ETA-6:55:45]
2023.04.09-13:50:44:160:[step-9000/34000: 26.47%]--[loss-1.727849: wl-2.264742, gl-0.595478]--[lr-0.000050]--[ETA-6:50:34]
2023.04.09-13:52:23:260:[step-9100/34000: 26.76%]--[loss-1.601400: wl-2.064176, gl-0.569312]--[lr-0.000050]--[ETA-6:57:26]
End of epoch 27 / 100: train_loss: 1.620 	 time: 376 sec
2023.04.09-13:54:46:20:[step-9200/34000: 27.06%]--[loss-1.646136: wl-2.105045, gl-0.593614]--[lr-0.000050]--[ETA-7:00:58]
2023.04.09-13:56:26:120:[step-9300/34000: 27.35%]--[loss-1.644656: wl-2.110292, gl-0.589510]--[lr-0.000050]--[ETA-7:02:34]
2023.04.09-13:58:07:220:[step-9400/34000: 27.65%]--[loss-1.551276: wl-2.028345, gl-0.537103]--[lr-0.000050]--[ETA-6:33:32]
2023.04.09-13:59:47:320:[step-9500/34000: 27.94%]--[loss-1.636594: wl-2.176641, gl-0.548273]--[lr-0.000050]--[ETA-6:21:35]
End of epoch 28 / 100: train_loss: 1.619 	 time: 385 sec
2023.04.09-14:02:10:80:[step-9600/34000: 28.24%]--[loss-1.619780: wl-2.112612, gl-0.563474]--[lr-0.000050]--[ETA-6:42:47]
2023.04.09-14:03:50:180:[step-9700/34000: 28.53%]--[loss-1.510560: wl-2.043998, gl-0.488561]--[lr-0.000050]--[ETA-6:34:43]
2023.04.09-14:05:28:280:[step-9800/34000: 28.82%]--[loss-1.539052: wl-2.058795, gl-0.509654]--[lr-0.000050]--[ETA-6:29:43]
End of epoch 29 / 100: train_loss: 1.608 	 time: 379 sec
2023.04.09-14:07:50:40:[step-9900/34000: 29.12%]--[loss-1.644712: wl-2.059145, gl-0.615140]--[lr-0.000050]--[ETA-6:46:50]
2023.04.09-14:09:31:140:[step-10000/34000: 29.41%]--[loss-1.686191: wl-2.253260, gl-0.559561]--[lr-0.000050]--[ETA-6:40:07]
2023.04.09-14:11:13:240:[step-10100/34000: 29.71%]--[loss-1.762259: wl-2.334415, gl-0.595052]--[lr-0.000050]--[ETA-6:33:27]
2023.04.09-14:12:51:340:[step-10200/34000: 30.00%]--[loss-1.673187: wl-2.185324, gl-0.580525]--[lr-0.000050]--[ETA-1:43:33]
End of epoch 30 / 100: train_loss: 1.599 	 time: 385 sec
Saving the model at the end of epoch 30, iters 10200
2023.04.09-14:15:12:100:[step-10300/34000: 30.29%]--[loss-1.591009: wl-2.141156, gl-0.520431]--[lr-0.000050]--[ETA-6:27:55]
2023.04.09-14:16:52:200:[step-10400/34000: 30.59%]--[loss-1.509014: wl-1.983446, gl-0.517291]--[lr-0.000050]--[ETA-6:36:28]
2023.04.09-14:18:31:300:[step-10500/34000: 30.88%]--[loss-1.598080: wl-2.112410, gl-0.541875]--[lr-0.000050]--[ETA-6:24:13]
End of epoch 31 / 100: train_loss: 1.596 	 time: 376 sec
2023.04.09-14:20:53:60:[step-10600/34000: 31.18%]--[loss-1.634628: wl-2.129789, gl-0.569733]--[lr-0.000050]--[ETA-6:32:44]
2023.04.09-14:22:34:160:[step-10700/34000: 31.47%]--[loss-1.551959: wl-2.131476, gl-0.486221]--[lr-0.000050]--[ETA-6:37:44]
2023.04.09-14:24:14:260:[step-10800/34000: 31.76%]--[loss-1.597986: wl-2.044436, gl-0.575768]--[lr-0.000050]--[ETA-6:26:11]
End of epoch 32 / 100: train_loss: 1.590 	 time: 385 sec
2023.04.09-14:26:33:20:[step-10900/34000: 32.06%]--[loss-1.612432: wl-2.208238, gl-0.508313]--[lr-0.000050]--[ETA-6:31:02]
2023.04.09-14:28:14:120:[step-11000/34000: 32.35%]--[loss-1.596669: wl-2.067349, gl-0.562995]--[lr-0.000050]--[ETA-6:23:12]
2023.04.09-14:29:53:220:[step-11100/34000: 32.65%]--[loss-1.654181: wl-2.244341, gl-0.532010]--[lr-0.000050]--[ETA-6:20:31]
2023.04.09-14:31:31:320:[step-11200/34000: 32.94%]--[loss-1.496146: wl-2.018304, gl-0.486994]--[lr-0.000050]--[ETA-5:59:31]
End of epoch 33 / 100: train_loss: 1.590 	 time: 376 sec
2023.04.09-14:33:55:80:[step-11300/34000: 33.24%]--[loss-1.539076: wl-2.037720, gl-0.520216]--[lr-0.000050]--[ETA-6:30:04]
2023.04.09-14:35:37:180:[step-11400/34000: 33.53%]--[loss-1.575444: wl-2.113705, gl-0.518591]--[lr-0.000050]--[ETA-6:21:31]
2023.04.09-14:37:17:280:[step-11500/34000: 33.82%]--[loss-1.489190: wl-2.073323, gl-0.452528]--[lr-0.000050]--[ETA-6:05:22]
End of epoch 34 / 100: train_loss: 1.589 	 time: 386 sec
2023.04.09-14:39:40:40:[step-11600/34000: 34.12%]--[loss-1.588982: wl-2.168307, gl-0.504829]--[lr-0.000050]--[ETA-6:34:07]
2023.04.09-14:41:19:140:[step-11700/34000: 34.41%]--[loss-1.690375: wl-2.132116, gl-0.624317]--[lr-0.000050]--[ETA-5:55:39]
2023.04.09-14:42:58:240:[step-11800/34000: 34.71%]--[loss-1.547282: wl-2.170457, gl-0.462053]--[lr-0.000050]--[ETA-6:01:11]
2023.04.09-14:44:35:340:[step-11900/34000: 35.00%]--[loss-1.481635: wl-1.823158, gl-0.570056]--[lr-0.000050]--[ETA-1:49:34]
End of epoch 35 / 100: train_loss: 1.576 	 time: 378 sec
Saving the model at the end of epoch 35, iters 11900
2023.04.09-14:46:55:100:[step-12000/34000: 35.29%]--[loss-1.589312: wl-2.211910, gl-0.483358]--[lr-0.000050]--[ETA-6:22:27]
2023.04.09-14:48:36:200:[step-12100/34000: 35.59%]--[loss-1.517658: wl-2.116605, gl-0.459355]--[lr-0.000050]--[ETA-6:18:16]
2023.04.09-14:50:15:300:[step-12200/34000: 35.88%]--[loss-1.579996: wl-2.112904, gl-0.523544]--[lr-0.000050]--[ETA-5:48:18]
End of epoch 36 / 100: train_loss: 1.571 	 time: 379 sec
2023.04.09-14:52:34:60:[step-12300/34000: 36.18%]--[loss-1.647900: wl-2.160677, gl-0.567562]--[lr-0.000050]--[ETA-6:14:36]
2023.04.09-14:54:13:160:[step-12400/34000: 36.47%]--[loss-1.550784: wl-2.117409, gl-0.492080]--[lr-0.000050]--[ETA-5:51:38]
2023.04.09-14:55:52:260:[step-12500/34000: 36.76%]--[loss-1.517045: wl-1.975039, gl-0.529526]--[lr-0.000050]--[ETA-5:49:07]
End of epoch 37 / 100: train_loss: 1.576 	 time: 374 sec
2023.04.09-14:58:09:20:[step-12600/34000: 37.06%]--[loss-1.530810: wl-2.135808, gl-0.462905]--[lr-0.000050]--[ETA-5:50:14]
2023.04.09-14:59:50:120:[step-12700/34000: 37.35%]--[loss-1.524554: wl-2.087126, gl-0.480992]--[lr-0.000050]--[ETA-5:51:12]
2023.04.09-15:01:31:220:[step-12800/34000: 37.65%]--[loss-1.648814: wl-2.297539, gl-0.500045]--[lr-0.000050]--[ETA-5:48:38]
2023.04.09-15:03:12:320:[step-12900/34000: 37.94%]--[loss-1.549682: wl-2.133517, gl-0.482924]--[lr-0.000050]--[ETA-5:41:48]
End of epoch 38 / 100: train_loss: 1.561 	 time: 382 sec
2023.04.09-15:05:39:80:[step-13000/34000: 38.24%]--[loss-1.495936: wl-2.025514, gl-0.483178]--[lr-0.000050]--[ETA-5:34:51]
2023.04.09-15:07:18:180:[step-13100/34000: 38.53%]--[loss-1.527746: wl-2.053330, gl-0.501081]--[lr-0.000050]--[ETA-5:37:08]
2023.04.09-15:08:57:280:[step-13200/34000: 38.82%]--[loss-1.580903: wl-2.108914, gl-0.526446]--[lr-0.000050]--[ETA-5:36:47]
End of epoch 39 / 100: train_loss: 1.564 	 time: 383 sec
2023.04.09-15:11:15:40:[step-13300/34000: 39.12%]--[loss-1.561700: wl-2.084758, gl-0.519321]--[lr-0.000050]--[ETA-5:40:00]
2023.04.09-15:12:56:140:[step-13400/34000: 39.41%]--[loss-1.481902: wl-2.011834, gl-0.475985]--[lr-0.000050]--[ETA-5:42:14]
2023.04.09-15:14:37:240:[step-13500/34000: 39.71%]--[loss-1.543355: wl-2.126506, gl-0.480102]--[lr-0.000050]--[ETA-5:48:09]
2023.04.09-15:16:15:340:[step-13600/34000: 40.00%]--[loss-1.418754: wl-2.057690, gl-0.389909]--[lr-0.000050]--[ETA-1:46:04]
End of epoch 40 / 100: train_loss: 1.563 	 time: 380 sec
Saving the model at the end of epoch 40, iters 13600
2023.04.09-15:18:36:100:[step-13700/34000: 40.29%]--[loss-1.497476: wl-2.075904, gl-0.459524]--[lr-0.000050]--[ETA-5:23:58]
2023.04.09-15:20:15:200:[step-13800/34000: 40.59%]--[loss-1.531135: wl-2.103206, gl-0.479532]--[lr-0.000050]--[ETA-5:25:42]
2023.04.09-15:21:53:300:[step-13900/34000: 40.88%]--[loss-1.526675: wl-2.075336, gl-0.489007]--[lr-0.000050]--[ETA-5:29:24]
End of epoch 41 / 100: train_loss: 1.545 	 time: 374 sec
2023.04.09-15:24:10:60:[step-14000/34000: 41.18%]--[loss-1.599945: wl-2.280934, gl-0.459478]--[lr-0.000050]--[ETA-5:42:20]
2023.04.09-15:25:51:160:[step-14100/34000: 41.47%]--[loss-1.489923: wl-2.040350, gl-0.469748]--[lr-0.000050]--[ETA-5:29:41]
2023.04.09-15:27:32:260:[step-14200/34000: 41.76%]--[loss-1.573997: wl-2.176441, gl-0.485776]--[lr-0.000050]--[ETA-5:49:38]
End of epoch 42 / 100: train_loss: 1.544 	 time: 380 sec
2023.04.09-15:29:50:20:[step-14300/34000: 42.06%]--[loss-1.572669: wl-2.084346, gl-0.530496]--[lr-0.000050]--[ETA-5:22:29]
2023.04.09-15:31:30:120:[step-14400/34000: 42.35%]--[loss-1.521125: wl-2.083781, gl-0.479235]--[lr-0.000050]--[ETA-5:09:01]
2023.04.09-15:33:09:220:[step-14500/34000: 42.65%]--[loss-1.517922: wl-2.094300, gl-0.470772]--[lr-0.000050]--[ETA-5:15:40]
2023.04.09-15:34:48:320:[step-14600/34000: 42.94%]--[loss-1.471863: wl-2.009777, gl-0.466975]--[lr-0.000050]--[ETA-5:13:21]
End of epoch 43 / 100: train_loss: 1.545 	 time: 375 sec
2023.04.09-15:37:06:80:[step-14700/34000: 43.24%]--[loss-1.488504: wl-2.039478, gl-0.468765]--[lr-0.000050]--[ETA-5:22:06]
2023.04.09-15:38:47:180:[step-14800/34000: 43.53%]--[loss-1.495828: wl-2.118315, gl-0.436671]--[lr-0.000050]--[ETA-5:25:27]
2023.04.09-15:40:28:280:[step-14900/34000: 43.82%]--[loss-1.524366: wl-2.113426, gl-0.467653]--[lr-0.000050]--[ETA-5:10:38]
End of epoch 44 / 100: train_loss: 1.531 	 time: 380 sec
2023.04.09-15:42:46:40:[step-15000/34000: 44.12%]--[loss-1.576848: wl-2.215810, gl-0.468943]--[lr-0.000050]--[ETA-5:16:30]
2023.04.09-15:44:26:140:[step-15100/34000: 44.41%]--[loss-1.492659: wl-2.101572, gl-0.441873]--[lr-0.000050]--[ETA-5:10:08]
2023.04.09-15:46:05:240:[step-15200/34000: 44.71%]--[loss-1.496796: wl-2.056599, gl-0.468497]--[lr-0.000050]--[ETA-5:23:10]
2023.04.09-15:47:43:340:[step-15300/34000: 45.00%]--[loss-1.451841: wl-1.993810, gl-0.454936]--[lr-0.000050]--[ETA-1:36:03]
End of epoch 45 / 100: train_loss: 1.529 	 time: 375 sec
Saving the model at the end of epoch 45, iters 15300
2023.04.09-15:50:05:100:[step-15400/34000: 45.29%]--[loss-1.562988: wl-2.114587, gl-0.505695]--[lr-0.000050]--[ETA-5:26:51]
2023.04.09-15:51:46:200:[step-15500/34000: 45.59%]--[loss-1.433877: wl-2.054284, gl-0.406735]--[lr-0.000050]--[ETA-5:10:28]
2023.04.09-15:53:26:300:[step-15600/34000: 45.88%]--[loss-1.479105: wl-2.095646, gl-0.431283]--[lr-0.000050]--[ETA-5:01:57]
End of epoch 46 / 100: train_loss: 1.528 	 time: 381 sec
2023.04.09-15:55:45:60:[step-15700/34000: 46.18%]--[loss-1.617746: wl-2.315419, gl-0.460036]--[lr-0.000050]--[ETA-4:55:24]
2023.04.09-15:57:24:160:[step-15800/34000: 46.47%]--[loss-1.644285: wl-2.256531, gl-0.516020]--[lr-0.000050]--[ETA-5:02:10]
2023.04.09-15:59:02:260:[step-15900/34000: 46.76%]--[loss-1.473442: wl-2.074535, gl-0.436174]--[lr-0.000050]--[ETA-5:03:45]
End of epoch 47 / 100: train_loss: 1.527 	 time: 374 sec
2023.04.09-16:01:19:20:[step-16000/34000: 47.06%]--[loss-1.611372: wl-2.196931, gl-0.512907]--[lr-0.000050]--[ETA-4:59:02]
2023.04.09-16:02:59:120:[step-16100/34000: 47.35%]--[loss-1.492104: wl-2.018261, gl-0.482973]--[lr-0.000050]--[ETA-4:50:36]
2023.04.09-16:04:40:220:[step-16200/34000: 47.65%]--[loss-1.445735: wl-2.033106, gl-0.429182]--[lr-0.000050]--[ETA-4:58:13]
2023.04.09-16:06:19:320:[step-16300/34000: 47.94%]--[loss-1.537285: wl-2.123216, gl-0.475677]--[lr-0.000050]--[ETA-4:38:24]
End of epoch 48 / 100: train_loss: 1.547 	 time: 378 sec
2023.04.09-16:08:37:80:[step-16400/34000: 48.24%]--[loss-1.475592: wl-2.098429, gl-0.426378]--[lr-0.000050]--[ETA-4:52:38]
2023.04.09-16:10:16:180:[step-16500/34000: 48.53%]--[loss-1.453844: wl-2.076767, gl-0.415460]--[lr-0.000050]--[ETA-4:56:32]
2023.04.09-16:11:54:280:[step-16600/34000: 48.82%]--[loss-1.586824: wl-2.192667, gl-0.490491]--[lr-0.000050]--[ETA-4:51:38]
End of epoch 49 / 100: train_loss: 1.536 	 time: 372 sec
2023.04.09-16:14:15:40:[step-16700/34000: 49.12%]--[loss-1.475999: wl-2.037606, gl-0.457196]--[lr-0.000050]--[ETA-4:44:04]
2023.04.09-16:15:54:140:[step-16800/34000: 49.41%]--[loss-1.464508: wl-2.063891, gl-0.432563]--[lr-0.000050]--[ETA-4:46:36]
2023.04.09-16:17:35:240:[step-16900/34000: 49.71%]--[loss-1.404823: wl-1.944968, gl-0.432339]--[lr-0.000050]--[ETA-4:49:55]
2023.04.09-16:19:12:340:[step-17000/34000: 50.00%]--[loss-1.866227: wl-2.077909, gl-0.827273]--[lr-0.000050]--[ETA-1:15:22]
End of epoch 50 / 100: train_loss: 1.520 	 time: 382 sec
Saving the model at the end of epoch 50, iters 17000
2023.04.09-16:21:31:100:[step-17100/34000: 50.29%]--[loss-1.615427: wl-2.224703, gl-0.503075]--[lr-0.000050]--[ETA-5:02:18]
2023.04.09-16:23:10:200:[step-17200/34000: 50.59%]--[loss-1.520537: wl-2.126116, gl-0.457479]--[lr-0.000050]--[ETA-4:26:26]
2023.04.09-16:24:49:300:[step-17300/34000: 50.88%]--[loss-1.448726: wl-2.012083, gl-0.442685]--[lr-0.000050]--[ETA-4:23:38]
End of epoch 51 / 100: train_loss: 1.511 	 time: 372 sec
2023.04.09-16:27:09:60:[step-17400/34000: 51.18%]--[loss-1.496400: wl-2.118430, gl-0.437185]--[lr-0.000049]--[ETA-4:28:30]
2023.04.09-16:28:48:160:[step-17500/34000: 51.47%]--[loss-1.520180: wl-2.089512, gl-0.475424]--[lr-0.000049]--[ETA-4:29:56]
2023.04.09-16:30:28:260:[step-17600/34000: 51.76%]--[loss-1.495583: wl-2.091403, gl-0.449882]--[lr-0.000049]--[ETA-4:35:58]
End of epoch 52 / 100: train_loss: 1.507 	 time: 381 sec
2023.04.09-16:32:50:20:[step-17700/34000: 52.06%]--[loss-1.652113: wl-2.142207, gl-0.581010]--[lr-0.000048]--[ETA-4:29:56]
2023.04.09-16:34:29:120:[step-17800/34000: 52.35%]--[loss-1.634418: wl-2.336109, gl-0.466364]--[lr-0.000048]--[ETA-4:22:39]
2023.04.09-16:36:08:220:[step-17900/34000: 52.65%]--[loss-1.582254: wl-2.278603, gl-0.442952]--[lr-0.000048]--[ETA-4:18:02]
2023.04.09-16:37:45:320:[step-18000/34000: 52.94%]--[loss-1.440547: wl-2.085716, gl-0.397689]--[lr-0.000048]--[ETA-4:14:34]
End of epoch 53 / 100: train_loss: 1.520 	 time: 376 sec
2023.04.09-16:40:06:80:[step-18100/34000: 53.24%]--[loss-1.579978: wl-2.122619, gl-0.518668]--[lr-0.000047]--[ETA-4:25:43]
2023.04.09-16:41:47:180:[step-18200/34000: 53.53%]--[loss-1.598877: wl-2.209384, gl-0.494185]--[lr-0.000047]--[ETA-4:26:40]
2023.04.09-16:43:27:280:[step-18300/34000: 53.82%]--[loss-1.524334: wl-2.144817, gl-0.451926]--[lr-0.000047]--[ETA-4:19:18]
End of epoch 54 / 100: train_loss: 1.564 	 time: 381 sec
2023.04.09-16:45:44:40:[step-18400/34000: 54.12%]--[loss-1.554337: wl-2.266807, gl-0.420933]--[lr-0.000046]--[ETA-4:24:12]
2023.04.09-16:47:24:140:[step-18500/34000: 54.41%]--[loss-1.588171: wl-2.217178, gl-0.479582]--[lr-0.000046]--[ETA-4:12:45]
2023.04.09-16:49:02:240:[step-18600/34000: 54.71%]--[loss-1.426813: wl-2.021083, gl-0.416271]--[lr-0.000046]--[ETA-4:04:11]
2023.04.09-16:50:39:340:[step-18700/34000: 55.00%]--[loss-1.661635: wl-2.213638, gl-0.554816]--[lr-0.000046]--[ETA-1:08:48]
End of epoch 55 / 100: train_loss: 1.504 	 time: 373 sec
Saving the model at the end of epoch 55, iters 18700
2023.04.09-16:53:03:100:[step-18800/34000: 55.29%]--[loss-1.413598: wl-2.052942, gl-0.387127]--[lr-0.000045]--[ETA-4:10:19]
2023.04.09-16:54:44:200:[step-18900/34000: 55.59%]--[loss-1.407156: wl-1.975778, gl-0.419267]--[lr-0.000045]--[ETA-4:10:15]
2023.04.09-16:56:23:300:[step-19000/34000: 55.88%]--[loss-1.540442: wl-2.206149, gl-0.437368]--[lr-0.000045]--[ETA-4:18:01]
End of epoch 56 / 100: train_loss: 1.496 	 time: 383 sec
2023.04.09-16:58:40:60:[step-19100/34000: 56.18%]--[loss-1.457023: wl-2.043232, gl-0.435407]--[lr-0.000044]--[ETA-4:04:24]
2023.04.09-17:00:18:160:[step-19200/34000: 56.47%]--[loss-1.574613: wl-2.175202, gl-0.487012]--[lr-0.000044]--[ETA-4:03:15]
2023.04.09-17:01:56:260:[step-19300/34000: 56.76%]--[loss-1.463370: wl-2.084193, gl-0.421273]--[lr-0.000044]--[ETA-3:58:27]
End of epoch 57 / 100: train_loss: 1.490 	 time: 369 sec
2023.04.09-17:04:10:20:[step-19400/34000: 57.06%]--[loss-1.499884: wl-2.095689, gl-0.452039]--[lr-0.000043]--[ETA-4:00:11]
2023.04.09-17:05:50:120:[step-19500/34000: 57.35%]--[loss-1.546159: wl-2.209215, gl-0.441551]--[lr-0.000043]--[ETA-4:00:31]
2023.04.09-17:07:30:220:[step-19600/34000: 57.65%]--[loss-1.527796: wl-2.197539, gl-0.429027]--[lr-0.000043]--[ETA-4:02:21]
2023.04.09-17:09:10:320:[step-19700/34000: 57.94%]--[loss-1.544404: wl-2.198528, gl-0.445140]--[lr-0.000043]--[ETA-3:50:56]
End of epoch 58 / 100: train_loss: 1.488 	 time: 376 sec
2023.04.09-17:11:33:80:[step-19800/34000: 58.24%]--[loss-1.524321: wl-2.144622, gl-0.452010]--[lr-0.000042]--[ETA-3:51:02]
2023.04.09-17:13:11:180:[step-19900/34000: 58.53%]--[loss-1.399270: wl-2.044019, gl-0.377260]--[lr-0.000042]--[ETA-3:48:34]
2023.04.09-17:14:49:280:[step-20000/34000: 58.82%]--[loss-1.412769: wl-1.992145, gl-0.416696]--[lr-0.000042]--[ETA-3:50:13]
End of epoch 59 / 100: train_loss: 1.485 	 time: 376 sec
2023.04.09-17:17:03:40:[step-20100/34000: 59.12%]--[loss-1.492163: wl-2.065291, gl-0.459517]--[lr-0.000041]--[ETA-3:47:16]
2023.04.09-17:18:44:140:[step-20200/34000: 59.41%]--[loss-1.503747: wl-2.185924, gl-0.410785]--[lr-0.000041]--[ETA-3:49:14]
2023.04.09-17:20:23:240:[step-20300/34000: 59.71%]--[loss-1.535978: wl-2.183685, gl-0.444136]--[lr-0.000041]--[ETA-3:45:34]
2023.04.09-17:22:01:340:[step-20400/34000: 60.00%]--[loss-1.306912: wl-1.910143, gl-0.351841]--[lr-0.000041]--[ETA-1:04:11]
End of epoch 60 / 100: train_loss: 1.480 	 time: 375 sec
Saving the model at the end of epoch 60, iters 20400
2023.04.09-17:24:24:100:[step-20500/34000: 60.29%]--[loss-1.366727: wl-1.994078, gl-0.369688]--[lr-0.000040]--[ETA-3:32:43]
2023.04.09-17:26:02:200:[step-20600/34000: 60.59%]--[loss-1.508871: wl-2.187826, gl-0.414958]--[lr-0.000040]--[ETA-3:36:53]
2023.04.09-17:27:41:300:[step-20700/34000: 60.88%]--[loss-1.447344: wl-2.053670, gl-0.420509]--[lr-0.000040]--[ETA-3:35:36]
End of epoch 61 / 100: train_loss: 1.478 	 time: 375 sec
2023.04.09-17:29:57:60:[step-20800/34000: 61.18%]--[loss-1.526142: wl-2.174545, gl-0.438870]--[lr-0.000039]--[ETA-3:37:20]
2023.04.09-17:31:38:160:[step-20900/34000: 61.47%]--[loss-1.501720: wl-2.139045, gl-0.432198]--[lr-0.000039]--[ETA-3:48:06]
2023.04.09-17:33:18:260:[step-21000/34000: 61.76%]--[loss-1.461040: wl-2.054519, gl-0.433781]--[lr-0.000039]--[ETA-3:27:43]
End of epoch 62 / 100: train_loss: 1.477 	 time: 379 sec
2023.04.09-17:35:40:20:[step-21100/34000: 62.06%]--[loss-1.395502: wl-1.991901, gl-0.399551]--[lr-0.000038]--[ETA-3:33:55]
2023.04.09-17:37:19:120:[step-21200/34000: 62.35%]--[loss-1.496330: wl-2.114263, gl-0.439199]--[lr-0.000038]--[ETA-3:24:20]
2023.04.09-17:38:56:220:[step-21300/34000: 62.65%]--[loss-1.508814: wl-2.176945, gl-0.420342]--[lr-0.000038]--[ETA-3:30:44]
2023.04.09-17:40:33:320:[step-21400/34000: 62.94%]--[loss-1.492833: wl-2.199764, gl-0.392951]--[lr-0.000038]--[ETA-3:20:27]
End of epoch 63 / 100: train_loss: 1.473 	 time: 373 sec
2023.04.09-17:42:47:80:[step-21500/34000: 63.24%]--[loss-1.394878: wl-1.972336, gl-0.408710]--[lr-0.000037]--[ETA-3:37:28]
2023.04.09-17:44:27:180:[step-21600/34000: 63.53%]--[loss-1.499683: wl-2.134969, gl-0.432199]--[lr-0.000037]--[ETA-3:23:38]
2023.04.09-17:46:07:280:[step-21700/34000: 63.82%]--[loss-1.446314: wl-2.125246, gl-0.383691]--[lr-0.000037]--[ETA-3:19:00]
End of epoch 64 / 100: train_loss: 1.470 	 time: 374 sec
2023.04.09-17:48:24:40:[step-21800/34000: 64.12%]--[loss-1.431728: wl-2.021556, gl-0.420950]--[lr-0.000036]--[ETA-3:23:36]
2023.04.09-17:50:04:140:[step-21900/34000: 64.41%]--[loss-1.561531: wl-2.132166, gl-0.495448]--[lr-0.000036]--[ETA-3:15:06]
2023.04.09-17:51:41:240:[step-22000/34000: 64.71%]--[loss-1.458614: wl-2.083632, gl-0.416798]--[lr-0.000036]--[ETA-3:40:24]
2023.04.09-17:53:18:340:[step-22100/34000: 65.00%]--[loss-1.324363: wl-1.993483, gl-0.327622]--[lr-0.000036]--[ETA-0:52:35]
End of epoch 65 / 100: train_loss: 1.466 	 time: 372 sec
Saving the model at the end of epoch 65, iters 22100
2023.04.09-17:55:40:100:[step-22200/34000: 65.29%]--[loss-1.399423: wl-2.011477, gl-0.393684]--[lr-0.000035]--[ETA-3:15:08]
2023.04.09-17:57:20:200:[step-22300/34000: 65.59%]--[loss-1.367139: wl-1.983170, gl-0.375554]--[lr-0.000035]--[ETA-3:22:58]
2023.04.09-17:59:00:300:[step-22400/34000: 65.88%]--[loss-1.480586: wl-2.089441, gl-0.435866]--[lr-0.000035]--[ETA-3:02:18]
End of epoch 66 / 100: train_loss: 1.463 	 time: 379 sec
2023.04.09-18:01:15:60:[step-22500/34000: 66.18%]--[loss-1.487339: wl-2.117309, gl-0.428685]--[lr-0.000034]--[ETA-3:06:48]
2023.04.09-18:02:52:160:[step-22600/34000: 66.47%]--[loss-1.538086: wl-2.190833, gl-0.442669]--[lr-0.000034]--[ETA-3:05:12]
2023.04.09-18:04:30:260:[step-22700/34000: 66.76%]--[loss-1.425018: wl-2.074704, gl-0.387666]--[lr-0.000034]--[ETA-3:01:49]
End of epoch 67 / 100: train_loss: 1.461 	 time: 369 sec
2023.04.09-18:06:44:20:[step-22800/34000: 67.06%]--[loss-1.390030: wl-2.001758, gl-0.389151]--[lr-0.000033]--[ETA-3:15:19]
2023.04.09-18:08:24:120:[step-22900/34000: 67.35%]--[loss-1.447771: wl-2.087225, gl-0.404158]--[lr-0.000033]--[ETA-3:01:53]
2023.04.09-18:10:04:220:[step-23000/34000: 67.65%]--[loss-1.488682: wl-2.145883, gl-0.415740]--[lr-0.000033]--[ETA-3:08:21]
2023.04.09-18:11:44:320:[step-23100/34000: 67.94%]--[loss-1.460488: wl-2.082494, gl-0.419241]--[lr-0.000033]--[ETA-2:55:06]
End of epoch 68 / 100: train_loss: 1.459 	 time: 376 sec
2023.04.09-18:14:08:80:[step-23200/34000: 68.24%]--[loss-1.447389: wl-2.101891, gl-0.396444]--[lr-0.000032]--[ETA-2:59:55]
2023.04.09-18:15:47:180:[step-23300/34000: 68.53%]--[loss-1.457933: wl-2.051098, gl-0.432384]--[lr-0.000032]--[ETA-2:55:28]
2023.04.09-18:17:23:280:[step-23400/34000: 68.82%]--[loss-1.426469: wl-2.064428, gl-0.394254]--[lr-0.000032]--[ETA-2:52:53]
End of epoch 69 / 100: train_loss: 1.452 	 time: 377 sec
2023.04.09-18:19:39:40:[step-23500/34000: 69.12%]--[loss-1.534043: wl-2.256696, gl-0.405695]--[lr-0.000031]--[ETA-2:45:40]
2023.04.09-18:21:18:140:[step-23600/34000: 69.41%]--[loss-1.392273: wl-2.014915, gl-0.384815]--[lr-0.000031]--[ETA-2:52:20]
2023.04.09-18:22:58:240:[step-23700/34000: 69.71%]--[loss-1.432992: wl-2.032360, gl-0.416812]--[lr-0.000031]--[ETA-2:52:16]
2023.04.09-18:24:35:340:[step-23800/34000: 70.00%]--[loss-1.247212: wl-1.874837, gl-0.309794]--[lr-0.000031]--[ETA-0:45:44]
End of epoch 70 / 100: train_loss: 1.450 	 time: 374 sec
Saving the model at the end of epoch 70, iters 23800
2023.04.09-18:26:56:100:[step-23900/34000: 70.29%]--[loss-1.571871: wl-2.276091, gl-0.433825]--[lr-0.000030]--[ETA-2:42:04]
2023.04.09-18:28:35:200:[step-24000/34000: 70.59%]--[loss-1.501499: wl-2.164594, gl-0.419202]--[lr-0.000030]--[ETA-2:46:02]
2023.04.09-18:30:13:300:[step-24100/34000: 70.88%]--[loss-1.439420: wl-2.075505, gl-0.401668]--[lr-0.000030]--[ETA-2:36:57]
End of epoch 71 / 100: train_loss: 1.446 	 time: 373 sec
2023.04.09-18:32:28:60:[step-24200/34000: 71.18%]--[loss-1.554602: wl-2.221501, gl-0.443852]--[lr-0.000029]--[ETA-2:38:31]
2023.04.09-18:34:09:160:[step-24300/34000: 71.47%]--[loss-1.508150: wl-2.200318, gl-0.407991]--[lr-0.000029]--[ETA-2:48:20]
2023.04.09-18:35:48:260:[step-24400/34000: 71.76%]--[loss-1.473317: wl-2.184455, gl-0.381090]--[lr-0.000029]--[ETA-2:37:57]
End of epoch 72 / 100: train_loss: 1.444 	 time: 376 sec
2023.04.09-18:38:08:20:[step-24500/34000: 72.06%]--[loss-1.499487: wl-2.182243, gl-0.408365]--[lr-0.000028]--[ETA-2:41:54]
2023.04.09-18:39:47:120:[step-24600/34000: 72.35%]--[loss-1.378504: wl-2.044859, gl-0.356074]--[lr-0.000028]--[ETA-2:41:33]
2023.04.09-18:41:25:220:[step-24700/34000: 72.65%]--[loss-1.450991: wl-2.120905, gl-0.390538]--[lr-0.000028]--[ETA-2:33:16]
2023.04.09-18:43:02:320:[step-24800/34000: 72.94%]--[loss-1.425608: wl-2.075071, gl-0.388072]--[lr-0.000028]--[ETA-2:26:39]
End of epoch 73 / 100: train_loss: 1.441 	 time: 373 sec
2023.04.09-18:45:18:80:[step-24900/34000: 73.24%]--[loss-1.546818: wl-2.226230, gl-0.433703]--[lr-0.000027]--[ETA-2:31:56]
2023.04.09-18:46:58:180:[step-25000/34000: 73.53%]--[loss-1.484707: wl-2.178325, gl-0.395545]--[lr-0.000027]--[ETA-2:29:35]
2023.04.09-18:48:37:280:[step-25100/34000: 73.82%]--[loss-1.447899: wl-2.093050, gl-0.401374]--[lr-0.000027]--[ETA-2:28:15]
End of epoch 74 / 100: train_loss: 1.438 	 time: 375 sec
2023.04.09-18:50:58:40:[step-25200/34000: 74.12%]--[loss-1.460291: wl-2.091721, gl-0.414431]--[lr-0.000026]--[ETA-2:29:22]
2023.04.09-18:52:37:140:[step-25300/34000: 74.41%]--[loss-1.480561: wl-2.188064, gl-0.386529]--[lr-0.000026]--[ETA-2:21:35]
2023.04.09-18:54:15:240:[step-25400/34000: 74.71%]--[loss-1.391789: wl-1.956076, gl-0.413751]--[lr-0.000026]--[ETA-2:16:04]
2023.04.09-18:55:51:340:[step-25500/34000: 75.00%]--[loss-1.775508: wl-2.325107, gl-0.612955]--[lr-0.000026]--[ETA-0:46:47]
End of epoch 75 / 100: train_loss: 1.436 	 time: 375 sec
Saving the model at the end of epoch 75, iters 25500
2023.04.09-18:58:14:100:[step-25600/34000: 75.29%]--[loss-1.511529: wl-2.199131, gl-0.411964]--[lr-0.000025]--[ETA-2:20:40]
2023.04.09-18:59:55:200:[step-25700/34000: 75.59%]--[loss-1.437064: wl-2.089221, gl-0.392453]--[lr-0.000025]--[ETA-2:18:31]
2023.04.09-19:01:34:300:[step-25800/34000: 75.88%]--[loss-1.401875: wl-2.033489, gl-0.385131]--[lr-0.000025]--[ETA-2:14:47]
End of epoch 76 / 100: train_loss: 1.448 	 time: 380 sec
2023.04.09-19:03:50:60:[step-25900/34000: 76.18%]--[loss-1.481425: wl-2.138459, gl-0.412195]--[lr-0.000024]--[ETA-2:16:11]
2023.04.09-19:05:29:160:[step-26000/34000: 76.47%]--[loss-1.363174: wl-2.010038, gl-0.358155]--[lr-0.000024]--[ETA-2:13:07]
2023.04.09-19:07:07:260:[step-26100/34000: 76.76%]--[loss-1.415348: wl-2.054380, gl-0.388158]--[lr-0.000024]--[ETA-2:06:15]
End of epoch 77 / 100: train_loss: 1.434 	 time: 370 sec
2023.04.09-19:09:20:20:[step-26200/34000: 77.06%]--[loss-1.432210: wl-2.083056, gl-0.390681]--[lr-0.000023]--[ETA-2:08:04]
2023.04.09-19:11:00:120:[step-26300/34000: 77.35%]--[loss-1.478550: wl-2.154803, gl-0.401148]--[lr-0.000023]--[ETA-2:06:37]
2023.04.09-19:12:39:220:[step-26400/34000: 77.65%]--[loss-1.368450: wl-2.026144, gl-0.355378]--[lr-0.000023]--[ETA-2:05:20]
2023.04.09-19:14:18:320:[step-26500/34000: 77.94%]--[loss-1.382861: wl-2.016037, gl-0.374843]--[lr-0.000023]--[ETA-2:02:25]
End of epoch 78 / 100: train_loss: 1.425 	 time: 374 sec
2023.04.09-19:16:41:80:[step-26600/34000: 78.24%]--[loss-1.397599: wl-2.059347, gl-0.367925]--[lr-0.000022]--[ETA-2:01:35]
2023.04.09-19:18:19:180:[step-26700/34000: 78.53%]--[loss-1.410299: wl-2.122938, gl-0.348830]--[lr-0.000022]--[ETA-1:57:35]
2023.04.09-19:19:57:280:[step-26800/34000: 78.82%]--[loss-1.304197: wl-1.939759, gl-0.334318]--[lr-0.000022]--[ETA-1:55:51]
End of epoch 79 / 100: train_loss: 1.423 	 time: 376 sec
2023.04.09-19:22:12:40:[step-26900/34000: 79.12%]--[loss-1.378551: wl-2.033115, gl-0.361994]--[lr-0.000021]--[ETA-1:56:01]
2023.04.09-19:23:52:140:[step-27000/34000: 79.41%]--[loss-1.497189: wl-2.208504, gl-0.392937]--[lr-0.000021]--[ETA-1:54:56]
2023.04.09-19:25:33:240:[step-27100/34000: 79.71%]--[loss-1.466995: wl-2.132039, gl-0.400976]--[lr-0.000021]--[ETA-1:54:09]
2023.04.09-19:27:10:340:[step-27200/34000: 80.00%]--[loss-2.194279: wl-2.111502, gl-1.138528]--[lr-0.000021]--[ETA-0:31:31]
End of epoch 80 / 100: train_loss: 1.425 	 time: 376 sec
Saving the model at the end of epoch 80, iters 27200
2023.04.09-19:29:28:100:[step-27300/34000: 80.29%]--[loss-1.417802: wl-2.096131, gl-0.369737]--[lr-0.000020]--[ETA-1:54:04]
2023.04.09-19:31:08:200:[step-27400/34000: 80.59%]--[loss-1.507709: wl-2.262939, gl-0.376240]--[lr-0.000020]--[ETA-1:48:49]
2023.04.09-19:32:44:300:[step-27500/34000: 80.88%]--[loss-1.448879: wl-2.125417, gl-0.386170]--[lr-0.000020]--[ETA-1:45:46]
End of epoch 81 / 100: train_loss: 1.424 	 time: 370 sec
2023.04.09-19:35:05:60:[step-27600/34000: 81.18%]--[loss-1.340617: wl-1.975186, gl-0.353024]--[lr-0.000019]--[ETA-1:42:08]
2023.04.09-19:36:44:160:[step-27700/34000: 81.47%]--[loss-1.440702: wl-2.119517, gl-0.380943]--[lr-0.000019]--[ETA-1:47:00]
2023.04.09-19:38:24:260:[step-27800/34000: 81.76%]--[loss-1.321128: wl-1.953392, gl-0.344432]--[lr-0.000019]--[ETA-1:40:59]
End of epoch 82 / 100: train_loss: 1.417 	 time: 380 sec
2023.04.09-19:40:41:20:[step-27900/34000: 82.06%]--[loss-1.385281: wl-2.039744, gl-0.365409]--[lr-0.000018]--[ETA-1:38:22]
2023.04.09-19:42:22:120:[step-28000/34000: 82.35%]--[loss-1.471206: wl-2.168305, gl-0.387054]--[lr-0.000018]--[ETA-1:37:04]
2023.04.09-19:44:02:220:[step-28100/34000: 82.65%]--[loss-1.452073: wl-2.104358, gl-0.399894]--[lr-0.000018]--[ETA-1:34:46]
2023.04.09-19:45:40:320:[step-28200/34000: 82.94%]--[loss-1.377652: wl-2.021435, gl-0.366934]--[lr-0.000018]--[ETA-1:31:49]
End of epoch 83 / 100: train_loss: 1.416 	 time: 376 sec
2023.04.09-19:48:00:80:[step-28300/34000: 83.24%]--[loss-1.414336: wl-2.122545, gl-0.353063]--[lr-0.000017]--[ETA-1:34:40]
2023.04.09-19:49:40:180:[step-28400/34000: 83.53%]--[loss-1.375091: wl-2.010315, gl-0.369934]--[lr-0.000017]--[ETA-1:33:33]
2023.04.09-19:51:19:280:[step-28500/34000: 83.82%]--[loss-1.499688: wl-2.159408, gl-0.419984]--[lr-0.000017]--[ETA-1:29:42]
End of epoch 84 / 100: train_loss: 1.412 	 time: 379 sec
2023.04.09-19:53:42:40:[step-28600/34000: 84.12%]--[loss-1.466927: wl-2.199161, gl-0.367347]--[lr-0.000016]--[ETA-1:28:32]
2023.04.09-19:55:20:140:[step-28700/34000: 84.41%]--[loss-1.370504: wl-2.006769, gl-0.367119]--[lr-0.000016]--[ETA-1:30:24]
2023.04.09-19:57:00:240:[step-28800/34000: 84.71%]--[loss-1.347358: wl-2.030639, gl-0.332039]--[lr-0.000016]--[ETA-1:27:50]
2023.04.09-19:58:37:340:[step-28900/34000: 85.00%]--[loss-1.330917: wl-1.894514, gl-0.383661]--[lr-0.000016]--[ETA-0:28:54]
End of epoch 85 / 100: train_loss: 1.410 	 time: 379 sec
Saving the model at the end of epoch 85, iters 28900
2023.04.09-20:01:01:100:[step-29000/34000: 85.29%]--[loss-1.587749: wl-2.373614, gl-0.400942]--[lr-0.000015]--[ETA-1:24:20]
2023.04.09-20:02:42:200:[step-29100/34000: 85.59%]--[loss-1.397549: wl-2.074461, gl-0.360319]--[lr-0.000015]--[ETA-1:21:30]
2023.04.09-20:04:21:300:[step-29200/34000: 85.88%]--[loss-1.457927: wl-2.111360, gl-0.402247]--[lr-0.000015]--[ETA-1:18:23]
End of epoch 86 / 100: train_loss: 1.408 	 time: 382 sec
2023.04.09-20:06:37:60:[step-29300/34000: 86.18%]--[loss-1.436805: wl-2.087284, gl-0.393163]--[lr-0.000014]--[ETA-1:17:40]
2023.04.09-20:08:16:160:[step-29400/34000: 86.47%]--[loss-1.382481: wl-2.074043, gl-0.345460]--[lr-0.000014]--[ETA-1:16:22]
2023.04.09-20:09:53:260:[step-29500/34000: 86.76%]--[loss-1.365592: wl-2.014475, gl-0.358355]--[lr-0.000014]--[ETA-1:13:55]
End of epoch 87 / 100: train_loss: 1.406 	 time: 370 sec
2023.04.09-20:12:07:20:[step-29600/34000: 87.06%]--[loss-1.365225: wl-2.029247, gl-0.350602]--[lr-0.000013]--[ETA-1:09:28]
2023.04.09-20:13:46:120:[step-29700/34000: 87.35%]--[loss-1.327724: wl-1.982004, gl-0.336721]--[lr-0.000013]--[ETA-1:11:57]
2023.04.09-20:15:26:220:[step-29800/34000: 87.65%]--[loss-1.409791: wl-2.132169, gl-0.343707]--[lr-0.000013]--[ETA-1:09:19]
2023.04.09-20:17:04:320:[step-29900/34000: 87.94%]--[loss-1.368223: wl-2.050656, gl-0.342895]--[lr-0.000013]--[ETA-1:04:47]
End of epoch 88 / 100: train_loss: 1.405 	 time: 373 sec
2023.04.09-20:19:27:80:[step-30000/34000: 88.24%]--[loss-1.329883: wl-1.996856, gl-0.331456]--[lr-0.000012]--[ETA-1:05:36]
2023.04.09-20:21:05:180:[step-30100/34000: 88.53%]--[loss-1.418663: wl-2.122093, gl-0.357616]--[lr-0.000012]--[ETA-1:04:05]
2023.04.09-20:22:43:280:[step-30200/34000: 88.82%]--[loss-1.338060: wl-2.035681, gl-0.320219]--[lr-0.000012]--[ETA-1:02:44]
End of epoch 89 / 100: train_loss: 1.402 	 time: 376 sec
2023.04.09-20:24:58:40:[step-30300/34000: 89.12%]--[loss-1.293500: wl-1.953135, gl-0.316933]--[lr-0.000011]--[ETA-0:58:49]
2023.04.09-20:26:38:140:[step-30400/34000: 89.41%]--[loss-1.398337: wl-2.060572, gl-0.368051]--[lr-0.000011]--[ETA-1:01:08]
2023.04.09-20:28:18:240:[step-30500/34000: 89.71%]--[loss-1.422645: wl-2.090426, gl-0.377432]--[lr-0.000011]--[ETA-0:58:38]
2023.04.09-20:29:55:340:[step-30600/34000: 90.00%]--[loss-1.280337: wl-2.006058, gl-0.277308]--[lr-0.000011]--[ETA-0:18:10]
End of epoch 90 / 100: train_loss: 1.400 	 time: 375 sec
Saving the model at the end of epoch 90, iters 30600
2023.04.09-20:32:14:100:[step-30700/34000: 90.29%]--[loss-1.451881: wl-2.102950, gl-0.400406]--[lr-0.000010]--[ETA-0:56:52]
2023.04.09-20:33:53:200:[step-30800/34000: 90.59%]--[loss-1.400229: wl-2.030073, gl-0.385193]--[lr-0.000010]--[ETA-0:52:10]
2023.04.09-20:35:31:300:[step-30900/34000: 90.88%]--[loss-1.387177: wl-2.048329, gl-0.363013]--[lr-0.000010]--[ETA-0:49:02]
End of epoch 91 / 100: train_loss: 1.400 	 time: 372 sec
2023.04.09-20:37:52:60:[step-31000/34000: 91.18%]--[loss-1.434946: wl-2.146423, gl-0.361734]--[lr-0.000009]--[ETA-0:50:28]
2023.04.09-20:39:32:160:[step-31100/34000: 91.47%]--[loss-1.372163: wl-2.081100, gl-0.331613]--[lr-0.000009]--[ETA-0:47:28]
2023.04.09-20:41:12:260:[step-31200/34000: 91.76%]--[loss-1.399378: wl-2.005117, gl-0.396820]--[lr-0.000009]--[ETA-0:47:02]
End of epoch 92 / 100: train_loss: 1.398 	 time: 381 sec
2023.04.09-20:43:33:20:[step-31300/34000: 92.06%]--[loss-1.359421: wl-2.027988, gl-0.345427]--[lr-0.000008]--[ETA-0:43:12]
2023.04.09-20:45:11:120:[step-31400/34000: 92.35%]--[loss-1.404549: wl-2.078261, gl-0.365418]--[lr-0.000008]--[ETA-0:41:46]
2023.04.09-20:46:50:220:[step-31500/34000: 92.65%]--[loss-1.413252: wl-2.074731, gl-0.375886]--[lr-0.000008]--[ETA-0:40:19]
2023.04.09-20:48:27:320:[step-31600/34000: 92.94%]--[loss-1.409655: wl-2.096983, gl-0.361163]--[lr-0.000008]--[ETA-0:37:55]
End of epoch 93 / 100: train_loss: 1.395 	 time: 375 sec
2023.04.09-20:50:42:80:[step-31700/34000: 93.24%]--[loss-1.442074: wl-2.197569, gl-0.343290]--[lr-0.000007]--[ETA-0:38:37]
2023.04.09-20:52:23:180:[step-31800/34000: 93.53%]--[loss-1.422669: wl-2.126142, gl-0.359598]--[lr-0.000007]--[ETA-0:36:31]
2023.04.09-20:54:02:280:[step-31900/34000: 93.82%]--[loss-1.356789: wl-2.024336, gl-0.344622]--[lr-0.000007]--[ETA-0:34:28]
End of epoch 94 / 100: train_loss: 1.394 	 time: 375 sec
2023.04.09-20:56:24:40:[step-32000/34000: 94.12%]--[loss-1.469121: wl-2.194596, gl-0.371823]--[lr-0.000006]--[ETA-0:33:03]
2023.04.09-20:58:03:140:[step-32100/34000: 94.41%]--[loss-1.419100: wl-2.121413, gl-0.358394]--[lr-0.000006]--[ETA-0:30:22]
2023.04.09-20:59:40:240:[step-32200/34000: 94.71%]--[loss-1.462098: wl-2.154268, gl-0.384964]--[lr-0.000006]--[ETA-0:29:21]
2023.04.09-21:01:16:340:[step-32300/34000: 95.00%]--[loss-1.868934: wl-2.319158, gl-0.709355]--[lr-0.000006]--[ETA-0:09:09]
End of epoch 95 / 100: train_loss: 1.393 	 time: 375 sec
Saving the model at the end of epoch 95, iters 32300
2023.04.09-21:03:34:100:[step-32400/34000: 95.29%]--[loss-1.358654: wl-2.040829, gl-0.338239]--[lr-0.000005]--[ETA-0:26:44]
2023.04.09-21:05:14:200:[step-32500/34000: 95.59%]--[loss-1.403331: wl-2.157747, gl-0.324458]--[lr-0.000005]--[ETA-0:25:50]
2023.04.09-21:06:53:300:[step-32600/34000: 95.88%]--[loss-1.375693: wl-2.043219, gl-0.354083]--[lr-0.000005]--[ETA-0:22:51]
End of epoch 96 / 100: train_loss: 1.392 	 time: 374 sec
2023.04.09-21:09:09:60:[step-32700/34000: 96.18%]--[loss-1.379967: wl-2.106193, gl-0.326871]--[lr-0.000004]--[ETA-0:21:37]
2023.04.09-21:10:49:160:[step-32800/34000: 96.47%]--[loss-1.383437: wl-2.089869, gl-0.338502]--[lr-0.000004]--[ETA-0:19:32]
2023.04.09-21:12:27:260:[step-32900/34000: 96.76%]--[loss-1.392010: wl-2.048352, gl-0.367834]--[lr-0.000004]--[ETA-0:17:52]
End of epoch 97 / 100: train_loss: 1.390 	 time: 373 sec
2023.04.09-21:14:43:20:[step-33000/34000: 97.06%]--[loss-1.443188: wl-2.203383, gl-0.341497]--[lr-0.000003]--[ETA-0:16:00]
2023.04.09-21:16:23:120:[step-33100/34000: 97.35%]--[loss-1.403514: wl-2.055003, gl-0.376012]--[lr-0.000003]--[ETA-0:15:04]
2023.04.09-21:18:03:220:[step-33200/34000: 97.65%]--[loss-1.349186: wl-2.056955, gl-0.320709]--[lr-0.000003]--[ETA-0:13:27]
2023.04.09-21:19:42:320:[step-33300/34000: 97.94%]--[loss-1.406682: wl-2.080993, gl-0.366185]--[lr-0.000003]--[ETA-0:10:59]
End of epoch 98 / 100: train_loss: 1.389 	 time: 377 sec
2023.04.09-21:22:05:80:[step-33400/34000: 98.24%]--[loss-1.464447: wl-2.177347, gl-0.375773]--[lr-0.000002]--[ETA-0:11:23]
2023.04.09-21:23:44:180:[step-33500/34000: 98.53%]--[loss-1.358175: wl-2.041653, gl-0.337348]--[lr-0.000002]--[ETA-0:07:58]
2023.04.09-21:25:22:280:[step-33600/34000: 98.82%]--[loss-1.361746: wl-2.065931, gl-0.328780]--[lr-0.000002]--[ETA-0:06:42]
End of epoch 99 / 100: train_loss: 1.387 	 time: 377 sec
2023.04.09-21:27:38:40:[step-33700/34000: 99.12%]--[loss-1.315126: wl-2.008681, gl-0.310786]--[lr-0.000001]--[ETA-0:04:52]
2023.04.09-21:29:18:140:[step-33800/34000: 99.41%]--[loss-1.447045: wl-2.133473, gl-0.380308]--[lr-0.000001]--[ETA-0:03:40]
2023.04.09-21:30:57:240:[step-33900/34000: 99.71%]--[loss-1.352592: wl-2.013389, gl-0.345897]--[lr-0.000001]--[ETA-0:01:38]
2023.04.09-21:32:35:340:[step-34000/34000: 100.00%]--[loss-1.478681: wl-2.147507, gl-0.404928]--[lr-0.000001]--[ETA-0:01:49]
End of epoch 100 / 100: train_loss: 1.387 	 time: 376 sec
Saving the model at the end of epoch 100, iters 34000
