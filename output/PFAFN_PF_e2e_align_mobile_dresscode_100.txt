/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/opt/conda/envs/srmgn/lib/python3.10/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/opt/conda/envs/srmgn/lib/python3.10/site-packages/cupy/cuda/compiler.py:464: UserWarning: cupy.cuda.compile_with_cache has been deprecated in CuPy v10, and will be removed in the future. Use cupy.RawModule or cupy.RawKernel instead.
  warnings.warn(
2023.04.11-10:07:23:100:[step-100/113100: 0.09%]--[loss-1.454968: wl-3.223871, gl-0.649000]--[lr: pb-0.000030, pf-0.000030]--[ETA-19:36:13]
2023.04.11-10:08:32:200:[step-200/113100: 0.18%]--[loss-1.432923: wl-3.045287, gl-0.671602]--[lr: pb-0.000030, pf-0.000030]--[ETA-18:38:16]
2023.04.11-10:09:40:300:[step-300/113100: 0.27%]--[loss-1.464007: wl-3.379549, gl-0.619120]--[lr: pb-0.000030, pf-0.000030]--[ETA-19:00:20]
2023.04.11-10:10:49:400:[step-400/113100: 0.35%]--[loss-1.412791: wl-3.348284, gl-0.575720]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:43:53]
2023.04.11-10:11:57:500:[step-500/113100: 0.44%]--[loss-1.501841: wl-3.525207, gl-0.620539]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:23:58]
2023.04.11-10:13:06:600:[step-600/113100: 0.53%]--[loss-1.473326: wl-3.302035, gl-0.647817]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:30:20]
2023.04.11-10:14:15:700:[step-700/113100: 0.62%]--[loss-1.370553: wl-3.345759, gl-0.534113]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:43:27]
2023.04.11-10:15:24:800:[step-800/113100: 0.71%]--[loss-1.421706: wl-3.214638, gl-0.618047]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:41:53]
2023.04.11-10:16:33:900:[step-900/113100: 0.80%]--[loss-1.349588: wl-3.114742, gl-0.570903]--[lr: pb-0.000030, pf-0.000030]--[ETA-18:06:16]
2023.04.11-10:17:41:1000:[step-1000/113100: 0.88%]--[loss-1.496608: wl-3.635835, gl-0.587649]--[lr: pb-0.000030, pf-0.000030]--[ETA-18:43:00]
2023.04.11-10:18:50:1100:[step-1100/113100: 0.97%]--[loss-1.282641: wl-3.022524, gl-0.527010]--[lr: pb-0.000030, pf-0.000030]--[ETA-18:31:39]
End of epoch 1 / 100: train_loss: 1.386 	 time: 784 sec
Saving the model at the end of epoch 1, iters 1131
2023.04.11-10:20:10:69:[step-1200/113100: 1.06%]--[loss-1.455651: wl-3.508116, gl-0.578622]--[lr: pb-0.000030, pf-0.000030]--[ETA-21:18:55]
2023.04.11-10:21:19:169:[step-1300/113100: 1.15%]--[loss-1.535244: wl-3.790485, gl-0.587623]--[lr: pb-0.000030, pf-0.000030]--[ETA-21:11:05]
2023.04.11-10:22:30:269:[step-1400/113100: 1.24%]--[loss-1.253132: wl-3.064622, gl-0.486977]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:36:18]
2023.04.11-10:23:40:369:[step-1500/113100: 1.33%]--[loss-1.550326: wl-3.556868, gl-0.661109]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:17:29]
2023.04.11-10:24:50:469:[step-1600/113100: 1.41%]--[loss-1.423439: wl-3.707174, gl-0.496646]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:15:23]
2023.04.11-10:25:59:569:[step-1700/113100: 1.50%]--[loss-1.314291: wl-3.112643, gl-0.536131]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:13:05]
2023.04.11-10:27:09:669:[step-1800/113100: 1.59%]--[loss-1.316352: wl-3.183678, gl-0.520433]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:22:43]
2023.04.11-10:28:19:769:[step-1900/113100: 1.68%]--[loss-1.310101: wl-3.434056, gl-0.451587]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:44:07]
2023.04.11-10:30:16:869:[step-2000/113100: 1.77%]--[loss-1.477438: wl-3.484111, gl-0.606410]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:46:56]
2023.04.11-10:32:11:969:[step-2100/113100: 1.86%]--[loss-1.376603: wl-3.217242, gl-0.572293]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:53:08]
2023.04.11-10:34:07:1069:[step-2200/113100: 1.95%]--[loss-1.364719: wl-3.111142, gl-0.586933]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:24:15]
End of epoch 2 / 100: train_loss: 1.356 	 time: 967 sec
Saving the model at the end of epoch 2, iters 2262
2023.04.11-10:36:12:38:[step-2300/113100: 2.03%]--[loss-1.252352: wl-3.051426, gl-0.489495]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:58:23]
2023.04.11-10:38:08:138:[step-2400/113100: 2.12%]--[loss-1.239517: wl-3.137402, gl-0.455167]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:59:22]
2023.04.11-10:40:05:238:[step-2500/113100: 2.21%]--[loss-1.291432: wl-3.138878, gl-0.506712]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:46:33]
2023.04.11-10:42:02:338:[step-2600/113100: 2.30%]--[loss-1.480114: wl-3.487389, gl-0.608267]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:02:56]
2023.04.11-10:43:59:438:[step-2700/113100: 2.39%]--[loss-1.312102: wl-3.268011, gl-0.495099]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:29:56]
2023.04.11-10:45:57:538:[step-2800/113100: 2.48%]--[loss-1.356193: wl-3.004328, gl-0.605111]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:41:02]
2023.04.11-10:47:54:638:[step-2900/113100: 2.56%]--[loss-1.442576: wl-3.242252, gl-0.632013]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 13:04:36]
2023.04.11-10:49:50:738:[step-3000/113100: 2.65%]--[loss-1.332794: wl-3.342725, gl-0.497113]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:13:57]
2023.04.11-10:51:47:838:[step-3100/113100: 2.74%]--[loss-1.224135: wl-2.986617, gl-0.477481]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:28:16]
2023.04.11-10:53:43:938:[step-3200/113100: 2.83%]--[loss-1.351166: wl-3.201245, gl-0.550854]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:03:15]
2023.04.11-10:55:40:1038:[step-3300/113100: 2.92%]--[loss-1.386275: wl-3.333807, gl-0.552824]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:01:47]
End of epoch 3 / 100: train_loss: 1.346 	 time: 1329 sec
Saving the model at the end of epoch 3, iters 3393
2023.04.11-10:57:46:7:[step-3400/113100: 3.01%]--[loss-1.488740: wl-3.609427, gl-0.586383]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:54:48]
2023.04.11-10:59:30:107:[step-3500/113100: 3.09%]--[loss-1.239314: wl-3.084175, gl-0.468270]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:53:43]
2023.04.11-11:01:13:207:[step-3600/113100: 3.18%]--[loss-1.468647: wl-3.335431, gl-0.634789]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:22:59]
2023.04.11-11:03:05:307:[step-3700/113100: 3.27%]--[loss-1.518515: wl-3.488371, gl-0.646422]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:48:03]
2023.04.11-11:05:01:407:[step-3800/113100: 3.36%]--[loss-1.161893: wl-2.951668, gl-0.423976]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:38:11]
2023.04.11-11:06:59:507:[step-3900/113100: 3.45%]--[loss-1.417099: wl-3.620244, gl-0.512039]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:52:55]
2023.04.11-11:08:56:607:[step-4000/113100: 3.54%]--[loss-1.337525: wl-3.142505, gl-0.551898]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:59:42]
2023.04.11-11:10:53:707:[step-4100/113100: 3.63%]--[loss-1.410899: wl-3.243099, gl-0.600124]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:51:52]
2023.04.11-11:12:50:807:[step-4200/113100: 3.71%]--[loss-1.404405: wl-3.449961, gl-0.541915]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:38:16]
2023.04.11-11:14:47:907:[step-4300/113100: 3.80%]--[loss-1.440716: wl-3.275506, gl-0.621839]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:38:18]
2023.04.11-11:16:44:1007:[step-4400/113100: 3.89%]--[loss-1.380744: wl-3.274787, gl-0.562047]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:57:05]
2023.04.11-11:18:41:1107:[step-4500/113100: 3.98%]--[loss-1.328947: wl-3.131110, gl-0.546170]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:48:17]
End of epoch 4 / 100: train_loss: 1.341 	 time: 1299 sec
Saving the model at the end of epoch 4, iters 4524
2023.04.11-11:20:47:76:[step-4600/113100: 4.07%]--[loss-1.182776: wl-3.000177, gl-0.432732]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:15:29]
2023.04.11-11:22:44:176:[step-4700/113100: 4.16%]--[loss-1.327577: wl-3.362927, gl-0.486845]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:49:50]
2023.04.11-11:24:42:276:[step-4800/113100: 4.24%]--[loss-1.323197: wl-3.156529, gl-0.534064]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:25:37]
2023.04.11-11:26:40:376:[step-4900/113100: 4.33%]--[loss-1.306961: wl-3.187951, gl-0.509973]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:27:44]
2023.04.11-11:28:36:476:[step-5000/113100: 4.42%]--[loss-1.514565: wl-3.575026, gl-0.620809]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:42:54]
2023.04.11-11:30:33:576:[step-5100/113100: 4.51%]--[loss-1.304114: wl-3.079651, gl-0.534201]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:07:28]
2023.04.11-11:32:30:676:[step-5200/113100: 4.60%]--[loss-1.435355: wl-3.348976, gl-0.598111]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:02:54]
2023.04.11-11:34:15:776:[step-5300/113100: 4.69%]--[loss-1.262964: wl-3.087602, gl-0.491064]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:40:13]
2023.04.11-11:35:57:876:[step-5400/113100: 4.77%]--[loss-1.449950: wl-3.748011, gl-0.512948]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:19:52]
2023.04.11-11:37:47:976:[step-5500/113100: 4.86%]--[loss-1.357678: wl-3.132145, gl-0.574642]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:26:13]
2023.04.11-11:39:41:1076:[step-5600/113100: 4.95%]--[loss-1.425324: wl-3.273288, gl-0.607002]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:43:31]
End of epoch 5 / 100: train_loss: 1.335 	 time: 1296 sec
Saving the model at the end of epoch 5, iters 5655
2023.04.11-11:41:48:45:[step-5700/113100: 5.04%]--[loss-1.111889: wl-2.851944, gl-0.398903]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:54:51]
2023.04.11-11:43:46:145:[step-5800/113100: 5.13%]--[loss-1.379670: wl-3.330244, gl-0.547109]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:28:42]
2023.04.11-11:45:43:245:[step-5900/113100: 5.22%]--[loss-1.278173: wl-3.082047, gl-0.507661]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:38:43]
2023.04.11-11:47:40:345:[step-6000/113100: 5.31%]--[loss-1.300415: wl-3.368352, gl-0.458327]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:02:19]
2023.04.11-11:49:37:445:[step-6100/113100: 5.39%]--[loss-1.235374: wl-3.054183, gl-0.471828]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:51:40]
2023.04.11-11:51:34:545:[step-6200/113100: 5.48%]--[loss-1.406346: wl-3.313887, gl-0.577874]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:37:58]
2023.04.11-11:53:31:645:[step-6300/113100: 5.57%]--[loss-1.363711: wl-3.162703, gl-0.573035]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:43:05]
2023.04.11-11:55:27:745:[step-6400/113100: 5.66%]--[loss-1.194810: wl-3.100792, gl-0.419612]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:28:28]
2023.04.11-11:57:24:845:[step-6500/113100: 5.75%]--[loss-1.386001: wl-3.281476, gl-0.565632]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:07:54]
2023.04.11-11:59:20:945:[step-6600/113100: 5.84%]--[loss-1.259104: wl-3.000110, gl-0.509077]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:58:11]
2023.04.11-12:01:17:1045:[step-6700/113100: 5.92%]--[loss-1.321420: wl-3.261873, gl-0.505951]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 12:14:13]
End of epoch 6 / 100: train_loss: 1.330 	 time: 1331 sec
Saving the model at the end of epoch 6, iters 6786
2023.04.11-12:03:23:14:[step-6800/113100: 6.01%]--[loss-1.316156: wl-3.175563, gl-0.522265]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:27:05]
2023.04.11-12:05:20:114:[step-6900/113100: 6.10%]--[loss-1.285816: wl-3.292828, gl-0.462609]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:15:38]
2023.04.11-12:07:17:214:[step-7000/113100: 6.19%]--[loss-1.175772: wl-2.942105, gl-0.440245]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:05:23]
2023.04.11-12:09:02:314:[step-7100/113100: 6.28%]--[loss-1.297434: wl-3.151032, gl-0.509676]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:06:38]
2023.04.11-12:10:43:414:[step-7200/113100: 6.37%]--[loss-1.341151: wl-3.199629, gl-0.541244]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:26:36]
2023.04.11-12:12:33:514:[step-7300/113100: 6.45%]--[loss-1.307103: wl-3.260724, gl-0.491922]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:20:09]
2023.04.11-12:14:30:614:[step-7400/113100: 6.54%]--[loss-1.338705: wl-3.205953, gl-0.537217]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:21:23]
2023.04.11-12:16:26:714:[step-7500/113100: 6.63%]--[loss-1.203498: wl-3.050651, gl-0.440836]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:09:19]
2023.04.11-12:18:23:814:[step-7600/113100: 6.72%]--[loss-1.262930: wl-3.067582, gl-0.496035]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:45:21]
2023.04.11-12:20:19:914:[step-7700/113100: 6.81%]--[loss-1.408502: wl-3.355919, gl-0.569522]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:13:37]
2023.04.11-12:22:16:1014:[step-7800/113100: 6.90%]--[loss-1.456236: wl-3.525477, gl-0.574867]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:20:40]
2023.04.11-12:24:13:1114:[step-7900/113100: 6.98%]--[loss-1.347284: wl-3.177063, gl-0.553018]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:10:58]
End of epoch 7 / 100: train_loss: 1.329 	 time: 1294 sec
Saving the model at the end of epoch 7, iters 7917
2023.04.11-12:26:19:83:[step-8000/113100: 7.07%]--[loss-1.397829: wl-3.464159, gl-0.531790]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:41:23]
2023.04.11-12:28:16:183:[step-8100/113100: 7.16%]--[loss-1.307012: wl-3.085621, gl-0.535607]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:34:28]
2023.04.11-12:30:13:283:[step-8200/113100: 7.25%]--[loss-1.420839: wl-3.378025, gl-0.576333]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 11:31:35]
2023.04.11-12:32:09:383:[step-8300/113100: 7.34%]--[loss-1.236945: wl-2.992984, gl-0.488699]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:00:06]
2023.04.11-12:34:06:483:[step-8400/113100: 7.43%]--[loss-1.177900: wl-3.104718, gl-0.401721]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:10:47]
2023.04.11-12:36:02:583:[step-8500/113100: 7.52%]--[loss-1.414795: wl-3.288291, gl-0.592723]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:31:25]
2023.04.11-12:37:59:683:[step-8600/113100: 7.60%]--[loss-1.298014: wl-3.195719, gl-0.499085]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:40:10]
2023.04.11-12:39:56:783:[step-8700/113100: 7.69%]--[loss-1.304053: wl-3.235278, gl-0.495234]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:55:25]
2023.04.11-12:41:52:883:[step-8800/113100: 7.78%]--[loss-1.308646: wl-3.175092, gl-0.514873]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:57:07]
2023.04.11-12:43:38:983:[step-8900/113100: 7.87%]--[loss-1.180560: wl-3.027887, gl-0.423588]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:01:10]
2023.04.11-12:45:18:1083:[step-9000/113100: 7.96%]--[loss-1.313542: wl-3.199419, gl-0.513687]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:05:29]
End of epoch 8 / 100: train_loss: 1.325 	 time: 1297 sec
Saving the model at the end of epoch 8, iters 9048
2023.04.11-12:47:17:52:[step-9100/113100: 8.05%]--[loss-1.229727: wl-3.048805, gl-0.467526]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:51:03]
2023.04.11-12:49:14:152:[step-9200/113100: 8.13%]--[loss-1.388996: wl-3.342994, gl-0.553247]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:37:04]
2023.04.11-12:51:11:252:[step-9300/113100: 8.22%]--[loss-1.161598: wl-2.896858, gl-0.437383]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:06:34]
2023.04.11-12:53:08:352:[step-9400/113100: 8.31%]--[loss-1.298713: wl-3.139477, gl-0.513844]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:52:38]
2023.04.11-12:55:04:452:[step-9500/113100: 8.40%]--[loss-1.323099: wl-3.412125, gl-0.470068]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:49:48]
2023.04.11-12:57:01:552:[step-9600/113100: 8.49%]--[loss-1.238955: wl-2.961488, gl-0.498583]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:34:03]
2023.04.11-12:58:57:652:[step-9700/113100: 8.58%]--[loss-1.286596: wl-3.183409, gl-0.490744]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:38:28]
2023.04.11-13:00:53:752:[step-9800/113100: 8.66%]--[loss-1.372382: wl-3.283674, gl-0.551464]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:34:03]
2023.04.11-13:02:50:852:[step-9900/113100: 8.75%]--[loss-1.291439: wl-3.248765, gl-0.479248]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:48:11]
2023.04.11-13:04:47:952:[step-10000/113100: 8.84%]--[loss-1.456217: wl-3.396354, gl-0.607128]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:51:10]
2023.04.11-13:06:44:1052:[step-10100/113100: 8.93%]--[loss-1.267003: wl-2.993911, gl-0.518525]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:24:16]
End of epoch 9 / 100: train_loss: 1.324 	 time: 1325 sec
Saving the model at the end of epoch 9, iters 10179
2023.04.11-13:08:50:21:[step-10200/113100: 9.02%]--[loss-1.307864: wl-3.116683, gl-0.528693]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:06:31]
2023.04.11-13:10:47:121:[step-10300/113100: 9.11%]--[loss-1.194217: wl-2.975839, gl-0.450257]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:00:04]
2023.04.11-13:12:44:221:[step-10400/113100: 9.20%]--[loss-1.409474: wl-3.561422, gl-0.519118]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:10:53]
2023.04.11-13:14:41:321:[step-10500/113100: 9.28%]--[loss-1.285217: wl-3.112238, gl-0.507158]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:10:21]
2023.04.11-13:16:38:421:[step-10600/113100: 9.37%]--[loss-1.217475: wl-3.157592, gl-0.428077]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:36:45]
2023.04.11-13:18:23:521:[step-10700/113100: 9.46%]--[loss-1.155501: wl-2.936778, gl-0.421306]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:40:51]
2023.04.11-13:20:05:621:[step-10800/113100: 9.55%]--[loss-1.346972: wl-3.249952, gl-0.534484]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:04:58]
2023.04.11-13:21:56:721:[step-10900/113100: 9.64%]--[loss-1.266635: wl-3.154949, gl-0.477897]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:18:31]
2023.04.11-13:23:51:821:[step-11000/113100: 9.73%]--[loss-1.241643: wl-3.124932, gl-0.460410]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:49:33]
2023.04.11-13:25:48:921:[step-11100/113100: 9.81%]--[loss-1.343519: wl-3.293710, gl-0.520091]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:54:13]
2023.04.11-13:27:44:1021:[step-11200/113100: 9.90%]--[loss-1.218112: wl-3.061255, gl-0.452798]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:28:20]
2023.04.11-13:29:41:1121:[step-11300/113100: 9.99%]--[loss-1.232837: wl-3.135603, gl-0.448936]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:44:06]
End of epoch 10 / 100: train_loss: 1.320 	 time: 1295 sec
Saving the model at the end of epoch 10, iters 11310
2023.04.11-13:31:49:90:[step-11400/113100: 10.08%]--[loss-1.386837: wl-3.287880, gl-0.564867]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:00:09]
2023.04.11-13:33:47:190:[step-11500/113100: 10.17%]--[loss-1.237190: wl-3.129412, gl-0.454837]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 10:12:11]
2023.04.11-13:35:44:290:[step-11600/113100: 10.26%]--[loss-1.371352: wl-3.186761, gl-0.574662]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:03:47]
2023.04.11-13:37:41:390:[step-11700/113100: 10.34%]--[loss-1.319181: wl-3.150509, gl-0.531554]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:21:27]
2023.04.11-13:39:38:490:[step-11800/113100: 10.43%]--[loss-1.373645: wl-3.288123, gl-0.551615]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:34:01]
2023.04.11-13:41:35:590:[step-11900/113100: 10.52%]--[loss-1.200026: wl-3.019456, gl-0.445161]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:53:18]
2023.04.11-13:43:32:690:[step-12000/113100: 10.61%]--[loss-1.366891: wl-3.159060, gl-0.577126]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:15:30]
2023.04.11-13:45:29:790:[step-12100/113100: 10.70%]--[loss-1.356091: wl-3.209109, gl-0.553814]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:52:58]
2023.04.11-13:47:26:890:[step-12200/113100: 10.79%]--[loss-1.254018: wl-3.189392, gl-0.456670]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:49:06]
2023.04.11-13:49:23:990:[step-12300/113100: 10.88%]--[loss-1.326859: wl-3.221205, gl-0.521557]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:54:48]
2023.04.11-13:51:20:1090:[step-12400/113100: 10.96%]--[loss-1.278657: wl-3.173234, gl-0.485349]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:45:52]
End of epoch 11 / 100: train_loss: 1.318 	 time: 1334 sec
Saving the model at the end of epoch 11, iters 12441
2023.04.11-13:53:12:59:[step-12500/113100: 11.05%]--[loss-1.478410: wl-3.717139, gl-0.549125]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:20:17]
2023.04.11-13:54:57:159:[step-12600/113100: 11.14%]--[loss-1.254411: wl-3.218021, gl-0.449906]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:53:54]
2023.04.11-13:56:49:259:[step-12700/113100: 11.23%]--[loss-1.465148: wl-3.629985, gl-0.557652]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:26:12]
2023.04.11-13:58:46:359:[step-12800/113100: 11.32%]--[loss-1.229367: wl-3.132129, gl-0.446335]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:11:17]
2023.04.11-14:00:42:459:[step-12900/113100: 11.41%]--[loss-1.296758: wl-3.122210, gl-0.516206]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:23:02]
2023.04.11-14:02:39:559:[step-13000/113100: 11.49%]--[loss-1.375490: wl-3.303585, gl-0.549594]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:59:47]
2023.04.11-14:04:36:659:[step-13100/113100: 11.58%]--[loss-1.500079: wl-3.544466, gl-0.613963]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:34:56]
2023.04.11-14:06:33:759:[step-13200/113100: 11.67%]--[loss-1.341326: wl-3.262897, gl-0.525601]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:47:11]
2023.04.11-14:08:29:859:[step-13300/113100: 11.76%]--[loss-1.392749: wl-3.344820, gl-0.556544]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:21:04]
2023.04.11-14:10:25:959:[step-13400/113100: 11.85%]--[loss-1.332506: wl-3.202298, gl-0.531931]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:54:27]
2023.04.11-14:12:22:1059:[step-13500/113100: 11.94%]--[loss-1.479682: wl-3.654144, gl-0.566146]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:33:19]
End of epoch 12 / 100: train_loss: 1.318 	 time: 1298 sec
Saving the model at the end of epoch 12, iters 13572
2023.04.11-14:14:30:28:[step-13600/113100: 12.02%]--[loss-1.293287: wl-3.298038, gl-0.468778]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:55:48]
2023.04.11-14:16:26:128:[step-13700/113100: 12.11%]--[loss-1.504100: wl-3.535435, gl-0.620241]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:09:11]
2023.04.11-14:18:24:228:[step-13800/113100: 12.20%]--[loss-1.335968: wl-3.295067, gl-0.512202]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:37:24]
2023.04.11-14:20:21:328:[step-13900/113100: 12.29%]--[loss-1.213260: wl-3.091540, gl-0.440375]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:16:36]
2023.04.11-14:22:18:428:[step-14000/113100: 12.38%]--[loss-1.309677: wl-3.284952, gl-0.488439]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:00:00]
2023.04.11-14:24:15:528:[step-14100/113100: 12.47%]--[loss-1.287295: wl-3.305564, gl-0.460904]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:29:41]
2023.04.11-14:26:12:628:[step-14200/113100: 12.56%]--[loss-1.225754: wl-3.025170, gl-0.469461]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:40:44]
2023.04.11-14:27:53:728:[step-14300/113100: 12.64%]--[loss-1.153205: wl-2.917160, gl-0.423915]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:49:06]
2023.04.11-14:29:37:828:[step-14400/113100: 12.73%]--[loss-1.230517: wl-3.173784, gl-0.437071]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:29:58]
2023.04.11-14:31:31:928:[step-14500/113100: 12.82%]--[loss-1.218126: wl-2.939950, gl-0.483139]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:07:39]
2023.04.11-14:33:28:1028:[step-14600/113100: 12.91%]--[loss-1.339344: wl-3.232806, gl-0.531142]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:42:35]
2023.04.11-14:35:24:1128:[step-14700/113100: 13.00%]--[loss-1.370564: wl-3.272260, gl-0.552500]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:28:22]
End of epoch 13 / 100: train_loss: 1.314 	 time: 1300 sec
Saving the model at the end of epoch 13, iters 14703
2023.04.11-14:37:31:97:[step-14800/113100: 13.09%]--[loss-1.377825: wl-3.339482, gl-0.542955]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:24:27]
2023.04.11-14:39:27:197:[step-14900/113100: 13.17%]--[loss-1.330229: wl-3.529960, gl-0.447740]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:07:50]
2023.04.11-14:41:23:297:[step-15000/113100: 13.26%]--[loss-1.249445: wl-3.014459, gl-0.495831]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:01:46]
2023.04.11-14:43:21:397:[step-15100/113100: 13.35%]--[loss-1.369835: wl-3.387151, gl-0.523048]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:24:56]
2023.04.11-14:45:17:497:[step-15200/113100: 13.44%]--[loss-1.363716: wl-3.145607, gl-0.577314]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:54:15]
2023.04.11-14:47:14:597:[step-15300/113100: 13.53%]--[loss-1.296328: wl-3.145164, gl-0.510037]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:46:39]
2023.04.11-14:49:10:697:[step-15400/113100: 13.62%]--[loss-1.260516: wl-3.111477, gl-0.482647]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:37:56]
2023.04.11-14:51:07:797:[step-15500/113100: 13.70%]--[loss-1.357594: wl-3.443512, gl-0.496716]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 9:02:50]
2023.04.11-14:53:04:897:[step-15600/113100: 13.79%]--[loss-1.295536: wl-3.230510, gl-0.487908]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:43:16]
2023.04.11-14:55:00:997:[step-15700/113100: 13.88%]--[loss-1.257629: wl-3.208630, gl-0.455472]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:26:17]
2023.04.11-14:56:57:1097:[step-15800/113100: 13.97%]--[loss-1.265259: wl-3.002740, gl-0.514574]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:34:07]
End of epoch 14 / 100: train_loss: 1.312 	 time: 1328 sec
Saving the model at the end of epoch 14, iters 15834
2023.04.11-14:59:04:66:[step-15900/113100: 14.06%]--[loss-1.335716: wl-3.216511, gl-0.531588]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:00:47]
2023.04.11-15:01:01:166:[step-16000/113100: 14.15%]--[loss-1.174659: wl-2.890817, gl-0.451955]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:26:49]
2023.04.11-15:02:40:266:[step-16100/113100: 14.24%]--[loss-1.320658: wl-3.362769, gl-0.479966]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:57:52]
2023.04.11-15:04:25:366:[step-16200/113100: 14.32%]--[loss-1.179354: wl-2.996647, gl-0.430192]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:51:20]
2023.04.11-15:06:20:466:[step-16300/113100: 14.41%]--[loss-1.250909: wl-3.098906, gl-0.476183]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:54:00]
2023.04.11-15:08:17:566:[step-16400/113100: 14.50%]--[loss-1.342898: wl-3.244274, gl-0.531829]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:42:12]
2023.04.11-15:10:14:666:[step-16500/113100: 14.59%]--[loss-1.320900: wl-3.110752, gl-0.543212]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:45:23]
2023.04.11-15:12:11:766:[step-16600/113100: 14.68%]--[loss-1.425893: wl-3.287774, gl-0.603950]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:48:56]
2023.04.11-15:14:06:866:[step-16700/113100: 14.77%]--[loss-1.289010: wl-3.167054, gl-0.497247]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:50:00]
2023.04.11-15:16:03:966:[step-16800/113100: 14.85%]--[loss-1.403817: wl-3.233283, gl-0.595496]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:37:38]
2023.04.11-15:18:00:1066:[step-16900/113100: 14.94%]--[loss-1.425156: wl-3.483956, gl-0.554167]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:41:26]
End of epoch 15 / 100: train_loss: 1.309 	 time: 1298 sec
Saving the model at the end of epoch 15, iters 16965
2023.04.11-15:20:06:35:[step-17000/113100: 15.03%]--[loss-1.358945: wl-3.374140, gl-0.515410]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:15:07]
2023.04.11-15:22:04:135:[step-17100/113100: 15.12%]--[loss-1.343878: wl-3.589127, gl-0.446596]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:11:00]
2023.04.11-15:24:01:235:[step-17200/113100: 15.21%]--[loss-1.311539: wl-3.246773, gl-0.499845]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:33:56]
2023.04.11-15:25:58:335:[step-17300/113100: 15.30%]--[loss-1.378039: wl-3.593655, gl-0.479625]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:29:31]
2023.04.11-15:27:55:435:[step-17400/113100: 15.38%]--[loss-1.384666: wl-3.293827, gl-0.561209]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:06:08]
2023.04.11-15:29:50:535:[step-17500/113100: 15.47%]--[loss-1.473884: wl-3.566444, gl-0.582273]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:22:02]
2023.04.11-15:31:47:635:[step-17600/113100: 15.56%]--[loss-1.322846: wl-3.176617, gl-0.528692]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:34:18]
2023.04.11-15:33:44:735:[step-17700/113100: 15.65%]--[loss-1.389847: wl-3.438709, gl-0.530170]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 8:20:08]
2023.04.11-15:35:42:835:[step-17800/113100: 15.74%]--[loss-1.339138: wl-3.253002, gl-0.525888]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:52:49]
2023.04.11-15:37:19:935:[step-17900/113100: 15.83%]--[loss-1.365574: wl-3.297791, gl-0.541126]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:37:25]
2023.04.11-15:39:05:1035:[step-18000/113100: 15.92%]--[loss-1.222932: wl-3.029115, gl-0.465653]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:16:17]
End of epoch 16 / 100: train_loss: 1.307 	 time: 1300 sec
Saving the model at the end of epoch 16, iters 18096
2023.04.11-15:41:12:4:[step-18100/113100: 16.00%]--[loss-1.300039: wl-3.058221, gl-0.535483]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:13:57]
2023.04.11-15:43:10:104:[step-18200/113100: 16.09%]--[loss-1.455444: wl-3.665788, gl-0.538997]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:38:31]
2023.04.11-15:45:07:204:[step-18300/113100: 16.18%]--[loss-1.316864: wl-3.300807, gl-0.491662]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:32:13]
2023.04.11-15:47:05:304:[step-18400/113100: 16.27%]--[loss-1.220300: wl-3.111420, gl-0.442445]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:40:53]
2023.04.11-15:49:03:404:[step-18500/113100: 16.36%]--[loss-1.368244: wl-3.240681, gl-0.558074]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 7:15:51]
2023.04.11-15:51:00:504:[step-18600/113100: 16.45%]--[loss-1.427616: wl-3.506062, gl-0.551100]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:42:32]
2023.04.11-15:52:57:604:[step-18700/113100: 16.53%]--[loss-1.247754: wl-3.116030, gl-0.468747]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:27:37]
2023.04.11-15:54:54:704:[step-18800/113100: 16.62%]--[loss-1.155303: wl-3.023339, gl-0.399468]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:57:00]
2023.04.11-15:56:51:804:[step-18900/113100: 16.71%]--[loss-1.229900: wl-3.050165, gl-0.467359]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 6:33:03]
2023.04.11-15:58:43:904:[step-19000/113100: 16.80%]--[loss-1.160265: wl-2.832213, gl-0.452212]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:54:18]
2023.04.11-16:00:24:1004:[step-19100/113100: 16.89%]--[loss-1.267977: wl-3.235322, gl-0.459147]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:04:16]
2023.04.11-16:02:05:1104:[step-19200/113100: 16.98%]--[loss-1.350128: wl-3.241553, gl-0.539740]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:24:09]
End of epoch 17 / 100: train_loss: 1.306 	 time: 1295 sec
Saving the model at the end of epoch 17, iters 19227
2023.04.11-16:03:56:73:[step-19300/113100: 17.06%]--[loss-1.363699: wl-3.226602, gl-0.557049]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:42:32]
2023.04.11-16:05:38:173:[step-19400/113100: 17.15%]--[loss-1.317254: wl-3.163798, gl-0.526304]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:54:44]
2023.04.11-16:07:20:273:[step-19500/113100: 17.24%]--[loss-1.355740: wl-3.244666, gl-0.544573]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:06:50]
2023.04.11-16:08:54:373:[step-19600/113100: 17.33%]--[loss-1.079517: wl-2.824951, gl-0.373280]--[lr: pb-0.000030, pf-0.000030]--[ETA-19:33:38]
2023.04.11-16:10:20:473:[step-19700/113100: 17.42%]--[loss-1.296983: wl-3.191231, gl-0.499175]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:07:16]
2023.04.11-16:11:56:573:[step-19800/113100: 17.51%]--[loss-1.347520: wl-3.228622, gl-0.540365]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:56:15]
2023.04.11-16:13:34:673:[step-19900/113100: 17.60%]--[loss-1.167320: wl-3.051511, gl-0.404443]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:22:18]
2023.04.11-16:15:15:773:[step-20000/113100: 17.68%]--[loss-1.378015: wl-3.332023, gl-0.545009]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:50:18]
2023.04.11-16:16:56:873:[step-20100/113100: 17.77%]--[loss-1.390634: wl-3.111975, gl-0.612640]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:58:43]
2023.04.11-16:18:38:973:[step-20200/113100: 17.86%]--[loss-1.427784: wl-3.491561, gl-0.554893]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:31:04]
2023.04.11-16:20:18:1073:[step-20300/113100: 17.95%]--[loss-1.291115: wl-3.341252, gl-0.455802]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:11:00]
End of epoch 18 / 100: train_loss: 1.303 	 time: 1124 sec
Saving the model at the end of epoch 18, iters 20358
2023.04.11-16:22:09:42:[step-20400/113100: 18.04%]--[loss-1.475644: wl-3.506087, gl-0.599122]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:52:17]
2023.04.11-16:23:51:142:[step-20500/113100: 18.13%]--[loss-1.283024: wl-3.159518, gl-0.493145]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:31:53]
2023.04.11-16:25:32:242:[step-20600/113100: 18.21%]--[loss-1.286844: wl-3.287045, gl-0.465083]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:14:56]
2023.04.11-16:27:14:342:[step-20700/113100: 18.30%]--[loss-1.336642: wl-3.325914, gl-0.505164]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:44:31]
2023.04.11-16:28:55:442:[step-20800/113100: 18.39%]--[loss-1.310205: wl-3.268070, gl-0.493187]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:50:09]
2023.04.11-16:30:36:542:[step-20900/113100: 18.48%]--[loss-1.251999: wl-2.876484, gl-0.532878]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:50:45]
2023.04.11-16:32:17:642:[step-21000/113100: 18.57%]--[loss-1.217206: wl-3.172763, gl-0.424015]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:40:53]
2023.04.11-16:33:59:742:[step-21100/113100: 18.66%]--[loss-1.434861: wl-3.463726, gl-0.568930]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:32:26]
2023.04.11-16:35:40:842:[step-21200/113100: 18.74%]--[loss-1.434785: wl-3.650112, gl-0.522257]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:36:23]
2023.04.11-16:37:21:942:[step-21300/113100: 18.83%]--[loss-1.360617: wl-3.447543, gl-0.498731]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:03:14]
2023.04.11-16:38:45:1042:[step-21400/113100: 18.92%]--[loss-1.243666: wl-3.039146, gl-0.483880]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:16:26]
End of epoch 19 / 100: train_loss: 1.302 	 time: 1128 sec
Saving the model at the end of epoch 19, iters 21489
2023.04.11-16:40:28:11:[step-21500/113100: 19.01%]--[loss-1.353878: wl-3.280196, gl-0.533829]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:03]
2023.04.11-16:42:06:111:[step-21600/113100: 19.10%]--[loss-1.363552: wl-3.262570, gl-0.547909]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:43]
2023.04.11-16:43:47:211:[step-21700/113100: 19.19%]--[loss-1.329982: wl-3.229419, gl-0.522627]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:14:16]
2023.04.11-16:45:29:311:[step-21800/113100: 19.27%]--[loss-1.417570: wl-3.443798, gl-0.556621]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:48:55]
2023.04.11-16:47:10:411:[step-21900/113100: 19.36%]--[loss-1.307713: wl-3.159338, gl-0.517878]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:29:49]
2023.04.11-16:48:51:511:[step-22000/113100: 19.45%]--[loss-1.317270: wl-3.325373, gl-0.485927]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:29:26]
2023.04.11-16:50:32:611:[step-22100/113100: 19.54%]--[loss-1.246393: wl-3.257899, gl-0.431918]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:45:38]
2023.04.11-16:52:13:711:[step-22200/113100: 19.63%]--[loss-1.229609: wl-2.913562, gl-0.501218]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:47:35]
2023.04.11-16:53:54:811:[step-22300/113100: 19.72%]--[loss-1.266770: wl-3.096733, gl-0.492586]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:36:11]
2023.04.11-16:55:35:911:[step-22400/113100: 19.81%]--[loss-1.258677: wl-3.220055, gl-0.453663]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:34:30]
2023.04.11-16:57:15:1011:[step-22500/113100: 19.89%]--[loss-1.291360: wl-3.434429, gl-0.432753]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:39:11]
2023.04.11-16:58:56:1111:[step-22600/113100: 19.98%]--[loss-1.259242: wl-3.151828, gl-0.471285]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:44]
End of epoch 20 / 100: train_loss: 1.300 	 time: 1149 sec
Saving the model at the end of epoch 20, iters 22620
2023.04.11-17:00:48:80:[step-22700/113100: 20.07%]--[loss-1.341238: wl-3.249199, gl-0.528938]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:19:01]
2023.04.11-17:02:30:180:[step-22800/113100: 20.16%]--[loss-1.265121: wl-3.162564, gl-0.474480]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:15:19]
2023.04.11-17:04:11:280:[step-22900/113100: 20.25%]--[loss-1.100047: wl-2.862015, gl-0.384543]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:48:43]
2023.04.11-17:05:52:380:[step-23000/113100: 20.34%]--[loss-1.324636: wl-3.286876, gl-0.502917]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:23:55]
2023.04.11-17:07:19:480:[step-23100/113100: 20.42%]--[loss-1.291551: wl-3.069633, gl-0.524142]--[lr: pb-0.000030, pf-0.000030]--[ETA-21:18:18]
2023.04.11-17:08:50:580:[step-23200/113100: 20.51%]--[loss-1.384333: wl-3.352169, gl-0.546291]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:53:26]
2023.04.11-17:10:30:680:[step-23300/113100: 20.60%]--[loss-1.376364: wl-3.316584, gl-0.547218]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:11:31]
2023.04.11-17:12:10:780:[step-23400/113100: 20.69%]--[loss-1.187227: wl-2.911639, gl-0.459318]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:04]
2023.04.11-17:13:51:880:[step-23500/113100: 20.78%]--[loss-1.361743: wl-3.224426, gl-0.555637]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:48:07]
2023.04.11-17:15:32:980:[step-23600/113100: 20.87%]--[loss-1.209385: wl-3.117249, gl-0.430073]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:50:39]
2023.04.11-17:17:13:1080:[step-23700/113100: 20.95%]--[loss-1.286531: wl-3.052035, gl-0.523523]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:55:02]
End of epoch 21 / 100: train_loss: 1.298 	 time: 1127 sec
Saving the model at the end of epoch 21, iters 23751
2023.04.11-17:19:05:49:[step-23800/113100: 21.04%]--[loss-1.340749: wl-3.380234, gl-0.495690]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:39:09]
2023.04.11-17:20:47:149:[step-23900/113100: 21.13%]--[loss-1.155354: wl-2.901272, gl-0.430036]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:56:02]
2023.04.11-17:22:27:249:[step-24000/113100: 21.22%]--[loss-1.188812: wl-2.978223, gl-0.444256]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:44:32]
2023.04.11-17:24:08:349:[step-24100/113100: 21.31%]--[loss-1.317774: wl-3.212220, gl-0.514719]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:45:22]
2023.04.11-17:25:49:449:[step-24200/113100: 21.40%]--[loss-1.246955: wl-3.211653, gl-0.444042]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:57:58]
2023.04.11-17:27:29:549:[step-24300/113100: 21.49%]--[loss-1.270576: wl-3.100909, gl-0.495349]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:31:42]
2023.04.11-17:29:10:649:[step-24400/113100: 21.57%]--[loss-1.212103: wl-3.209186, gl-0.409806]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:49:40]
2023.04.11-17:30:50:749:[step-24500/113100: 21.66%]--[loss-1.254893: wl-3.183065, gl-0.459127]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:36:45]
2023.04.11-17:32:31:849:[step-24600/113100: 21.75%]--[loss-1.349413: wl-3.382529, gl-0.503780]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:57]
2023.04.11-17:34:11:949:[step-24700/113100: 21.84%]--[loss-1.272109: wl-3.191525, gl-0.474228]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:03:35]
2023.04.11-17:35:44:1049:[step-24800/113100: 21.93%]--[loss-1.381710: wl-3.447926, gl-0.519728]--[lr: pb-0.000030, pf-0.000030]--[ETA-19:27:24]
End of epoch 22 / 100: train_loss: 1.297 	 time: 1129 sec
Saving the model at the end of epoch 22, iters 24882
2023.04.11-17:37:23:18:[step-24900/113100: 22.02%]--[loss-1.256779: wl-3.146150, gl-0.470242]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:35:26]
2023.04.11-17:39:02:118:[step-25000/113100: 22.10%]--[loss-1.353637: wl-3.302573, gl-0.527994]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:25:33]
2023.04.11-17:40:43:218:[step-25100/113100: 22.19%]--[loss-1.276830: wl-2.969457, gl-0.534466]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:52:19]
2023.04.11-17:42:25:318:[step-25200/113100: 22.28%]--[loss-1.384735: wl-3.368876, gl-0.542516]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:03:37]
2023.04.11-17:44:05:418:[step-25300/113100: 22.37%]--[loss-1.263293: wl-3.246902, gl-0.451568]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:43:12]
2023.04.11-17:45:46:518:[step-25400/113100: 22.46%]--[loss-1.449749: wl-3.423269, gl-0.593931]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:54:46]
2023.04.11-17:47:27:618:[step-25500/113100: 22.55%]--[loss-1.294464: wl-3.297506, gl-0.470088]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:10:32]
2023.04.11-17:49:07:718:[step-25600/113100: 22.63%]--[loss-1.234244: wl-3.158088, gl-0.444722]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:12:26]
2023.04.11-17:50:47:818:[step-25700/113100: 22.72%]--[loss-1.336475: wl-3.357590, gl-0.497078]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:07:08]
2023.04.11-17:52:29:918:[step-25800/113100: 22.81%]--[loss-1.334831: wl-3.247348, gl-0.522994]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:30:21]
2023.04.11-17:54:09:1018:[step-25900/113100: 22.90%]--[loss-1.262305: wl-3.138345, gl-0.477718]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:49:49]
2023.04.11-17:55:49:1118:[step-26000/113100: 22.99%]--[loss-1.376259: wl-3.235651, gl-0.567346]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:12:00]
End of epoch 23 / 100: train_loss: 1.296 	 time: 1148 sec
Saving the model at the end of epoch 23, iters 26013
2023.04.11-17:57:42:87:[step-26100/113100: 23.08%]--[loss-1.181726: wl-2.942131, gl-0.446193]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:34:19]
2023.04.11-17:59:23:187:[step-26200/113100: 23.17%]--[loss-1.217555: wl-3.000814, gl-0.467352]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:54:30]
2023.04.11-18:01:04:287:[step-26300/113100: 23.25%]--[loss-1.285261: wl-3.303914, gl-0.459283]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:19:29]
2023.04.11-18:02:45:387:[step-26400/113100: 23.34%]--[loss-1.195045: wl-2.997109, gl-0.445768]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:45:20]
2023.04.11-18:04:19:487:[step-26500/113100: 23.43%]--[loss-1.274533: wl-3.242516, gl-0.463904]--[lr: pb-0.000030, pf-0.000030]--[ETA-18:28:06]
2023.04.11-18:05:44:587:[step-26600/113100: 23.52%]--[loss-1.191286: wl-3.209909, gl-0.388809]--[lr: pb-0.000030, pf-0.000030]--[ETA-21:46:14]
2023.04.11-18:07:21:687:[step-26700/113100: 23.61%]--[loss-1.339415: wl-3.282520, gl-0.518785]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:41:03]
2023.04.11-18:09:15:787:[step-26800/113100: 23.70%]--[loss-1.242709: wl-3.042283, gl-0.482138]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:33:48]
2023.04.11-18:11:11:887:[step-26900/113100: 23.78%]--[loss-1.283327: wl-3.282644, gl-0.462666]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:16:02]
2023.04.11-18:13:07:987:[step-27000/113100: 23.87%]--[loss-1.236649: wl-3.051122, gl-0.473868]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:34:21]
2023.04.11-18:15:05:1087:[step-27100/113100: 23.96%]--[loss-1.308632: wl-3.366149, gl-0.467095]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:01:42]
End of epoch 24 / 100: train_loss: 1.294 	 time: 1192 sec
Saving the model at the end of epoch 24, iters 27144
2023.04.11-18:17:12:56:[step-27200/113100: 24.05%]--[loss-1.280709: wl-3.051586, gl-0.517812]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:37:32]
2023.04.11-18:19:09:156:[step-27300/113100: 24.14%]--[loss-1.251691: wl-3.032872, gl-0.493473]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:04:31]
2023.04.11-18:21:07:256:[step-27400/113100: 24.23%]--[loss-1.242019: wl-3.181683, gl-0.446598]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:19:48]
2023.04.11-18:23:05:356:[step-27500/113100: 24.31%]--[loss-1.239619: wl-3.241686, gl-0.429197]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 5:48:52]
2023.04.11-18:25:02:456:[step-27600/113100: 24.40%]--[loss-1.403721: wl-3.382782, gl-0.558026]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:24:25]
2023.04.11-18:26:59:556:[step-27700/113100: 24.49%]--[loss-1.484380: wl-3.833095, gl-0.526106]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:25:16]
2023.04.11-18:28:56:656:[step-27800/113100: 24.58%]--[loss-1.354941: wl-3.303094, gl-0.529168]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:04:35]
2023.04.11-18:30:53:756:[step-27900/113100: 24.67%]--[loss-1.396302: wl-3.336178, gl-0.562257]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:04:23]
2023.04.11-18:32:50:856:[step-28000/113100: 24.76%]--[loss-1.256646: wl-3.204325, gl-0.455565]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:24:11]
2023.04.11-18:34:47:956:[step-28100/113100: 24.85%]--[loss-1.232039: wl-3.260208, gl-0.416987]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:12:06]
2023.04.11-18:36:43:1056:[step-28200/113100: 24.93%]--[loss-1.236773: wl-3.271697, gl-0.418849]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:35:58]
End of epoch 25 / 100: train_loss: 1.294 	 time: 1326 sec
Saving the model at the end of epoch 25, iters 28275
2023.04.11-18:38:39:25:[step-28300/113100: 25.02%]--[loss-1.240998: wl-3.114213, gl-0.462444]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:25:11]
2023.04.11-18:40:26:125:[step-28400/113100: 25.11%]--[loss-1.206686: wl-3.199447, gl-0.406824]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:29:24]
2023.04.11-18:42:22:225:[step-28500/113100: 25.20%]--[loss-1.294346: wl-3.121438, gl-0.513986]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:34:13]
2023.04.11-18:44:20:325:[step-28600/113100: 25.29%]--[loss-1.314267: wl-3.350151, gl-0.476729]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:21:05]
2023.04.11-18:46:18:425:[step-28700/113100: 25.38%]--[loss-1.363007: wl-3.230451, gl-0.555394]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:24:47]
2023.04.11-18:48:16:525:[step-28800/113100: 25.46%]--[loss-1.344278: wl-3.233921, gl-0.535798]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:43:31]
2023.04.11-18:50:12:625:[step-28900/113100: 25.55%]--[loss-1.417337: wl-3.469056, gl-0.550073]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:40:58]
2023.04.11-18:52:10:725:[step-29000/113100: 25.64%]--[loss-1.266015: wl-3.122746, gl-0.485328]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:14:21]
2023.04.11-18:54:07:825:[step-29100/113100: 25.73%]--[loss-1.322703: wl-3.105570, gl-0.546310]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:42:39]
2023.04.11-18:56:04:925:[step-29200/113100: 25.82%]--[loss-1.259115: wl-3.201286, gl-0.458793]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:00:23]
2023.04.11-18:58:01:1025:[step-29300/113100: 25.91%]--[loss-1.247308: wl-3.144070, gl-0.461290]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:24:33]
2023.04.11-18:59:58:1125:[step-29400/113100: 25.99%]--[loss-1.501749: wl-3.647620, gl-0.589844]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:08:47]
End of epoch 26 / 100: train_loss: 1.290 	 time: 1321 sec
Saving the model at the end of epoch 26, iters 29406
2023.04.11-19:02:06:94:[step-29500/113100: 26.08%]--[loss-1.356222: wl-3.199319, gl-0.556392]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:59:28]
2023.04.11-19:04:04:194:[step-29600/113100: 26.17%]--[loss-1.321881: wl-3.462177, gl-0.456337]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:05:44]
2023.04.11-19:06:02:294:[step-29700/113100: 26.26%]--[loss-1.384022: wl-3.410448, gl-0.531410]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:51:33]
2023.04.11-19:08:00:394:[step-29800/113100: 26.35%]--[loss-1.168135: wl-2.946034, gl-0.431626]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:22:48]
2023.04.11-19:09:57:494:[step-29900/113100: 26.44%]--[loss-1.231346: wl-3.098812, gl-0.456643]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:12:20]
2023.04.11-19:11:51:594:[step-30000/113100: 26.53%]--[loss-1.157758: wl-2.928466, gl-0.425641]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:46:17]
2023.04.11-19:13:29:694:[step-30100/113100: 26.61%]--[loss-1.246898: wl-3.150546, gl-0.459261]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:20:33]
2023.04.11-19:15:19:794:[step-30200/113100: 26.70%]--[loss-1.201859: wl-2.922769, gl-0.471167]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:25:59]
2023.04.11-19:17:15:894:[step-30300/113100: 26.79%]--[loss-1.325984: wl-3.303068, gl-0.500217]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:50:57]
2023.04.11-19:19:12:994:[step-30400/113100: 26.88%]--[loss-1.397744: wl-3.283741, gl-0.576809]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:04:50]
2023.04.11-19:21:09:1094:[step-30500/113100: 26.97%]--[loss-1.248026: wl-3.018918, gl-0.493296]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:08:18]
End of epoch 27 / 100: train_loss: 1.291 	 time: 1307 sec
Saving the model at the end of epoch 27, iters 30537
2023.04.11-19:23:18:63:[step-30600/113100: 27.06%]--[loss-1.347192: wl-3.137894, gl-0.562719]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:37:55]
2023.04.11-19:25:15:163:[step-30700/113100: 27.14%]--[loss-1.398992: wl-3.370246, gl-0.556430]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:27:35]
2023.04.11-19:27:13:263:[step-30800/113100: 27.23%]--[loss-1.303163: wl-3.153890, gl-0.514691]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:33:44]
2023.04.11-19:29:11:363:[step-30900/113100: 27.32%]--[loss-1.339577: wl-3.266813, gl-0.522874]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:40:07]
2023.04.11-19:31:07:463:[step-31000/113100: 27.41%]--[loss-1.332665: wl-3.256190, gl-0.518618]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 4:40:41]
2023.04.11-19:33:05:563:[step-31100/113100: 27.50%]--[loss-1.155847: wl-2.967604, gl-0.413946]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:57:18]
2023.04.11-19:35:02:663:[step-31200/113100: 27.59%]--[loss-1.267016: wl-3.229084, gl-0.459745]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:26:26]
2023.04.11-19:36:59:763:[step-31300/113100: 27.67%]--[loss-1.304490: wl-3.164419, gl-0.513385]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:46:50]
2023.04.11-19:38:56:863:[step-31400/113100: 27.76%]--[loss-1.270662: wl-3.169358, gl-0.478322]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:45:23]
2023.04.11-19:40:53:963:[step-31500/113100: 27.85%]--[loss-1.166726: wl-2.923490, gl-0.435854]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:41:03]
2023.04.11-19:42:50:1063:[step-31600/113100: 27.94%]--[loss-1.373026: wl-3.277070, gl-0.553758]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:52]
End of epoch 28 / 100: train_loss: 1.289 	 time: 1337 sec
Saving the model at the end of epoch 28, iters 31668
2023.04.11-19:44:58:32:[step-31700/113100: 28.03%]--[loss-1.315335: wl-3.454907, gl-0.451609]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:06:45]
2023.04.11-19:46:43:132:[step-31800/113100: 28.12%]--[loss-1.299846: wl-3.144281, gl-0.513776]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:36:47]
2023.04.11-19:48:28:232:[step-31900/113100: 28.21%]--[loss-1.305975: wl-3.195462, gl-0.507110]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:20:12]
2023.04.11-19:50:22:332:[step-32000/113100: 28.29%]--[loss-1.320175: wl-3.274098, gl-0.501650]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:11:13]
2023.04.11-19:52:20:432:[step-32100/113100: 28.38%]--[loss-1.222548: wl-3.029262, gl-0.465233]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:23:24]
2023.04.11-19:54:18:532:[step-32200/113100: 28.47%]--[loss-1.396507: wl-3.434515, gl-0.537878]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:59:05]
2023.04.11-19:56:15:632:[step-32300/113100: 28.56%]--[loss-1.403573: wl-3.617133, gl-0.499290]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:52:02]
2023.04.11-19:58:12:732:[step-32400/113100: 28.65%]--[loss-1.294329: wl-3.224791, gl-0.488131]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:06:51]
2023.04.11-20:00:09:832:[step-32500/113100: 28.74%]--[loss-1.124515: wl-2.892707, gl-0.401338]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:25:57]
2023.04.11-20:02:05:932:[step-32600/113100: 28.82%]--[loss-1.213856: wl-3.057309, gl-0.449528]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:56:29]
2023.04.11-20:04:02:1032:[step-32700/113100: 28.91%]--[loss-1.400790: wl-3.426742, gl-0.544105]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:43:53]
End of epoch 29 / 100: train_loss: 1.287 	 time: 1307 sec
Saving the model at the end of epoch 29, iters 32799
2023.04.11-20:06:11:1:[step-32800/113100: 29.00%]--[loss-1.250966: wl-3.207857, gl-0.449002]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 15:04:30]
2023.04.11-20:08:09:101:[step-32900/113100: 29.09%]--[loss-1.156319: wl-3.000196, gl-0.406270]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:46:00]
2023.04.11-20:10:06:201:[step-33000/113100: 29.18%]--[loss-1.305760: wl-3.070222, gl-0.538205]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:26:42]
2023.04.11-20:12:04:301:[step-33100/113100: 29.27%]--[loss-1.248101: wl-3.189175, gl-0.450807]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:47:25]
2023.04.11-20:14:02:401:[step-33200/113100: 29.35%]--[loss-1.253446: wl-3.240323, gl-0.443366]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:23:25]
2023.04.11-20:15:59:501:[step-33300/113100: 29.44%]--[loss-1.274148: wl-3.187224, gl-0.477342]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:03:42]
2023.04.11-20:17:57:601:[step-33400/113100: 29.53%]--[loss-1.235335: wl-3.044150, gl-0.474297]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:10:25]
2023.04.11-20:19:53:701:[step-33500/113100: 29.62%]--[loss-1.246934: wl-3.142217, gl-0.461380]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:14:20]
2023.04.11-20:21:31:801:[step-33600/113100: 29.71%]--[loss-1.305107: wl-3.233837, gl-0.496648]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:36:55]
2023.04.11-20:23:19:901:[step-33700/113100: 29.80%]--[loss-1.191825: wl-3.090611, gl-0.419173]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:10:16]
2023.04.11-20:25:11:1001:[step-33800/113100: 29.89%]--[loss-1.323188: wl-3.194042, gl-0.524677]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:58:11]
2023.04.11-20:27:08:1101:[step-33900/113100: 29.97%]--[loss-1.377463: wl-3.223913, gl-0.571485]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:24:00]
End of epoch 30 / 100: train_loss: 1.287 	 time: 1305 sec
Saving the model at the end of epoch 30, iters 33930
2023.04.11-20:29:17:70:[step-34000/113100: 30.06%]--[loss-1.218195: wl-3.196883, gl-0.418974]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:40:43]
2023.04.11-20:31:15:170:[step-34100/113100: 30.15%]--[loss-1.280548: wl-3.219136, gl-0.475764]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:15:45]
2023.04.11-20:33:13:270:[step-34200/113100: 30.24%]--[loss-1.355182: wl-3.404677, gl-0.504013]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:14:39]
2023.04.11-20:35:10:370:[step-34300/113100: 30.33%]--[loss-1.254847: wl-3.079083, gl-0.485076]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:37:46]
2023.04.11-20:37:07:470:[step-34400/113100: 30.42%]--[loss-1.171306: wl-2.938849, gl-0.436594]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:13:41]
2023.04.11-20:39:05:570:[step-34500/113100: 30.50%]--[loss-1.314387: wl-3.129667, gl-0.531971]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:51:13]
2023.04.11-20:41:02:670:[step-34600/113100: 30.59%]--[loss-1.301893: wl-3.242931, gl-0.491161]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:14:59]
2023.04.11-20:42:59:770:[step-34700/113100: 30.68%]--[loss-1.208332: wl-2.994129, gl-0.459800]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:12:17]
2023.04.11-20:44:56:870:[step-34800/113100: 30.77%]--[loss-1.203217: wl-3.133889, gl-0.419745]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:52:29]
2023.04.11-20:46:53:970:[step-34900/113100: 30.86%]--[loss-1.286667: wl-3.217951, gl-0.482179]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:10:26]
2023.04.11-20:48:50:1070:[step-35000/113100: 30.95%]--[loss-1.382580: wl-3.408903, gl-0.530354]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:36:01]
End of epoch 31 / 100: train_loss: 1.286 	 time: 1338 sec
Saving the model at the end of epoch 31, iters 35061
2023.04.11-20:50:58:39:[step-35100/113100: 31.03%]--[loss-1.216658: wl-3.174051, gl-0.423145]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 2:03:32]
2023.04.11-20:52:56:139:[step-35200/113100: 31.12%]--[loss-1.278427: wl-3.228303, gl-0.471351]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:53:30]
2023.04.11-20:54:48:239:[step-35300/113100: 31.21%]--[loss-1.349124: wl-3.347639, gl-0.512214]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:09:29]
2023.04.11-20:56:28:339:[step-35400/113100: 31.30%]--[loss-1.196273: wl-3.117842, gl-0.416813]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:08:00]
2023.04.11-20:58:20:439:[step-35500/113100: 31.39%]--[loss-1.253594: wl-3.262783, gl-0.437898]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:26:35]
2023.04.11-21:00:15:539:[step-35600/113100: 31.48%]--[loss-1.167727: wl-2.823983, gl-0.461731]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:42:09]
2023.04.11-21:02:12:639:[step-35700/113100: 31.56%]--[loss-1.227599: wl-3.155860, gl-0.438633]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:36:42]
2023.04.11-21:04:10:739:[step-35800/113100: 31.65%]--[loss-1.228227: wl-2.875734, gl-0.509294]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:29:21]
2023.04.11-21:06:06:839:[step-35900/113100: 31.74%]--[loss-1.151585: wl-3.092357, gl-0.378496]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:33:38]
2023.04.11-21:08:03:939:[step-36000/113100: 31.83%]--[loss-1.334291: wl-3.249012, gl-0.522039]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:31:42]
2023.04.11-21:10:01:1039:[step-36100/113100: 31.92%]--[loss-1.229689: wl-3.065711, gl-0.463261]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:39:57]
End of epoch 32 / 100: train_loss: 1.283 	 time: 1305 sec
Saving the model at the end of epoch 32, iters 36192
2023.04.11-21:12:09:8:[step-36200/113100: 32.01%]--[loss-1.259027: wl-3.072952, gl-0.490789]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:57:38]
2023.04.11-21:14:06:108:[step-36300/113100: 32.10%]--[loss-1.311098: wl-3.451877, gl-0.448128]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:13:59]
2023.04.11-21:16:03:208:[step-36400/113100: 32.18%]--[loss-1.183203: wl-3.050262, gl-0.420638]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:01:33]
2023.04.11-21:18:01:308:[step-36500/113100: 32.27%]--[loss-1.312395: wl-3.187594, gl-0.515497]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:05:15]
2023.04.11-21:19:58:408:[step-36600/113100: 32.36%]--[loss-1.287238: wl-3.219782, gl-0.482293]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:45:47]
2023.04.11-21:21:55:508:[step-36700/113100: 32.45%]--[loss-1.253437: wl-3.115459, gl-0.474572]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:23:30]
2023.04.11-21:23:52:608:[step-36800/113100: 32.54%]--[loss-1.313158: wl-3.347842, gl-0.476197]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:35:57]
2023.04.11-21:25:49:708:[step-36900/113100: 32.63%]--[loss-1.299651: wl-3.110160, gl-0.522111]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:23:46]
2023.04.11-21:27:46:808:[step-37000/113100: 32.71%]--[loss-1.214155: wl-2.965602, gl-0.472754]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:41:24]
2023.04.11-21:29:32:908:[step-37100/113100: 32.80%]--[loss-1.332947: wl-3.279871, gl-0.512979]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:22:01]
2023.04.11-21:31:15:1008:[step-37200/113100: 32.89%]--[loss-1.140715: wl-2.914792, gl-0.412017]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:03:34]
2023.04.11-21:33:06:1108:[step-37300/113100: 32.98%]--[loss-1.210523: wl-2.940552, gl-0.475385]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:43:59]
End of epoch 33 / 100: train_loss: 1.282 	 time: 1297 sec
Saving the model at the end of epoch 33, iters 37323
2023.04.11-21:34:54:77:[step-37400/113100: 33.07%]--[loss-1.450848: wl-3.634541, gl-0.542213]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:11:37]
2023.04.11-21:36:41:177:[step-37500/113100: 33.16%]--[loss-1.410838: wl-3.474001, gl-0.542338]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:20:35]
2023.04.11-21:38:35:277:[step-37600/113100: 33.24%]--[loss-1.140734: wl-2.968084, gl-0.398713]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:57:54]
2023.04.11-21:39:49:377:[step-37700/113100: 33.33%]--[loss-1.343124: wl-3.441944, gl-0.482638]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:52:23]
2023.04.11-21:41:00:477:[step-37800/113100: 33.42%]--[loss-1.321087: wl-3.358334, gl-0.481503]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:45:56]
2023.04.11-21:42:12:577:[step-37900/113100: 33.51%]--[loss-1.257642: wl-3.221098, gl-0.452367]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:01:02]
2023.04.11-21:43:23:677:[step-38000/113100: 33.60%]--[loss-1.212518: wl-3.092318, gl-0.439439]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:36:27]
2023.04.11-21:44:34:777:[step-38100/113100: 33.69%]--[loss-1.261093: wl-3.295282, gl-0.437272]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:06:51]
2023.04.11-21:45:46:877:[step-38200/113100: 33.78%]--[loss-1.600185: wl-3.803880, gl-0.649215]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:49:42]
2023.04.11-21:46:58:977:[step-38300/113100: 33.86%]--[loss-1.215105: wl-3.014480, gl-0.461485]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:34:50]
2023.04.11-21:48:10:1077:[step-38400/113100: 33.95%]--[loss-1.156090: wl-2.926970, gl-0.424347]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:24:56]
End of epoch 34 / 100: train_loss: 1.281 	 time: 922 sec
Saving the model at the end of epoch 34, iters 38454
2023.04.11-21:49:35:46:[step-38500/113100: 34.04%]--[loss-1.269967: wl-3.047769, gl-0.508025]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:30:45]
2023.04.11-21:50:48:146:[step-38600/113100: 34.13%]--[loss-1.289148: wl-3.096224, gl-0.515092]--[lr: pb-0.000030, pf-0.000030]--[ETA-16:06:53]
2023.04.11-21:52:00:246:[step-38700/113100: 34.22%]--[loss-1.251480: wl-3.142604, gl-0.465829]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:43:12]
2023.04.11-21:53:12:346:[step-38800/113100: 34.31%]--[loss-1.410991: wl-3.541282, gl-0.525671]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:53:56]
2023.04.11-21:54:25:446:[step-38900/113100: 34.39%]--[loss-1.352876: wl-3.367763, gl-0.510936]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:36:36]
2023.04.11-21:55:37:546:[step-39000/113100: 34.48%]--[loss-1.305356: wl-3.261372, gl-0.490013]--[lr: pb-0.000030, pf-0.000030]--[ETA-16:04:04]
2023.04.11-21:57:28:646:[step-39100/113100: 34.57%]--[loss-1.223968: wl-3.028966, gl-0.466727]--[lr: pb-0.000030, pf-0.000030]--[ETA-20:32:19]
2023.04.11-21:58:41:746:[step-39200/113100: 34.66%]--[loss-1.207178: wl-2.962023, gl-0.466672]--[lr: pb-0.000030, pf-0.000030]--[ETA-16:05:22]
2023.04.11-21:59:53:846:[step-39300/113100: 34.75%]--[loss-1.253805: wl-3.226527, gl-0.447173]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:49:30]
2023.04.11-22:01:04:946:[step-39400/113100: 34.84%]--[loss-1.302902: wl-3.297181, gl-0.478607]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:27:34]
2023.04.11-22:02:15:1046:[step-39500/113100: 34.92%]--[loss-1.210368: wl-3.137558, gl-0.425978]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:09:19]
End of epoch 35 / 100: train_loss: 1.278 	 time: 866 sec
Saving the model at the end of epoch 35, iters 39585
2023.04.11-22:03:39:15:[step-39600/113100: 35.01%]--[loss-1.224584: wl-3.168054, gl-0.432571]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:03:19]
2023.04.11-22:04:52:115:[step-39700/113100: 35.10%]--[loss-1.227636: wl-3.119498, gl-0.447762]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:37:25]
2023.04.11-22:06:06:215:[step-39800/113100: 35.19%]--[loss-1.287423: wl-3.268585, gl-0.470277]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:35:40]
2023.04.11-22:07:18:315:[step-39900/113100: 35.28%]--[loss-1.334944: wl-3.574909, gl-0.441217]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:25:32]
2023.04.11-22:08:52:415:[step-40000/113100: 35.37%]--[loss-1.476833: wl-3.795669, gl-0.527915]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:12:54]
2023.04.11-22:10:21:515:[step-40100/113100: 35.46%]--[loss-1.173036: wl-3.029790, gl-0.415588]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:18:34]
2023.04.11-22:11:33:615:[step-40200/113100: 35.54%]--[loss-1.227589: wl-3.212531, gl-0.424456]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:55:06]
2023.04.11-22:12:44:715:[step-40300/113100: 35.63%]--[loss-1.265802: wl-3.340273, gl-0.430733]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:49:38]
2023.04.11-22:13:56:815:[step-40400/113100: 35.72%]--[loss-1.362339: wl-3.335283, gl-0.528518]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:21:18]
2023.04.11-22:15:07:915:[step-40500/113100: 35.81%]--[loss-1.224782: wl-3.212895, gl-0.421558]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:35:46]
2023.04.11-22:16:19:1015:[step-40600/113100: 35.90%]--[loss-1.371936: wl-3.427161, gl-0.515145]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:49:29]
2023.04.11-22:17:30:1115:[step-40700/113100: 35.99%]--[loss-1.172105: wl-3.083384, gl-0.401258]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:48:00]
End of epoch 36 / 100: train_loss: 1.279 	 time: 864 sec
Saving the model at the end of epoch 36, iters 40716
2023.04.11-22:18:54:84:[step-40800/113100: 36.07%]--[loss-1.134059: wl-2.880057, gl-0.414045]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:21:41]
2023.04.11-22:20:24:184:[step-40900/113100: 36.16%]--[loss-1.192516: wl-2.994916, gl-0.443787]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:29:51]
2023.04.11-22:21:57:284:[step-41000/113100: 36.25%]--[loss-1.259313: wl-3.104810, gl-0.483110]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:04:50]
2023.04.11-22:23:10:384:[step-41100/113100: 36.34%]--[loss-1.262621: wl-3.154390, gl-0.474023]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:27:49]
2023.04.11-22:24:23:484:[step-41200/113100: 36.43%]--[loss-1.213972: wl-3.078447, gl-0.444361]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:09:29]
2023.04.11-22:25:35:584:[step-41300/113100: 36.52%]--[loss-1.218739: wl-3.112820, gl-0.440534]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:17:17]
2023.04.11-22:26:48:684:[step-41400/113100: 36.60%]--[loss-1.285757: wl-3.067461, gl-0.518892]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:29:37]
2023.04.11-22:28:00:784:[step-41500/113100: 36.69%]--[loss-1.213472: wl-3.091325, gl-0.440640]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:29:26]
2023.04.11-22:29:14:884:[step-41600/113100: 36.78%]--[loss-1.241032: wl-3.065779, gl-0.474587]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:07:50]
2023.04.11-22:30:27:984:[step-41700/113100: 36.87%]--[loss-1.354240: wl-3.228236, gl-0.547181]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:16:31]
2023.04.11-22:31:59:1084:[step-41800/113100: 36.96%]--[loss-1.380133: wl-3.388937, gl-0.532899]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:16:57]
End of epoch 37 / 100: train_loss: 1.277 	 time: 890 sec
Saving the model at the end of epoch 37, iters 41847
2023.04.11-22:33:38:53:[step-41900/113100: 37.05%]--[loss-1.237649: wl-3.155364, gl-0.448808]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:38:24]
2023.04.11-22:34:58:153:[step-42000/113100: 37.14%]--[loss-1.296752: wl-3.363198, gl-0.455952]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:45:20]
2023.04.11-22:36:12:253:[step-42100/113100: 37.22%]--[loss-1.392421: wl-3.412542, gl-0.539286]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:09:44]
2023.04.11-22:37:26:353:[step-42200/113100: 37.31%]--[loss-1.193871: wl-2.990618, gl-0.446216]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:10:04]
2023.04.11-22:38:40:453:[step-42300/113100: 37.40%]--[loss-1.236255: wl-3.050201, gl-0.473704]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:24:15]
2023.04.11-22:39:54:553:[step-42400/113100: 37.49%]--[loss-1.261250: wl-3.115979, gl-0.482256]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:08:45]
2023.04.11-22:41:07:653:[step-42500/113100: 37.58%]--[loss-1.257081: wl-3.077260, gl-0.487766]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:09:47]
2023.04.11-22:42:21:753:[step-42600/113100: 37.67%]--[loss-1.272880: wl-3.269067, gl-0.455613]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:00:34]
2023.04.11-22:43:58:853:[step-42700/113100: 37.75%]--[loss-1.251394: wl-3.147221, gl-0.464588]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:49:45]
2023.04.11-22:45:11:953:[step-42800/113100: 37.84%]--[loss-1.313878: wl-3.238352, gl-0.504290]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:43:26]
2023.04.11-22:46:46:1053:[step-42900/113100: 37.93%]--[loss-1.168979: wl-3.019415, gl-0.414126]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:06:30]
End of epoch 38 / 100: train_loss: 1.276 	 time: 911 sec
Saving the model at the end of epoch 38, iters 42978
2023.04.11-22:48:13:22:[step-43000/113100: 38.02%]--[loss-1.421192: wl-3.397046, gl-0.571931]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:21:42]
2023.04.11-22:49:27:122:[step-43100/113100: 38.11%]--[loss-1.273755: wl-3.236753, gl-0.464567]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:04:19]
2023.04.11-22:50:40:222:[step-43200/113100: 38.20%]--[loss-1.317234: wl-3.336277, gl-0.483165]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:33:39]
2023.04.11-22:51:54:322:[step-43300/113100: 38.28%]--[loss-1.344014: wl-3.313623, gl-0.515608]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:44:36]
2023.04.11-22:53:07:422:[step-43400/113100: 38.37%]--[loss-1.467445: wl-3.637908, gl-0.557968]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:39:19]
2023.04.11-22:54:23:522:[step-43500/113100: 38.46%]--[loss-1.299883: wl-3.049858, gl-0.537419]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:42:34]
2023.04.11-22:55:55:622:[step-43600/113100: 38.55%]--[loss-1.270102: wl-3.121304, gl-0.489776]--[lr: pb-0.000030, pf-0.000030]--[ETA-15:08:48]
2023.04.11-22:57:09:722:[step-43700/113100: 38.64%]--[loss-1.221391: wl-3.041051, gl-0.461129]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:59:05]
2023.04.11-22:58:41:822:[step-43800/113100: 38.73%]--[loss-1.298187: wl-3.274941, gl-0.479452]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 1:03:21]
2023.04.11-22:59:56:922:[step-43900/113100: 38.82%]--[loss-1.349545: wl-3.487824, gl-0.477589]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:00:51]
2023.04.11-23:01:10:1022:[step-44000/113100: 38.90%]--[loss-1.332640: wl-3.382515, gl-0.487012]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:24:12]
2023.04.11-23:02:22:1122:[step-44100/113100: 38.99%]--[loss-1.351590: wl-3.457080, gl-0.487320]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:04:25]
End of epoch 39 / 100: train_loss: 1.275 	 time: 885 sec
Saving the model at the end of epoch 39, iters 44109
2023.04.11-23:03:49:91:[step-44200/113100: 39.08%]--[loss-1.184277: wl-2.996549, gl-0.435139]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:26:14]
2023.04.11-23:05:02:191:[step-44300/113100: 39.17%]--[loss-1.313661: wl-3.203825, gl-0.512705]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:46:57]
2023.04.11-23:06:32:291:[step-44400/113100: 39.26%]--[loss-1.190035: wl-3.080701, gl-0.419859]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:29:40]
2023.04.11-23:07:50:391:[step-44500/113100: 39.35%]--[loss-1.355726: wl-3.547269, gl-0.468909]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:33:36]
2023.04.11-23:09:03:491:[step-44600/113100: 39.43%]--[loss-1.200543: wl-3.120206, gl-0.420492]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:48:17]
2023.04.11-23:10:15:591:[step-44700/113100: 39.52%]--[loss-1.212055: wl-3.245681, gl-0.400635]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:45:53]
2023.04.11-23:11:45:691:[step-44800/113100: 39.61%]--[loss-1.192250: wl-3.072465, gl-0.424134]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:49:56]
2023.04.11-23:12:57:791:[step-44900/113100: 39.70%]--[loss-1.284266: wl-3.155152, gl-0.495478]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:48:05]
2023.04.11-23:14:08:891:[step-45000/113100: 39.79%]--[loss-1.385942: wl-3.411269, gl-0.533125]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:55:09]
2023.04.11-23:15:21:991:[step-45100/113100: 39.88%]--[loss-1.323466: wl-3.315458, gl-0.494601]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:13:02]
2023.04.11-23:16:32:1091:[step-45200/113100: 39.96%]--[loss-1.219109: wl-3.096143, gl-0.445073]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:50:43]
End of epoch 40 / 100: train_loss: 1.273 	 time: 871 sec
Saving the model at the end of epoch 40, iters 45240
2023.04.11-23:18:17:60:[step-45300/113100: 40.05%]--[loss-1.548207: wl-3.936722, gl-0.564027]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 3:26:21]
2023.04.11-23:19:30:160:[step-45400/113100: 40.14%]--[loss-1.335367: wl-3.374005, gl-0.491866]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:19:27]
2023.04.11-23:20:44:260:[step-45500/113100: 40.23%]--[loss-1.314757: wl-3.241309, gl-0.504430]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:33:25]
2023.04.11-23:21:57:360:[step-45600/113100: 40.32%]--[loss-1.179214: wl-3.000701, gl-0.429039]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:20:31]
2023.04.11-23:23:28:460:[step-45700/113100: 40.41%]--[loss-1.273130: wl-3.036555, gl-0.513992]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:15:32]
2023.04.11-23:24:40:560:[step-45800/113100: 40.50%]--[loss-1.281190: wl-3.162594, gl-0.490541]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:48:40]
2023.04.11-23:25:52:660:[step-45900/113100: 40.58%]--[loss-1.248116: wl-3.079050, gl-0.478354]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:49:16]
2023.04.11-23:27:04:760:[step-46000/113100: 40.67%]--[loss-1.203724: wl-3.109687, gl-0.426302]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:02:17]
2023.04.11-23:28:16:860:[step-46100/113100: 40.76%]--[loss-1.216765: wl-3.148499, gl-0.429640]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:10:04]
2023.04.11-23:29:35:960:[step-46200/113100: 40.85%]--[loss-1.237915: wl-3.163407, gl-0.447063]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:02:34]
2023.04.11-23:30:58:1060:[step-46300/113100: 40.94%]--[loss-1.288775: wl-3.225125, gl-0.482494]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:56:08]
End of epoch 41 / 100: train_loss: 1.273 	 time: 887 sec
Saving the model at the end of epoch 41, iters 46371
2023.04.11-23:32:24:29:[step-46400/113100: 41.03%]--[loss-1.227539: wl-2.999070, gl-0.477772]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:10:10]
2023.04.11-23:33:37:129:[step-46500/113100: 41.11%]--[loss-1.184453: wl-2.952861, gl-0.446238]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:12:40]
2023.04.11-23:34:50:229:[step-46600/113100: 41.20%]--[loss-1.293490: wl-3.258336, gl-0.478906]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:43:08]
2023.04.11-23:36:24:329:[step-46700/113100: 41.29%]--[loss-1.209464: wl-3.027504, gl-0.452588]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:55:38]
2023.04.11-23:37:37:429:[step-46800/113100: 41.38%]--[loss-1.360188: wl-3.343968, gl-0.524196]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:56:52]
2023.04.11-23:38:49:529:[step-46900/113100: 41.47%]--[loss-1.280553: wl-3.352816, gl-0.442349]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:39:48]
2023.04.11-23:40:01:629:[step-47000/113100: 41.56%]--[loss-1.357346: wl-3.490309, gl-0.484769]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:02:13]
2023.04.11-23:41:23:729:[step-47100/113100: 41.64%]--[loss-1.388648: wl-3.376893, gl-0.544424]--[lr: pb-0.000030, pf-0.000030]--[ETA-1 day, 0:43:01]
2023.04.11-23:42:44:829:[step-47200/113100: 41.73%]--[loss-1.270815: wl-3.131704, gl-0.487889]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:12:05]
2023.04.11-23:43:56:929:[step-47300/113100: 41.82%]--[loss-1.190625: wl-3.049847, gl-0.428163]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:23:13]
2023.04.11-23:45:07:1029:[step-47400/113100: 41.91%]--[loss-1.277934: wl-3.172828, gl-0.484727]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:54:36]
2023.04.11-23:46:18:1129:[step-47500/113100: 42.00%]--[loss-1.385319: wl-3.495222, gl-0.511513]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:31:20]
End of epoch 42 / 100: train_loss: 1.273 	 time: 870 sec
Saving the model at the end of epoch 42, iters 47502
2023.04.11-23:48:03:98:[step-47600/113100: 42.09%]--[loss-1.281371: wl-3.263976, gl-0.465377]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:17:14]
2023.04.11-23:49:15:198:[step-47700/113100: 42.18%]--[loss-1.339807: wl-3.275627, gl-0.520900]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:03:33]
2023.04.11-23:50:28:298:[step-47800/113100: 42.26%]--[loss-1.233947: wl-3.072328, gl-0.465865]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:35:47]
2023.04.11-23:51:40:398:[step-47900/113100: 42.35%]--[loss-1.211792: wl-3.020401, gl-0.456692]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:11:08]
2023.04.11-23:53:12:498:[step-48000/113100: 42.44%]--[loss-1.214452: wl-3.121980, gl-0.433956]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:16:28]
2023.04.11-23:54:23:598:[step-48100/113100: 42.53%]--[loss-1.356466: wl-3.208893, gl-0.554243]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:39:44]
2023.04.11-23:55:35:698:[step-48200/113100: 42.62%]--[loss-1.238161: wl-3.148325, gl-0.451080]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:13:36]
2023.04.11-23:56:47:798:[step-48300/113100: 42.71%]--[loss-1.282718: wl-3.172446, gl-0.489606]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:23:24]
2023.04.11-23:57:59:898:[step-48400/113100: 42.79%]--[loss-1.317661: wl-3.369289, gl-0.475339]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:53:20]
2023.04.11-23:59:14:998:[step-48500/113100: 42.88%]--[loss-1.244362: wl-3.210555, gl-0.441723]--[lr: pb-0.000030, pf-0.000030]--[ETA-22:50:00]
2023.04.12-00:00:41:1098:[step-48600/113100: 42.97%]--[loss-1.268085: wl-3.204051, gl-0.467073]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:20:02]
End of epoch 43 / 100: train_loss: 1.271 	 time: 883 sec
Saving the model at the end of epoch 43, iters 48633
2023.04.12-00:02:05:67:[step-48700/113100: 43.06%]--[loss-1.196488: wl-2.919833, gl-0.466530]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:00:24]
2023.04.12-00:03:17:167:[step-48800/113100: 43.15%]--[loss-1.418165: wl-3.427340, gl-0.561330]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:34:14]
2023.04.12-00:04:48:267:[step-48900/113100: 43.24%]--[loss-1.160933: wl-2.982421, gl-0.415328]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:30:57]
2023.04.12-00:06:00:367:[step-49000/113100: 43.32%]--[loss-1.283616: wl-3.182231, gl-0.488058]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:41:49]
2023.04.12-00:07:13:467:[step-49100/113100: 43.41%]--[loss-1.289488: wl-3.262908, gl-0.473761]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:56:50]
2023.04.12-00:08:24:567:[step-49200/113100: 43.50%]--[loss-1.262515: wl-3.163113, gl-0.471737]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:44:59]
2023.04.12-00:09:35:667:[step-49300/113100: 43.59%]--[loss-1.231161: wl-3.098907, gl-0.456435]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:54:24]
2023.04.12-00:10:47:767:[step-49400/113100: 43.68%]--[loss-1.169790: wl-3.109732, gl-0.392357]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:01:27]
2023.04.12-00:12:17:867:[step-49500/113100: 43.77%]--[loss-1.279541: wl-3.115677, gl-0.500622]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:35:17]
2023.04.12-00:13:29:967:[step-49600/113100: 43.85%]--[loss-1.230806: wl-3.056986, gl-0.466559]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:49:17]
2023.04.12-00:14:40:1067:[step-49700/113100: 43.94%]--[loss-1.252701: wl-3.303133, gl-0.426918]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:24:22]
End of epoch 44 / 100: train_loss: 1.269 	 time: 866 sec
Saving the model at the end of epoch 44, iters 49764
2023.04.12-00:16:22:36:[step-49800/113100: 44.03%]--[loss-1.226364: wl-3.206150, gl-0.424827]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:23:39]
2023.04.12-00:17:34:136:[step-49900/113100: 44.12%]--[loss-1.237171: wl-3.288051, gl-0.415158]--[lr: pb-0.000030, pf-0.000030]--[ETA-14:07:12]
2023.04.12-00:18:46:236:[step-50000/113100: 44.21%]--[loss-1.279067: wl-3.239126, gl-0.469285]--[lr: pb-0.000030, pf-0.000030]--[ETA-16:05:07]
2023.04.12-00:19:59:336:[step-50100/113100: 44.30%]--[loss-1.177952: wl-2.948270, gl-0.440884]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:37:28]
2023.04.12-00:21:10:436:[step-50200/113100: 44.39%]--[loss-1.203545: wl-3.137039, gl-0.419285]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:50:02]
2023.04.12-00:22:23:536:[step-50300/113100: 44.47%]--[loss-1.309349: wl-3.357265, gl-0.470033]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:25:22]
2023.04.12-00:23:55:636:[step-50400/113100: 44.56%]--[loss-1.278034: wl-3.269845, gl-0.460573]--[lr: pb-0.000030, pf-0.000030]--[ETA-23:09:25]
2023.04.12-00:25:07:736:[step-50500/113100: 44.65%]--[loss-1.279462: wl-3.104449, gl-0.503350]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:26:44]
2023.04.12-00:26:20:836:[step-50600/113100: 44.74%]--[loss-1.284155: wl-3.244177, gl-0.473111]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:35:03]
2023.04.12-00:27:50:936:[step-50700/113100: 44.83%]--[loss-1.315531: wl-3.278329, gl-0.495948]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:32:37]
2023.04.12-00:29:02:1036:[step-50800/113100: 44.92%]--[loss-1.205466: wl-3.113252, gl-0.427153]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:54:38]
End of epoch 45 / 100: train_loss: 1.269 	 time: 879 sec
Saving the model at the end of epoch 45, iters 50895
2023.04.12-00:30:27:5:[step-50900/113100: 45.00%]--[loss-1.427510: wl-3.633518, gl-0.519131]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:24:58]
2023.04.12-00:31:40:105:[step-51000/113100: 45.09%]--[loss-1.258185: wl-3.247653, gl-0.446272]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:46:48]
2023.04.12-00:32:54:205:[step-51100/113100: 45.18%]--[loss-1.367131: wl-3.331205, gl-0.534330]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:30:32]
2023.04.12-00:34:07:305:[step-51200/113100: 45.27%]--[loss-1.204581: wl-3.164517, gl-0.413452]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:59:02]
2023.04.12-00:35:19:405:[step-51300/113100: 45.36%]--[loss-1.280148: wl-3.116325, gl-0.501067]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:33:09]
2023.04.12-00:36:52:505:[step-51400/113100: 45.45%]--[loss-1.293571: wl-3.484705, gl-0.422395]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:49:00]
2023.04.12-00:38:03:605:[step-51500/113100: 45.53%]--[loss-1.387936: wl-3.456754, gl-0.523748]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:58:07]
2023.04.12-00:39:30:705:[step-51600/113100: 45.62%]--[loss-1.205908: wl-2.936427, gl-0.471802]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:02:31]
2023.04.12-00:40:47:805:[step-51700/113100: 45.71%]--[loss-1.167905: wl-3.004740, gl-0.416720]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:35:17]
2023.04.12-00:41:58:905:[step-51800/113100: 45.80%]--[loss-1.388831: wl-3.526081, gl-0.507311]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:56:40]
2023.04.12-00:43:10:1005:[step-51900/113100: 45.89%]--[loss-1.231442: wl-3.268047, gl-0.414430]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:22:49]
2023.04.12-00:44:21:1105:[step-52000/113100: 45.98%]--[loss-1.270346: wl-3.238844, gl-0.460635]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:50:33]
End of epoch 46 / 100: train_loss: 1.267 	 time: 869 sec
Saving the model at the end of epoch 46, iters 52026
2023.04.12-00:45:47:74:[step-52100/113100: 46.07%]--[loss-1.351727: wl-3.492685, gl-0.478556]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:05:44]
2023.04.12-00:47:00:174:[step-52200/113100: 46.15%]--[loss-1.230275: wl-3.104257, gl-0.454211]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:32:50]
2023.04.12-00:48:22:274:[step-52300/113100: 46.24%]--[loss-1.218449: wl-3.241035, gl-0.408191]--[lr: pb-0.000030, pf-0.000030]--[ETA-16:03:09]
2023.04.12-00:49:44:374:[step-52400/113100: 46.33%]--[loss-1.296129: wl-3.156200, gl-0.507079]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:59:41]
2023.04.12-00:51:17:474:[step-52500/113100: 46.42%]--[loss-1.503295: wl-3.698418, gl-0.578690]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:09:15]
2023.04.12-00:52:29:574:[step-52600/113100: 46.51%]--[loss-1.258782: wl-3.109843, gl-0.481321]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:59:42]
2023.04.12-00:53:42:674:[step-52700/113100: 46.60%]--[loss-1.240541: wl-3.144324, gl-0.454460]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:17:17]
2023.04.12-00:54:54:774:[step-52800/113100: 46.68%]--[loss-1.293462: wl-3.241812, gl-0.483009]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:43:16]
2023.04.12-00:56:06:874:[step-52900/113100: 46.77%]--[loss-1.248286: wl-3.044502, gl-0.487161]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:09:25]
2023.04.12-00:57:18:974:[step-53000/113100: 46.86%]--[loss-1.296676: wl-3.214248, gl-0.493114]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:21:39]
2023.04.12-00:58:29:1074:[step-53100/113100: 46.95%]--[loss-1.215474: wl-3.037963, gl-0.455983]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:34:14]
End of epoch 47 / 100: train_loss: 1.265 	 time: 869 sec
Saving the model at the end of epoch 47, iters 53157
2023.04.12-00:59:53:43:[step-53200/113100: 47.04%]--[loss-1.349391: wl-3.346251, gl-0.512829]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:40:59]
2023.04.12-01:01:20:143:[step-53300/113100: 47.13%]--[loss-1.318751: wl-3.133330, gl-0.535418]--[lr: pb-0.000030, pf-0.000030]--[ETA-13:05:47]
2023.04.12-01:02:49:243:[step-53400/113100: 47.21%]--[loss-1.378892: wl-3.265282, gl-0.562572]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:59:30]
2023.04.12-01:04:00:343:[step-53500/113100: 47.30%]--[loss-1.187740: wl-3.090011, gl-0.415237]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:34:39]
2023.04.12-01:05:11:443:[step-53600/113100: 47.39%]--[loss-1.175614: wl-3.058239, gl-0.411054]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:21:31]
2023.04.12-01:06:22:543:[step-53700/113100: 47.48%]--[loss-1.139179: wl-2.937895, gl-0.404705]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:56:07]
2023.04.12-01:07:32:643:[step-53800/113100: 47.57%]--[loss-1.334956: wl-3.299462, gl-0.510091]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:53:09]
2023.04.12-01:08:43:743:[step-53900/113100: 47.66%]--[loss-1.368138: wl-3.536498, gl-0.484014]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:25:29]
2023.04.12-01:09:53:843:[step-54000/113100: 47.75%]--[loss-1.139797: wl-2.941813, gl-0.404343]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:37:25]
2023.04.12-01:11:03:943:[step-54100/113100: 47.83%]--[loss-1.301652: wl-3.053728, gl-0.538220]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:41:49]
2023.04.12-01:12:27:1043:[step-54200/113100: 47.92%]--[loss-1.250795: wl-3.068257, gl-0.483731]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:03:20]
End of epoch 48 / 100: train_loss: 1.265 	 time: 858 sec
Saving the model at the end of epoch 48, iters 54288
2023.04.12-01:13:50:12:[step-54300/113100: 48.01%]--[loss-1.423112: wl-3.635862, gl-0.514147]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:57:54]
2023.04.12-01:15:01:112:[step-54400/113100: 48.10%]--[loss-1.283526: wl-3.375347, gl-0.439689]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:25:01]
2023.04.12-01:16:12:212:[step-54500/113100: 48.19%]--[loss-1.259895: wl-3.066489, gl-0.493273]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:42:36]
2023.04.12-01:17:23:312:[step-54600/113100: 48.28%]--[loss-1.185129: wl-3.121707, gl-0.404703]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:23:07]
2023.04.12-01:18:35:412:[step-54700/113100: 48.36%]--[loss-1.211232: wl-3.058868, gl-0.446515]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:10:48]
2023.04.12-01:19:45:512:[step-54800/113100: 48.45%]--[loss-1.262079: wl-3.102339, gl-0.486494]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:09:57]
2023.04.12-01:21:10:612:[step-54900/113100: 48.54%]--[loss-1.238197: wl-3.213716, gl-0.434768]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:47:51]
2023.04.12-01:22:20:712:[step-55000/113100: 48.63%]--[loss-1.337130: wl-3.584141, gl-0.441095]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:03:51]
2023.04.12-01:23:30:812:[step-55100/113100: 48.72%]--[loss-1.365986: wl-3.458015, gl-0.501482]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:15:46]
2023.04.12-01:24:39:912:[step-55200/113100: 48.81%]--[loss-1.241979: wl-3.101749, gl-0.466542]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:04:50]
2023.04.12-01:25:49:1012:[step-55300/113100: 48.89%]--[loss-1.342353: wl-3.384989, gl-0.496106]--[lr: pb-0.000030, pf-0.000030]--[ETA-8:51:11]
2023.04.12-01:26:59:1112:[step-55400/113100: 48.98%]--[loss-1.335508: wl-3.285032, gl-0.514250]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:05:41]
End of epoch 49 / 100: train_loss: 1.264 	 time: 822 sec
Saving the model at the end of epoch 49, iters 55419
2023.04.12-01:28:23:81:[step-55500/113100: 49.07%]--[loss-1.453530: wl-3.432755, gl-0.595341]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:21:24]
2023.04.12-01:29:37:181:[step-55600/113100: 49.16%]--[loss-1.426088: wl-3.356326, gl-0.587007]--[lr: pb-0.000030, pf-0.000030]--[ETA-12:19:00]
2023.04.12-01:30:59:281:[step-55700/113100: 49.25%]--[loss-1.364515: wl-3.138658, gl-0.579851]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:58:31]
2023.04.12-01:32:10:381:[step-55800/113100: 49.34%]--[loss-1.362016: wl-3.077506, gl-0.592640]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:33:03]
2023.04.12-01:33:20:481:[step-55900/113100: 49.43%]--[loss-1.340409: wl-3.109898, gl-0.562934]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:01:36]
2023.04.12-01:34:30:581:[step-56000/113100: 49.51%]--[loss-1.374884: wl-3.135989, gl-0.590887]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:28:09]
2023.04.12-01:35:40:681:[step-56100/113100: 49.60%]--[loss-1.293939: wl-3.080171, gl-0.523896]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:06:53]
2023.04.12-01:36:50:781:[step-56200/113100: 49.69%]--[loss-1.356797: wl-3.304551, gl-0.530659]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:11:45]
2023.04.12-01:38:00:881:[step-56300/113100: 49.78%]--[loss-1.486561: wl-3.527107, gl-0.604784]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:32:22]
2023.04.12-01:39:27:981:[step-56400/113100: 49.87%]--[loss-1.356354: wl-3.191350, gl-0.558517]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:49:05]
2023.04.12-01:40:37:1081:[step-56500/113100: 49.96%]--[loss-1.583316: wl-3.641750, gl-0.672878]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:54:58]
End of epoch 50 / 100: train_loss: 1.369 	 time: 839 sec
Saving the model at the end of epoch 50, iters 56550
2023.04.12-01:41:59:50:[step-56600/113100: 50.04%]--[loss-1.274985: wl-2.946543, gl-0.538349]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:09:50]
2023.04.12-01:43:09:150:[step-56700/113100: 50.13%]--[loss-1.463905: wl-3.151682, gl-0.675985]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:25:26]
2023.04.12-01:44:20:250:[step-56800/113100: 50.22%]--[loss-1.387670: wl-3.022112, gl-0.632142]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:25:05]
2023.04.12-01:45:30:350:[step-56900/113100: 50.31%]--[loss-1.294948: wl-3.162686, gl-0.504276]--[lr: pb-0.000030, pf-0.000030]--[ETA-9:07:11]
2023.04.12-01:46:42:450:[step-57000/113100: 50.40%]--[loss-1.380261: wl-3.240235, gl-0.570202]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:49:41]
2023.04.12-01:47:59:550:[step-57100/113100: 50.49%]--[loss-1.344983: wl-3.205733, gl-0.543550]--[lr: pb-0.000030, pf-0.000030]--[ETA-17:48:25]
2023.04.12-01:49:17:650:[step-57200/113100: 50.57%]--[loss-1.335703: wl-3.117392, gl-0.556355]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:36:39]
2023.04.12-01:50:26:750:[step-57300/113100: 50.66%]--[loss-1.391083: wl-3.431439, gl-0.533223]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:27:19]
2023.04.12-01:51:36:850:[step-57400/113100: 50.75%]--[loss-1.316804: wl-2.962339, gl-0.576220]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:38:33]
2023.04.12-01:52:47:950:[step-57500/113100: 50.84%]--[loss-1.421479: wl-3.343055, gl-0.585715]--[lr: pb-0.000030, pf-0.000030]--[ETA-11:39:37]
2023.04.12-01:53:57:1050:[step-57600/113100: 50.93%]--[loss-1.225762: wl-3.016887, gl-0.471541]--[lr: pb-0.000030, pf-0.000030]--[ETA-10:59:07]
End of epoch 51 / 100: train_loss: 1.362 	 time: 820 sec
Saving the model at the end of epoch 51, iters 57681
2023.04.12-01:55:17:19:[step-57700/113100: 51.02%]--[loss-1.293366: wl-2.984713, gl-0.547187]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:57:34]
2023.04.12-01:56:28:119:[step-57800/113100: 51.11%]--[loss-1.326804: wl-3.274688, gl-0.508132]--[lr: pb-0.000030, pf-0.000029]--[ETA-9:19:06]
2023.04.12-01:57:54:219:[step-57900/113100: 51.19%]--[loss-1.363668: wl-3.180084, gl-0.568647]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:21:35]
2023.04.12-01:59:05:319:[step-58000/113100: 51.28%]--[loss-1.288949: wl-3.118432, gl-0.509341]--[lr: pb-0.000030, pf-0.000029]--[ETA-12:18:51]
2023.04.12-02:00:17:419:[step-58100/113100: 51.37%]--[loss-1.473357: wl-3.360886, gl-0.633135]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:44:18]
2023.04.12-02:01:27:519:[step-58200/113100: 51.46%]--[loss-1.457053: wl-3.426505, gl-0.600427]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:52:47]
2023.04.12-02:02:37:619:[step-58300/113100: 51.55%]--[loss-1.408777: wl-3.257497, gl-0.594403]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:38:14]
2023.04.12-02:03:47:719:[step-58400/113100: 51.64%]--[loss-1.470175: wl-3.299849, gl-0.645212]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:19:13]
2023.04.12-02:04:57:819:[step-58500/113100: 51.72%]--[loss-1.324613: wl-3.080094, gl-0.554589]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:08:11]
2023.04.12-02:06:22:919:[step-58600/113100: 51.81%]--[loss-1.362246: wl-3.182452, gl-0.566633]--[lr: pb-0.000030, pf-0.000029]--[ETA-15:48:30]
2023.04.12-02:07:34:1019:[step-58700/113100: 51.90%]--[loss-1.514588: wl-3.364850, gl-0.673375]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:33:17]
2023.04.12-02:08:44:1119:[step-58800/113100: 51.99%]--[loss-1.253596: wl-2.991271, gl-0.505778]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:05:59]
End of epoch 52 / 100: train_loss: 1.362 	 time: 838 sec
Saving the model at the end of epoch 52, iters 58812
2023.04.12-02:10:07:88:[step-58900/113100: 52.08%]--[loss-1.267510: wl-3.149628, gl-0.480103]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:37:36]
2023.04.12-02:11:17:188:[step-59000/113100: 52.17%]--[loss-1.284200: wl-3.234943, gl-0.475464]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:47:28]
2023.04.12-02:12:27:288:[step-59100/113100: 52.25%]--[loss-1.318491: wl-3.240756, gl-0.508302]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:19:26]
2023.04.12-02:13:38:388:[step-59200/113100: 52.34%]--[loss-1.256328: wl-2.968645, gl-0.514167]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:27:25]
2023.04.12-02:14:48:488:[step-59300/113100: 52.43%]--[loss-1.247201: wl-3.045902, gl-0.485725]--[lr: pb-0.000030, pf-0.000029]--[ETA-11:30:14]
2023.04.12-02:16:14:588:[step-59400/113100: 52.52%]--[loss-1.597769: wl-3.579450, gl-0.702907]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:15:56]
2023.04.12-02:17:24:688:[step-59500/113100: 52.61%]--[loss-1.338544: wl-3.041195, gl-0.578245]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:53:58]
2023.04.12-02:18:34:788:[step-59600/113100: 52.70%]--[loss-1.315238: wl-3.066715, gl-0.548559]--[lr: pb-0.000030, pf-0.000029]--[ETA-10:52:26]
2023.04.12-02:19:44:888:[step-59700/113100: 52.79%]--[loss-1.460065: wl-3.288798, gl-0.637866]--[lr: pb-0.000030, pf-0.000029]--[ETA-9:08:14]
2023.04.12-02:20:54:988:[step-59800/113100: 52.87%]--[loss-1.331077: wl-2.952897, gl-0.592853]--[lr: pb-0.000030, pf-0.000029]--[ETA-8:19:07]
2023.04.12-02:22:04:1088:[step-59900/113100: 52.96%]--[loss-1.470093: wl-3.380812, gl-0.624890]--[lr: pb-0.000030, pf-0.000029]--[ETA-9:09:20]
End of epoch 53 / 100: train_loss: 1.360 	 time: 822 sec
Saving the model at the end of epoch 53, iters 59943
2023.04.12-02:23:28:57:[step-60000/113100: 53.05%]--[loss-1.516256: wl-3.261459, gl-0.700891]--[lr: pb-0.000030, pf-0.000028]--[ETA-11:47:01]
2023.04.12-02:24:55:157:[step-60100/113100: 53.14%]--[loss-1.263440: wl-3.010333, gl-0.510857]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:42:02]
2023.04.12-02:26:06:257:[step-60200/113100: 53.23%]--[loss-1.370424: wl-3.264725, gl-0.554243]--[lr: pb-0.000030, pf-0.000028]--[ETA-11:20:24]
2023.04.12-02:27:17:357:[step-60300/113100: 53.32%]--[loss-1.397929: wl-3.166794, gl-0.606230]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:22:55]
2023.04.12-02:28:27:457:[step-60400/113100: 53.40%]--[loss-1.301765: wl-3.238553, gl-0.492127]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:17:13]
2023.04.12-02:29:36:557:[step-60500/113100: 53.49%]--[loss-1.436206: wl-3.171003, gl-0.643455]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:39:43]
2023.04.12-02:30:47:657:[step-60600/113100: 53.58%]--[loss-1.267371: wl-2.975773, gl-0.523428]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:30:20]
2023.04.12-02:31:57:757:[step-60700/113100: 53.67%]--[loss-1.268395: wl-2.969618, gl-0.525990]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:39:36]
2023.04.12-02:33:10:857:[step-60800/113100: 53.76%]--[loss-1.347543: wl-3.410810, gl-0.494841]--[lr: pb-0.000030, pf-0.000028]--[ETA-20:12:19]
2023.04.12-02:34:31:957:[step-60900/113100: 53.85%]--[loss-1.276794: wl-3.164837, gl-0.485585]--[lr: pb-0.000030, pf-0.000028]--[ETA-9:58:34]
2023.04.12-02:35:40:1057:[step-61000/113100: 53.93%]--[loss-1.271022: wl-2.983432, gl-0.525164]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:15:06]
End of epoch 54 / 100: train_loss: 1.357 	 time: 837 sec
Saving the model at the end of epoch 54, iters 61074
2023.04.12-02:37:04:26:[step-61100/113100: 54.02%]--[loss-1.460296: wl-3.522383, gl-0.579700]--[lr: pb-0.000030, pf-0.000028]--[ETA-12:06:37]
2023.04.12-02:38:15:126:[step-61200/113100: 54.11%]--[loss-1.289614: wl-2.906939, gl-0.562879]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:26:32]
2023.04.12-02:39:26:226:[step-61300/113100: 54.20%]--[loss-1.204996: wl-2.826685, gl-0.498325]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:21:33]
2023.04.12-02:40:37:326:[step-61400/113100: 54.29%]--[loss-1.289202: wl-2.996819, gl-0.539997]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:26:28]
2023.04.12-02:41:48:426:[step-61500/113100: 54.38%]--[loss-1.358780: wl-3.162226, gl-0.568223]--[lr: pb-0.000030, pf-0.000028]--[ETA-8:37:13]
2023.04.12-02:43:14:526:[step-61600/113100: 54.47%]--[loss-1.335442: wl-3.327182, gl-0.503647]--[lr: pb-0.000030, pf-0.000028]--[ETA-9:49:31]
2023.04.12-02:44:24:626:[step-61700/113100: 54.55%]--[loss-1.352853: wl-3.025256, gl-0.596539]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:06:41]
2023.04.12-02:45:34:726:[step-61800/113100: 54.64%]--[loss-1.442332: wl-3.384105, gl-0.596306]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:35:23]
2023.04.12-02:46:45:826:[step-61900/113100: 54.73%]--[loss-1.391738: wl-3.308188, gl-0.564691]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:22:19]
2023.04.12-02:47:54:926:[step-62000/113100: 54.82%]--[loss-1.348768: wl-3.209891, gl-0.546295]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:05:04]
2023.04.12-02:49:04:1026:[step-62100/113100: 54.91%]--[loss-1.340217: wl-3.426566, gl-0.483576]--[lr: pb-0.000030, pf-0.000028]--[ETA-10:37:13]
2023.04.12-02:50:14:1126:[step-62200/113100: 55.00%]--[loss-1.317962: wl-3.158482, gl-0.528341]--[lr: pb-0.000030, pf-0.000028]--[ETA-9:59:34]
End of epoch 55 / 100: train_loss: 1.356 	 time: 824 sec
Saving the model at the end of epoch 55, iters 62205
2023.04.12-02:51:50:95:[step-62300/113100: 55.08%]--[loss-1.328030: wl-3.334319, gl-0.494450]--[lr: pb-0.000030, pf-0.000027]--[ETA-16:14:54]
2023.04.12-02:53:03:195:[step-62400/113100: 55.17%]--[loss-1.347943: wl-3.205936, gl-0.546458]--[lr: pb-0.000030, pf-0.000027]--[ETA-10:48:46]
2023.04.12-02:54:14:295:[step-62500/113100: 55.26%]--[loss-1.285264: wl-2.939584, gl-0.550368]--[lr: pb-0.000030, pf-0.000027]--[ETA-10:06:34]
2023.04.12-02:55:25:395:[step-62600/113100: 55.35%]--[loss-1.303988: wl-3.091891, gl-0.531016]--[lr: pb-0.000030, pf-0.000027]--[ETA-9:41:05]
2023.04.12-02:56:36:495:[step-62700/113100: 55.44%]--[loss-1.360476: wl-3.250871, gl-0.547758]--[lr: pb-0.000030, pf-0.000027]--[ETA-10:37:01]
2023.04.12-02:57:46:595:[step-62800/113100: 55.53%]--[loss-1.332709: wl-3.059437, gl-0.567850]--[lr: pb-0.000030, pf-0.000027]--[ETA-9:49:09]
2023.04.12-02:58:56:695:[step-62900/113100: 55.61%]--[loss-1.637224: wl-3.858364, gl-0.672633]--[lr: pb-0.000030, pf-0.000027]--[ETA-9:26:17]
2023.04.12-03:00:06:795:[step-63000/113100: 55.70%]--[loss-1.415639: wl-3.176289, gl-0.621567]--[lr: pb-0.000030, pf-0.000027]--[ETA-10:05:59]
2023.04.12-03:01:32:895:[step-63100/113100: 55.79%]--[loss-1.477351: wl-3.095148, gl-0.703564]--[lr: pb-0.000030, pf-0.000027]--[ETA-9:24:39]
2023.04.12-03:02:42:995:[step-63200/113100: 55.88%]--[loss-1.427140: wl-3.248664, gl-0.614974]--[lr: pb-0.000030, pf-0.000027]--[ETA-10:27:28]
2023.04.12-03:03:53:1095:[step-63300/113100: 55.97%]--[loss-1.337449: wl-3.041300, gl-0.577123]--[lr: pb-0.000030, pf-0.000027]--[ETA-9:40:11]
End of epoch 56 / 100: train_loss: 1.353 	 time: 839 sec
Saving the model at the end of epoch 56, iters 63336
2023.04.12-03:05:15:64:[step-63400/113100: 56.06%]--[loss-1.436862: wl-3.309934, gl-0.609378]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:42:23]
2023.04.12-03:06:26:164:[step-63500/113100: 56.15%]--[loss-1.343125: wl-3.219006, gl-0.538373]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:50:26]
2023.04.12-03:07:37:264:[step-63600/113100: 56.23%]--[loss-1.252893: wl-2.963825, gl-0.511937]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:31:15]
2023.04.12-03:08:48:364:[step-63700/113100: 56.32%]--[loss-1.353463: wl-3.168091, gl-0.561440]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:05:12]
2023.04.12-03:10:15:464:[step-63800/113100: 56.41%]--[loss-1.458982: wl-3.275935, gl-0.639998]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:48:16]
2023.04.12-03:11:25:564:[step-63900/113100: 56.50%]--[loss-1.299920: wl-3.020647, gl-0.544758]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:26:01]
2023.04.12-03:12:35:664:[step-64000/113100: 56.59%]--[loss-1.269862: wl-3.131432, gl-0.487004]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:26:09]
2023.04.12-03:13:46:764:[step-64100/113100: 56.68%]--[loss-1.323407: wl-3.020273, gl-0.568339]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:52:11]
2023.04.12-03:14:55:864:[step-64200/113100: 56.76%]--[loss-1.503982: wl-3.390151, gl-0.656444]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:31:15]
2023.04.12-03:16:06:964:[step-64300/113100: 56.85%]--[loss-1.462227: wl-3.442202, gl-0.601676]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:50:37]
2023.04.12-03:17:16:1064:[step-64400/113100: 56.94%]--[loss-1.285431: wl-3.245228, gl-0.474124]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:32:40]
End of epoch 57 / 100: train_loss: 1.353 	 time: 824 sec
Saving the model at the end of epoch 57, iters 64467
2023.04.12-03:18:45:33:[step-64500/113100: 57.03%]--[loss-1.263493: wl-3.065740, gl-0.497058]--[lr: pb-0.000030, pf-0.000026]--[ETA-18:58:05]
2023.04.12-03:20:05:133:[step-64600/113100: 57.12%]--[loss-1.457494: wl-3.558676, gl-0.567825]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:28:12]
2023.04.12-03:21:15:233:[step-64700/113100: 57.21%]--[loss-1.441231: wl-3.459527, gl-0.576349]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:17:38]
2023.04.12-03:22:26:333:[step-64800/113100: 57.29%]--[loss-1.353380: wl-3.169411, gl-0.561028]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:08:22]
2023.04.12-03:23:37:433:[step-64900/113100: 57.38%]--[loss-1.321191: wl-3.116499, gl-0.542066]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:27:16]
2023.04.12-03:24:47:533:[step-65000/113100: 57.47%]--[loss-1.361020: wl-3.188300, gl-0.563945]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:15:52]
2023.04.12-03:25:57:633:[step-65100/113100: 57.56%]--[loss-1.524924: wl-3.238163, gl-0.715383]--[lr: pb-0.000030, pf-0.000026]--[ETA-8:53:24]
2023.04.12-03:27:07:733:[step-65200/113100: 57.65%]--[loss-1.305145: wl-3.152570, gl-0.517002]--[lr: pb-0.000030, pf-0.000026]--[ETA-7:24:24]
2023.04.12-03:28:32:833:[step-65300/113100: 57.74%]--[loss-1.402808: wl-3.264770, gl-0.586615]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:34:54]
2023.04.12-03:29:42:933:[step-65400/113100: 57.82%]--[loss-1.230668: wl-2.985228, gl-0.484361]--[lr: pb-0.000030, pf-0.000026]--[ETA-9:31:04]
2023.04.12-03:30:53:1033:[step-65500/113100: 57.91%]--[loss-1.358804: wl-3.219735, gl-0.553870]--[lr: pb-0.000030, pf-0.000026]--[ETA-10:04:14]
End of epoch 58 / 100: train_loss: 1.351 	 time: 839 sec
Saving the model at the end of epoch 58, iters 65598
2023.04.12-03:32:14:2:[step-65600/113100: 58.00%]--[loss-1.383511: wl-3.149640, gl-0.596101]--[lr: pb-0.000030, pf-0.000025]--[ETA-14:34:38]
2023.04.12-03:33:25:102:[step-65700/113100: 58.09%]--[loss-1.289183: wl-3.041339, gl-0.528848]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:16:11]
2023.04.12-03:34:35:202:[step-65800/113100: 58.18%]--[loss-1.253232: wl-3.003382, gl-0.502387]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:26:21]
2023.04.12-03:35:46:302:[step-65900/113100: 58.27%]--[loss-1.411741: wl-3.178539, gl-0.617106]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:29:05]
2023.04.12-03:37:06:402:[step-66000/113100: 58.36%]--[loss-1.490037: wl-3.485554, gl-0.618648]--[lr: pb-0.000030, pf-0.000025]--[ETA-8:55:38]
2023.04.12-03:38:22:502:[step-66100/113100: 58.44%]--[loss-1.405117: wl-3.240543, gl-0.594982]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:56:12]
2023.04.12-03:39:32:602:[step-66200/113100: 58.53%]--[loss-1.246149: wl-3.123522, gl-0.465268]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:08:08]
2023.04.12-03:40:42:702:[step-66300/113100: 58.62%]--[loss-1.504052: wl-3.468170, gl-0.637010]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:37:30]
2023.04.12-03:41:53:802:[step-66400/113100: 58.71%]--[loss-1.307511: wl-3.088259, gl-0.535447]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:24:13]
2023.04.12-03:43:02:902:[step-66500/113100: 58.80%]--[loss-1.220867: wl-2.938745, gl-0.486181]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:17:45]
2023.04.12-03:44:12:1002:[step-66600/113100: 58.89%]--[loss-1.327340: wl-3.232812, gl-0.519137]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:52:46]
2023.04.12-03:45:22:1102:[step-66700/113100: 58.97%]--[loss-1.332909: wl-2.985669, gl-0.586492]--[lr: pb-0.000030, pf-0.000025]--[ETA-8:53:00]
End of epoch 59 / 100: train_loss: 1.351 	 time: 821 sec
Saving the model at the end of epoch 59, iters 66729
2023.04.12-03:47:01:71:[step-66800/113100: 59.06%]--[loss-1.361824: wl-3.302835, gl-0.536115]--[lr: pb-0.000030, pf-0.000025]--[ETA-7:51:06]
2023.04.12-03:48:11:171:[step-66900/113100: 59.15%]--[loss-1.303456: wl-2.953330, gl-0.565123]--[lr: pb-0.000030, pf-0.000025]--[ETA-8:09:04]
2023.04.12-03:49:22:271:[step-67000/113100: 59.24%]--[loss-1.283942: wl-3.033159, gl-0.525652]--[lr: pb-0.000030, pf-0.000025]--[ETA-7:34:49]
2023.04.12-03:50:33:371:[step-67100/113100: 59.33%]--[loss-1.279974: wl-2.944810, gl-0.543772]--[lr: pb-0.000030, pf-0.000025]--[ETA-8:26:56]
2023.04.12-03:51:44:471:[step-67200/113100: 59.42%]--[loss-1.319727: wl-3.291487, gl-0.496856]--[lr: pb-0.000030, pf-0.000025]--[ETA-10:12:10]
2023.04.12-03:52:54:571:[step-67300/113100: 59.50%]--[loss-1.300098: wl-2.999190, gl-0.550301]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:37:13]
2023.04.12-03:54:05:671:[step-67400/113100: 59.59%]--[loss-1.494776: wl-3.568775, gl-0.602582]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:08:13]
2023.04.12-03:55:29:771:[step-67500/113100: 59.68%]--[loss-1.332817: wl-3.147105, gl-0.546041]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:17:39]
2023.04.12-03:56:40:871:[step-67600/113100: 59.77%]--[loss-1.291894: wl-3.257788, gl-0.477447]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:32:01]
2023.04.12-03:57:50:971:[step-67700/113100: 59.86%]--[loss-1.353301: wl-3.083194, gl-0.582503]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:14:18]
2023.04.12-03:59:00:1071:[step-67800/113100: 59.95%]--[loss-1.304923: wl-2.825248, gl-0.598611]--[lr: pb-0.000030, pf-0.000025]--[ETA-9:18:09]
End of epoch 60 / 100: train_loss: 1.348 	 time: 838 sec
Saving the model at the end of epoch 60, iters 67860
2023.04.12-04:00:23:40:[step-67900/113100: 60.04%]--[loss-1.287762: wl-3.072366, gl-0.519670]--[lr: pb-0.000030, pf-0.000024]--[ETA-7:24:42]
2023.04.12-04:01:34:140:[step-68000/113100: 60.12%]--[loss-1.355686: wl-3.037104, gl-0.596410]--[lr: pb-0.000030, pf-0.000024]--[ETA-8:32:12]
2023.04.12-04:02:45:240:[step-68100/113100: 60.21%]--[loss-1.313664: wl-3.113205, gl-0.535363]--[lr: pb-0.000030, pf-0.000024]--[ETA-7:16:57]
2023.04.12-04:04:01:340:[step-68200/113100: 60.30%]--[loss-1.483430: wl-3.437212, gl-0.624127]--[lr: pb-0.000030, pf-0.000024]--[ETA-14:36:35]
2023.04.12-04:05:22:440:[step-68300/113100: 60.39%]--[loss-1.435454: wl-3.241838, gl-0.624995]--[lr: pb-0.000030, pf-0.000024]--[ETA-8:50:32]
2023.04.12-04:06:32:540:[step-68400/113100: 60.48%]--[loss-1.312912: wl-3.059663, gl-0.547996]--[lr: pb-0.000030, pf-0.000024]--[ETA-8:28:21]
2023.04.12-04:07:42:640:[step-68500/113100: 60.57%]--[loss-1.361413: wl-3.130683, gl-0.578742]--[lr: pb-0.000030, pf-0.000024]--[ETA-9:29:46]
2023.04.12-04:08:52:740:[step-68600/113100: 60.65%]--[loss-1.528083: wl-3.499467, gl-0.653216]--[lr: pb-0.000030, pf-0.000024]--[ETA-9:14:42]
2023.04.12-04:10:02:840:[step-68700/113100: 60.74%]--[loss-1.478015: wl-3.356910, gl-0.638788]--[lr: pb-0.000030, pf-0.000024]--[ETA-8:38:53]
2023.04.12-04:11:13:940:[step-68800/113100: 60.83%]--[loss-1.347806: wl-3.021150, gl-0.592518]--[lr: pb-0.000030, pf-0.000024]--[ETA-9:07:36]
2023.04.12-04:12:23:1040:[step-68900/113100: 60.92%]--[loss-1.335578: wl-3.190120, gl-0.538048]--[lr: pb-0.000030, pf-0.000024]--[ETA-8:48:03]
End of epoch 61 / 100: train_loss: 1.346 	 time: 837 sec
Saving the model at the end of epoch 61, iters 68991
2023.04.12-04:13:59:9:[step-69000/113100: 61.01%]--[loss-1.398101: wl-3.212027, gl-0.595095]--[lr: pb-0.000030, pf-0.000023]--[ETA-9:15:25]
2023.04.12-04:15:10:109:[step-69100/113100: 61.10%]--[loss-1.487548: wl-3.336360, gl-0.653458]--[lr: pb-0.000030, pf-0.000023]--[ETA-9:23:45]
2023.04.12-04:16:21:209:[step-69200/113100: 61.18%]--[loss-1.245549: wl-3.055016, gl-0.481795]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:45:50]
2023.04.12-04:17:31:309:[step-69300/113100: 61.27%]--[loss-1.317729: wl-3.303677, gl-0.491810]--[lr: pb-0.000030, pf-0.000023]--[ETA-9:13:05]
2023.04.12-04:18:42:409:[step-69400/113100: 61.36%]--[loss-1.392354: wl-3.169300, gl-0.600029]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:41:17]
2023.04.12-04:19:52:509:[step-69500/113100: 61.45%]--[loss-1.254184: wl-3.080388, gl-0.484087]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:41:33]
2023.04.12-04:21:02:609:[step-69600/113100: 61.54%]--[loss-1.451073: wl-3.524281, gl-0.570003]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:13:19]
2023.04.12-04:22:22:709:[step-69700/113100: 61.63%]--[loss-1.414978: wl-3.125572, gl-0.633585]--[lr: pb-0.000030, pf-0.000023]--[ETA-14:21:03]
2023.04.12-04:23:38:809:[step-69800/113100: 61.72%]--[loss-1.307850: wl-2.966810, gl-0.566148]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:08:58]
2023.04.12-04:24:49:909:[step-69900/113100: 61.80%]--[loss-1.331757: wl-3.140985, gl-0.546511]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:21:36]
2023.04.12-04:25:59:1009:[step-70000/113100: 61.89%]--[loss-1.365783: wl-3.329925, gl-0.533302]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:32:33]
2023.04.12-04:27:09:1109:[step-70100/113100: 61.98%]--[loss-1.393699: wl-3.396409, gl-0.544597]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:29:35]
End of epoch 62 / 100: train_loss: 1.344 	 time: 822 sec
Saving the model at the end of epoch 62, iters 70122
2023.04.12-04:28:31:78:[step-70200/113100: 62.07%]--[loss-1.332942: wl-3.059597, gl-0.568043]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:28:58]
2023.04.12-04:29:41:178:[step-70300/113100: 62.16%]--[loss-1.304790: wl-3.222179, gl-0.499245]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:12:56]
2023.04.12-04:30:52:278:[step-70400/113100: 62.25%]--[loss-1.364127: wl-3.343841, gl-0.528167]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:56:47]
2023.04.12-04:32:20:378:[step-70500/113100: 62.33%]--[loss-1.332660: wl-3.039034, gl-0.572901]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:40:22]
2023.04.12-04:33:29:478:[step-70600/113100: 62.42%]--[loss-1.408444: wl-3.119213, gl-0.628641]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:29:25]
2023.04.12-04:34:39:578:[step-70700/113100: 62.51%]--[loss-1.318523: wl-3.127524, gl-0.536642]--[lr: pb-0.000030, pf-0.000023]--[ETA-10:05:34]
2023.04.12-04:35:49:678:[step-70800/113100: 62.60%]--[loss-1.455560: wl-3.208110, gl-0.653532]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:40:04]
2023.04.12-04:36:58:778:[step-70900/113100: 62.69%]--[loss-1.254878: wl-2.975600, gl-0.510978]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:19:29]
2023.04.12-04:38:09:878:[step-71000/113100: 62.78%]--[loss-1.313454: wl-3.131285, gl-0.530633]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:36:46]
2023.04.12-04:39:19:978:[step-71100/113100: 62.86%]--[loss-1.311664: wl-3.103647, gl-0.535752]--[lr: pb-0.000030, pf-0.000023]--[ETA-8:26:16]
2023.04.12-04:40:29:1078:[step-71200/113100: 62.95%]--[loss-1.446755: wl-3.341351, gl-0.611417]--[lr: pb-0.000030, pf-0.000023]--[ETA-7:58:12]
End of epoch 63 / 100: train_loss: 1.343 	 time: 822 sec
Saving the model at the end of epoch 63, iters 71253
2023.04.12-04:41:53:47:[step-71300/113100: 63.04%]--[loss-1.288327: wl-3.088938, gl-0.516093]--[lr: pb-0.000030, pf-0.000022]--[ETA-9:12:48]
2023.04.12-04:43:05:147:[step-71400/113100: 63.13%]--[loss-1.408823: wl-3.166882, gl-0.617102]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:53:00]
2023.04.12-04:44:14:247:[step-71500/113100: 63.22%]--[loss-1.357948: wl-3.226242, gl-0.551387]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:22:42]
2023.04.12-04:45:26:347:[step-71600/113100: 63.31%]--[loss-1.356956: wl-3.297116, gl-0.532678]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:40:17]
2023.04.12-04:46:36:447:[step-71700/113100: 63.40%]--[loss-1.417892: wl-3.268388, gl-0.600795]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:52:10]
2023.04.12-04:47:45:547:[step-71800/113100: 63.48%]--[loss-1.292794: wl-3.195344, gl-0.493958]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:54:04]
2023.04.12-04:48:56:647:[step-71900/113100: 63.57%]--[loss-1.263320: wl-3.179216, gl-0.468516]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:25:37]
2023.04.12-04:50:05:747:[step-72000/113100: 63.66%]--[loss-1.505477: wl-3.368003, gl-0.663476]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:32:00]
2023.04.12-04:51:14:847:[step-72100/113100: 63.75%]--[loss-1.268362: wl-3.119074, gl-0.488594]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:15:22]
2023.04.12-04:52:24:947:[step-72200/113100: 63.84%]--[loss-1.440961: wl-3.448660, gl-0.578796]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:43:36]
2023.04.12-04:53:33:1047:[step-72300/113100: 63.93%]--[loss-1.427381: wl-3.431004, gl-0.569629]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:23:41]
End of epoch 64 / 100: train_loss: 1.340 	 time: 804 sec
Saving the model at the end of epoch 64, iters 72384
2023.04.12-04:54:56:16:[step-72400/113100: 64.01%]--[loss-1.276523: wl-3.058156, gl-0.511984]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:09:33]
2023.04.12-04:56:09:116:[step-72500/113100: 64.10%]--[loss-1.346944: wl-3.090505, gl-0.574318]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:08:02]
2023.04.12-04:57:17:216:[step-72600/113100: 64.19%]--[loss-1.417000: wl-3.422087, gl-0.561478]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:44:13]
2023.04.12-04:58:27:316:[step-72700/113100: 64.28%]--[loss-1.373843: wl-3.177633, gl-0.579434]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:54:42]
2023.04.12-04:59:39:416:[step-72800/113100: 64.37%]--[loss-1.384955: wl-3.078802, gl-0.615254]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:42:46]
2023.04.12-05:00:48:516:[step-72900/113100: 64.46%]--[loss-1.287146: wl-3.141506, gl-0.501769]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:56:38]
2023.04.12-05:01:57:616:[step-73000/113100: 64.54%]--[loss-1.325119: wl-3.204975, gl-0.523875]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:17:47]
2023.04.12-05:03:08:716:[step-73100/113100: 64.63%]--[loss-1.340482: wl-3.183855, gl-0.544519]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:12:34]
2023.04.12-05:04:17:816:[step-73200/113100: 64.72%]--[loss-1.287233: wl-3.083494, gl-0.516360]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:17:54]
2023.04.12-05:05:26:916:[step-73300/113100: 64.81%]--[loss-1.310749: wl-3.216193, gl-0.506701]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:21:19]
2023.04.12-05:06:36:1016:[step-73400/113100: 64.90%]--[loss-1.395735: wl-3.251343, gl-0.582899]--[lr: pb-0.000030, pf-0.000022]--[ETA-7:35:58]
2023.04.12-05:07:44:1116:[step-73500/113100: 64.99%]--[loss-1.435654: wl-3.330622, gl-0.602998]--[lr: pb-0.000030, pf-0.000022]--[ETA-8:21:28]
End of epoch 65 / 100: train_loss: 1.340 	 time: 803 sec
Saving the model at the end of epoch 65, iters 73515
2023.04.12-05:09:09:85:[step-73600/113100: 65.08%]--[loss-1.340132: wl-3.190739, gl-0.542447]--[lr: pb-0.000030, pf-0.000021]--[ETA-8:10:19]
2023.04.12-05:10:18:185:[step-73700/113100: 65.16%]--[loss-1.332014: wl-3.127330, gl-0.550181]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:48:42]
2023.04.12-05:11:16:285:[step-73800/113100: 65.25%]--[loss-1.328337: wl-3.110838, gl-0.550628]--[lr: pb-0.000030, pf-0.000021]--[ETA-5:49:05]
2023.04.12-05:12:14:385:[step-73900/113100: 65.34%]--[loss-1.392517: wl-3.432006, gl-0.534515]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:07:06]
2023.04.12-05:13:11:485:[step-74000/113100: 65.43%]--[loss-1.277307: wl-3.157543, gl-0.487921]--[lr: pb-0.000030, pf-0.000021]--[ETA-5:51:19]
2023.04.12-05:14:07:585:[step-74100/113100: 65.52%]--[loss-1.373827: wl-3.306150, gl-0.547290]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:02:45]
2023.04.12-05:15:03:685:[step-74200/113100: 65.61%]--[loss-1.238963: wl-2.967709, gl-0.497036]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:23:22]
2023.04.12-05:16:01:785:[step-74300/113100: 65.69%]--[loss-1.231638: wl-3.104107, gl-0.455611]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:22:04]
2023.04.12-05:16:56:885:[step-74400/113100: 65.78%]--[loss-1.465108: wl-3.243017, gl-0.654354]--[lr: pb-0.000030, pf-0.000021]--[ETA-5:56:33]
2023.04.12-05:17:52:985:[step-74500/113100: 65.87%]--[loss-1.321742: wl-3.227103, gl-0.514966]--[lr: pb-0.000030, pf-0.000021]--[ETA-5:48:03]
2023.04.12-05:18:48:1085:[step-74600/113100: 65.96%]--[loss-1.251911: wl-3.122568, gl-0.471269]--[lr: pb-0.000030, pf-0.000021]--[ETA-6:37:23]
End of epoch 66 / 100: train_loss: 1.338 	 time: 679 sec
Saving the model at the end of epoch 66, iters 74646
2023.04.12-05:19:57:54:[step-74700/113100: 66.05%]--[loss-1.213568: wl-2.975288, gl-0.469746]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:21:17]
2023.04.12-05:20:55:154:[step-74800/113100: 66.14%]--[loss-1.338130: wl-3.321429, gl-0.507772]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:23:42]
2023.04.12-05:21:54:254:[step-74900/113100: 66.22%]--[loss-1.307922: wl-3.150107, gl-0.520395]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:06:44]
2023.04.12-05:22:52:354:[step-75000/113100: 66.31%]--[loss-1.268744: wl-2.980877, gl-0.523525]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:55:42]
2023.04.12-05:23:48:454:[step-75100/113100: 66.40%]--[loss-1.257326: wl-3.094234, gl-0.483768]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:52:13]
2023.04.12-05:24:44:554:[step-75200/113100: 66.49%]--[loss-1.368608: wl-3.219386, gl-0.563762]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:15:12]
2023.04.12-05:25:40:654:[step-75300/113100: 66.58%]--[loss-1.365852: wl-3.215518, gl-0.561973]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:06:23]
2023.04.12-05:26:36:754:[step-75400/113100: 66.67%]--[loss-1.541801: wl-3.752067, gl-0.603784]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:48:29]
2023.04.12-05:27:32:854:[step-75500/113100: 66.76%]--[loss-1.295658: wl-3.070333, gl-0.528075]--[lr: pb-0.000030, pf-0.000020]--[ETA-6:13:44]
2023.04.12-05:28:28:954:[step-75600/113100: 66.84%]--[loss-1.330321: wl-3.191719, gl-0.532391]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:47:38]
2023.04.12-05:29:25:1054:[step-75700/113100: 66.93%]--[loss-1.261170: wl-3.100991, gl-0.485922]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:36:12]
End of epoch 67 / 100: train_loss: 1.336 	 time: 651 sec
Saving the model at the end of epoch 67, iters 75777
2023.04.12-05:30:33:23:[step-75800/113100: 67.02%]--[loss-1.352098: wl-3.157576, gl-0.562704]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:48:32]
2023.04.12-05:31:31:123:[step-75900/113100: 67.11%]--[loss-1.457121: wl-3.515913, gl-0.578143]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:40:05]
2023.04.12-05:32:29:223:[step-76000/113100: 67.20%]--[loss-1.248954: wl-2.997465, gl-0.499587]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:57:39]
2023.04.12-05:33:25:323:[step-76100/113100: 67.29%]--[loss-1.333710: wl-3.094626, gl-0.560053]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:52:16]
2023.04.12-05:34:21:423:[step-76200/113100: 67.37%]--[loss-1.292273: wl-2.966303, gl-0.550697]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:43:42]
2023.04.12-05:35:17:523:[step-76300/113100: 67.46%]--[loss-1.176524: wl-2.889716, gl-0.454096]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:51:54]
2023.04.12-05:36:14:623:[step-76400/113100: 67.55%]--[loss-1.343110: wl-3.164856, gl-0.551896]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:40:58]
2023.04.12-05:37:10:723:[step-76500/113100: 67.64%]--[loss-1.394402: wl-3.206985, gl-0.592655]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:28:06]
2023.04.12-05:38:06:823:[step-76600/113100: 67.73%]--[loss-1.211549: wl-3.003140, gl-0.460764]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:37:16]
2023.04.12-05:39:03:923:[step-76700/113100: 67.82%]--[loss-1.398923: wl-3.213380, gl-0.595578]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:38:31]
2023.04.12-05:39:59:1023:[step-76800/113100: 67.90%]--[loss-1.345996: wl-3.145649, gl-0.559584]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:21:35]
2023.04.12-05:40:54:1123:[step-76900/113100: 67.99%]--[loss-1.287020: wl-3.039640, gl-0.527110]--[lr: pb-0.000030, pf-0.000020]--[ETA-5:29:52]
End of epoch 68 / 100: train_loss: 1.335 	 time: 651 sec
Saving the model at the end of epoch 68, iters 76908
2023.04.12-05:42:07:92:[step-77000/113100: 68.08%]--[loss-1.383593: wl-3.350225, gl-0.546037]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:43:29]
2023.04.12-05:43:05:192:[step-77100/113100: 68.17%]--[loss-1.421348: wl-3.280142, gl-0.601312]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:55:35]
2023.04.12-05:44:01:292:[step-77200/113100: 68.26%]--[loss-1.399693: wl-3.164158, gl-0.608653]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:32:11]
2023.04.12-05:44:57:392:[step-77300/113100: 68.35%]--[loss-1.310670: wl-3.151828, gl-0.522713]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:32:22]
2023.04.12-05:45:54:492:[step-77400/113100: 68.44%]--[loss-1.357191: wl-3.110623, gl-0.579535]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:10:35]
2023.04.12-05:46:50:592:[step-77500/113100: 68.52%]--[loss-1.535135: wl-3.449277, gl-0.672815]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:27:46]
2023.04.12-05:47:46:692:[step-77600/113100: 68.61%]--[loss-1.313756: wl-3.156871, gl-0.524539]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:27:06]
2023.04.12-05:48:42:792:[step-77700/113100: 68.70%]--[loss-1.329191: wl-2.991004, gl-0.581440]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:39:56]
2023.04.12-05:49:39:892:[step-77800/113100: 68.79%]--[loss-1.350911: wl-3.079220, gl-0.581106]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:54:17]
2023.04.12-05:50:34:992:[step-77900/113100: 68.88%]--[loss-1.280278: wl-2.987322, gl-0.533448]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:14:15]
2023.04.12-05:51:30:1092:[step-78000/113100: 68.97%]--[loss-1.264586: wl-3.120911, gl-0.484358]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:33:30]
End of epoch 69 / 100: train_loss: 1.333 	 time: 652 sec
Saving the model at the end of epoch 69, iters 78039
2023.04.12-05:52:40:61:[step-78100/113100: 69.05%]--[loss-1.325286: wl-3.034298, gl-0.566711]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:14:44]
2023.04.12-05:53:37:161:[step-78200/113100: 69.14%]--[loss-1.287429: wl-3.037286, gl-0.528107]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:27:36]
2023.04.12-05:54:34:261:[step-78300/113100: 69.23%]--[loss-1.249422: wl-2.905290, gl-0.523099]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:12:25]
2023.04.12-05:55:30:361:[step-78400/113100: 69.32%]--[loss-1.362318: wl-3.231725, gl-0.554387]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:35:43]
2023.04.12-05:56:27:461:[step-78500/113100: 69.41%]--[loss-1.476318: wl-3.222297, gl-0.670744]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:19:08]
2023.04.12-05:57:23:561:[step-78600/113100: 69.50%]--[loss-1.278521: wl-3.264113, gl-0.462492]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:21:17]
2023.04.12-05:58:19:661:[step-78700/113100: 69.58%]--[loss-1.147879: wl-2.957626, gl-0.408473]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:19:12]
2023.04.12-05:59:16:761:[step-78800/113100: 69.67%]--[loss-1.545439: wl-3.543716, gl-0.659510]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:21:03]
2023.04.12-06:00:11:861:[step-78900/113100: 69.76%]--[loss-1.262761: wl-3.053892, gl-0.499288]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:17:37]
2023.04.12-06:01:07:961:[step-79000/113100: 69.85%]--[loss-1.336276: wl-3.251151, gl-0.523488]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:17:41]
2023.04.12-06:02:03:1061:[step-79100/113100: 69.94%]--[loss-1.286585: wl-3.069506, gl-0.519209]--[lr: pb-0.000030, pf-0.000019]--[ETA-5:20:44]
End of epoch 70 / 100: train_loss: 1.332 	 time: 650 sec
Saving the model at the end of epoch 70, iters 79170
2023.04.12-06:03:14:30:[step-79200/113100: 70.03%]--[loss-1.362465: wl-3.174224, gl-0.568909]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:32:22]
2023.04.12-06:04:12:130:[step-79300/113100: 70.11%]--[loss-1.458954: wl-3.191733, gl-0.661021]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:14:07]
2023.04.12-06:05:09:230:[step-79400/113100: 70.20%]--[loss-1.285870: wl-3.129192, gl-0.503572]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:08:13]
2023.04.12-06:06:06:330:[step-79500/113100: 70.29%]--[loss-1.274980: wl-3.056048, gl-0.510968]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:32:08]
2023.04.12-06:07:03:430:[step-79600/113100: 70.38%]--[loss-1.224178: wl-2.998555, gl-0.474539]--[lr: pb-0.000030, pf-0.000018]--[ETA-4:56:08]
2023.04.12-06:07:59:530:[step-79700/113100: 70.47%]--[loss-1.398636: wl-3.349120, gl-0.561356]--[lr: pb-0.000030, pf-0.000018]--[ETA-4:59:39]
2023.04.12-06:08:56:630:[step-79800/113100: 70.56%]--[loss-1.207481: wl-3.003462, gl-0.456616]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:07:52]
2023.04.12-06:09:53:730:[step-79900/113100: 70.65%]--[loss-1.433414: wl-3.168791, gl-0.641216]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:01:13]
2023.04.12-06:10:49:830:[step-80000/113100: 70.73%]--[loss-1.358344: wl-3.186225, gl-0.561788]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:28:41]
2023.04.12-06:11:45:930:[step-80100/113100: 70.82%]--[loss-1.338543: wl-3.063784, gl-0.572597]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:15:43]
2023.04.12-06:12:41:1030:[step-80200/113100: 70.91%]--[loss-1.194419: wl-2.951026, gl-0.456662]--[lr: pb-0.000030, pf-0.000018]--[ETA-5:06:51]
2023.04.12-06:13:36:1130:[step-80300/113100: 71.00%]--[loss-1.159613: wl-2.752082, gl-0.471592]--[lr: pb-0.000030, pf-0.000018]--[ETA-4:52:28]
End of epoch 71 / 100: train_loss: 1.332 	 time: 654 sec
Saving the model at the end of epoch 71, iters 80301
2023.04.12-06:14:47:99:[step-80400/113100: 71.09%]--[loss-1.429630: wl-3.211395, gl-0.626781]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:25:09]
2023.04.12-06:15:44:199:[step-80500/113100: 71.18%]--[loss-1.482682: wl-3.328106, gl-0.650656]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:19:10]
2023.04.12-06:16:40:299:[step-80600/113100: 71.26%]--[loss-1.219794: wl-2.946439, gl-0.483184]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:09:07]
2023.04.12-06:17:37:399:[step-80700/113100: 71.35%]--[loss-1.413417: wl-3.332492, gl-0.580294]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:17:25]
2023.04.12-06:18:34:499:[step-80800/113100: 71.44%]--[loss-1.415015: wl-3.445133, gl-0.553732]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:09:43]
2023.04.12-06:19:30:599:[step-80900/113100: 71.53%]--[loss-1.494085: wl-3.335528, gl-0.660203]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:45:25]
2023.04.12-06:20:26:699:[step-81000/113100: 71.62%]--[loss-1.308378: wl-3.129713, gl-0.525950]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:45:26]
2023.04.12-06:21:22:799:[step-81100/113100: 71.71%]--[loss-1.333233: wl-3.141773, gl-0.547790]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:14:56]
2023.04.12-06:22:19:899:[step-81200/113100: 71.79%]--[loss-1.453969: wl-3.307785, gl-0.627022]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:40:05]
2023.04.12-06:23:15:999:[step-81300/113100: 71.88%]--[loss-1.220688: wl-2.930771, gl-0.487995]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:57:26]
2023.04.12-06:24:10:1099:[step-81400/113100: 71.97%]--[loss-1.416554: wl-3.400154, gl-0.566515]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:00:02]
End of epoch 72 / 100: train_loss: 1.332 	 time: 650 sec
Saving the model at the end of epoch 72, iters 81432
2023.04.12-06:25:20:68:[step-81500/113100: 72.06%]--[loss-1.396559: wl-3.212241, gl-0.593499]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:46:50]
2023.04.12-06:26:17:168:[step-81600/113100: 72.15%]--[loss-1.388600: wl-3.126335, gl-0.607016]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:51:52]
2023.04.12-06:27:14:268:[step-81700/113100: 72.24%]--[loss-1.370949: wl-3.270386, gl-0.553352]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:03:43]
2023.04.12-06:28:11:368:[step-81800/113100: 72.33%]--[loss-1.148353: wl-2.973285, gl-0.405031]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:46:33]
2023.04.12-06:29:09:468:[step-81900/113100: 72.41%]--[loss-1.340564: wl-3.240068, gl-0.530547]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:06:48]
2023.04.12-06:30:07:568:[step-82000/113100: 72.50%]--[loss-1.327261: wl-3.021357, gl-0.571922]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:55:28]
2023.04.12-06:31:04:668:[step-82100/113100: 72.59%]--[loss-1.274997: wl-3.115987, gl-0.496000]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:55:12]
2023.04.12-06:32:01:768:[step-82200/113100: 72.68%]--[loss-1.340679: wl-3.238566, gl-0.531038]--[lr: pb-0.000030, pf-0.000017]--[ETA-5:10:49]
2023.04.12-06:32:59:868:[step-82300/113100: 72.77%]--[loss-1.313222: wl-3.132541, gl-0.530087]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:46:54]
2023.04.12-06:33:56:968:[step-82400/113100: 72.86%]--[loss-1.233196: wl-2.927476, gl-0.501327]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:52:45]
2023.04.12-06:34:52:1068:[step-82500/113100: 72.94%]--[loss-1.290024: wl-3.138982, gl-0.505278]--[lr: pb-0.000030, pf-0.000017]--[ETA-4:44:00]
End of epoch 73 / 100: train_loss: 1.329 	 time: 658 sec
Saving the model at the end of epoch 73, iters 82563
2023.04.12-06:36:03:37:[step-82600/113100: 73.03%]--[loss-1.181996: wl-2.910820, gl-0.454291]--[lr: pb-0.000030, pf-0.000016]--[ETA-5:02:18]
2023.04.12-06:37:00:137:[step-82700/113100: 73.12%]--[loss-1.344630: wl-3.183006, gl-0.548879]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:48:06]
2023.04.12-06:37:58:237:[step-82800/113100: 73.21%]--[loss-1.236676: wl-3.125267, gl-0.455359]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:47:55]
2023.04.12-06:38:56:337:[step-82900/113100: 73.30%]--[loss-1.428357: wl-3.412762, gl-0.575166]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:59:29]
2023.04.12-06:39:55:437:[step-83000/113100: 73.39%]--[loss-1.427378: wl-3.381319, gl-0.582048]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:48:37]
2023.04.12-06:40:51:537:[step-83100/113100: 73.47%]--[loss-1.407645: wl-3.310692, gl-0.579973]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:45:55]
2023.04.12-06:41:48:637:[step-83200/113100: 73.56%]--[loss-1.293776: wl-3.037817, gl-0.534321]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:37:07]
2023.04.12-06:42:46:737:[step-83300/113100: 73.65%]--[loss-1.241738: wl-3.212311, gl-0.438660]--[lr: pb-0.000030, pf-0.000016]--[ETA-5:20:55]
2023.04.12-06:43:42:837:[step-83400/113100: 73.74%]--[loss-1.340401: wl-3.268304, gl-0.523325]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:42:34]
2023.04.12-06:44:39:937:[step-83500/113100: 73.83%]--[loss-1.282376: wl-3.254934, gl-0.468643]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:34:41]
2023.04.12-06:45:35:1037:[step-83600/113100: 73.92%]--[loss-1.251431: wl-3.105814, gl-0.474978]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:35:29]
End of epoch 74 / 100: train_loss: 1.326 	 time: 660 sec
Saving the model at the end of epoch 74, iters 83694
2023.04.12-06:46:43:6:[step-83700/113100: 74.01%]--[loss-1.366973: wl-3.270480, gl-0.549353]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:45:30]
2023.04.12-06:47:40:106:[step-83800/113100: 74.09%]--[loss-1.278241: wl-2.819219, gl-0.573436]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:31:07]
2023.04.12-06:48:38:206:[step-83900/113100: 74.18%]--[loss-1.278474: wl-3.132598, gl-0.495324]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:33:27]
2023.04.12-06:49:37:306:[step-84000/113100: 74.27%]--[loss-1.307431: wl-3.253445, gl-0.494069]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:45:44]
2023.04.12-06:50:35:406:[step-84100/113100: 74.36%]--[loss-1.295220: wl-3.067308, gl-0.528393]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:36:52]
2023.04.12-06:51:32:506:[step-84200/113100: 74.45%]--[loss-1.296552: wl-3.222193, gl-0.491004]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:34:04]
2023.04.12-06:52:29:606:[step-84300/113100: 74.54%]--[loss-1.379890: wl-3.244030, gl-0.568882]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:30:38]
2023.04.12-06:53:25:706:[step-84400/113100: 74.62%]--[loss-1.177380: wl-2.926162, gl-0.445839]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:30:38]
2023.04.12-06:54:22:806:[step-84500/113100: 74.71%]--[loss-1.230775: wl-2.922545, gl-0.500139]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:31:02]
2023.04.12-06:55:18:906:[step-84600/113100: 74.80%]--[loss-1.377470: wl-3.135339, gl-0.593636]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:25:38]
2023.04.12-06:56:15:1006:[step-84700/113100: 74.89%]--[loss-1.332145: wl-3.317302, gl-0.502820]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:24:48]
2023.04.12-06:57:11:1106:[step-84800/113100: 74.98%]--[loss-1.284186: wl-3.044218, gl-0.523132]--[lr: pb-0.000030, pf-0.000016]--[ETA-4:07:08]
End of epoch 75 / 100: train_loss: 1.326 	 time: 655 sec
Saving the model at the end of epoch 75, iters 84825
2023.04.12-06:58:20:75:[step-84900/113100: 75.07%]--[loss-1.244150: wl-2.981163, gl-0.498859]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:19:53]
2023.04.12-06:59:17:175:[step-85000/113100: 75.15%]--[loss-1.178097: wl-2.929309, gl-0.445770]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:36:24]
2023.04.12-07:00:14:275:[step-85100/113100: 75.24%]--[loss-1.405301: wl-3.306937, gl-0.578567]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:37:29]
2023.04.12-07:01:10:375:[step-85200/113100: 75.33%]--[loss-1.417612: wl-3.017935, gl-0.663128]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:32:31]
2023.04.12-07:02:06:475:[step-85300/113100: 75.42%]--[loss-1.354413: wl-3.341074, gl-0.519145]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:14:03]
2023.04.12-07:03:04:575:[step-85400/113100: 75.51%]--[loss-1.270369: wl-3.203327, gl-0.469537]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:17:58]
2023.04.12-07:04:00:675:[step-85500/113100: 75.60%]--[loss-1.307539: wl-3.295651, gl-0.483626]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:16:24]
2023.04.12-07:04:56:775:[step-85600/113100: 75.69%]--[loss-1.312350: wl-3.090680, gl-0.539680]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:13:35]
2023.04.12-07:05:52:875:[step-85700/113100: 75.77%]--[loss-1.358271: wl-3.165348, gl-0.566934]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:18:05]
2023.04.12-07:06:50:975:[step-85800/113100: 75.86%]--[loss-1.380025: wl-3.159927, gl-0.590043]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:15:51]
2023.04.12-07:07:46:1075:[step-85900/113100: 75.95%]--[loss-1.191013: wl-2.888551, gl-0.468875]--[lr: pb-0.000030, pf-0.000015]--[ETA-4:34:14]
End of epoch 76 / 100: train_loss: 1.324 	 time: 652 sec
Saving the model at the end of epoch 76, iters 85956
2023.04.12-07:08:55:44:[step-86000/113100: 76.04%]--[loss-1.318713: wl-3.167864, gl-0.526747]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:37:36]
2023.04.12-07:09:53:144:[step-86100/113100: 76.13%]--[loss-1.363341: wl-3.170064, gl-0.570825]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:12:48]
2023.04.12-07:10:50:244:[step-86200/113100: 76.22%]--[loss-1.379318: wl-3.325153, gl-0.548030]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:12:18]
2023.04.12-07:11:47:344:[step-86300/113100: 76.30%]--[loss-1.214372: wl-3.002222, gl-0.463817]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:30:59]
2023.04.12-07:12:44:444:[step-86400/113100: 76.39%]--[loss-1.268045: wl-2.843748, gl-0.557108]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:09:14]
2023.04.12-07:13:40:544:[step-86500/113100: 76.48%]--[loss-1.282632: wl-3.089287, gl-0.510311]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:04:16]
2023.04.12-07:14:35:644:[step-86600/113100: 76.57%]--[loss-1.268018: wl-3.039343, gl-0.508183]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:58:54]
2023.04.12-07:15:31:744:[step-86700/113100: 76.66%]--[loss-1.194848: wl-2.924033, gl-0.463840]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:02:28]
2023.04.12-07:16:28:844:[step-86800/113100: 76.75%]--[loss-1.362886: wl-3.277602, gl-0.543486]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:56:50]
2023.04.12-07:17:24:944:[step-86900/113100: 76.83%]--[loss-1.220765: wl-3.142490, gl-0.435143]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:59:11]
2023.04.12-07:18:19:1044:[step-87000/113100: 76.92%]--[loss-1.151525: wl-2.866191, gl-0.434977]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:01:50]
End of epoch 77 / 100: train_loss: 1.324 	 time: 650 sec
Saving the model at the end of epoch 77, iters 87087
2023.04.12-07:19:26:13:[step-87100/113100: 77.01%]--[loss-1.318008: wl-2.995003, gl-0.569257]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:50:49]
2023.04.12-07:20:22:113:[step-87200/113100: 77.10%]--[loss-1.387951: wl-3.244789, gl-0.576754]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:15:53]
2023.04.12-07:21:19:213:[step-87300/113100: 77.19%]--[loss-1.292273: wl-3.180784, gl-0.497077]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:01:27]
2023.04.12-07:22:15:313:[step-87400/113100: 77.28%]--[loss-1.350055: wl-3.064937, gl-0.583821]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:15:36]
2023.04.12-07:23:13:413:[step-87500/113100: 77.37%]--[loss-1.309826: wl-3.046061, gl-0.548311]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:01:03]
2023.04.12-07:24:09:513:[step-87600/113100: 77.45%]--[loss-1.424720: wl-3.234802, gl-0.616020]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:00:06]
2023.04.12-07:25:05:613:[step-87700/113100: 77.54%]--[loss-1.283186: wl-3.123862, gl-0.502220]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:54:24]
2023.04.12-07:26:02:713:[step-87800/113100: 77.63%]--[loss-1.454734: wl-3.324534, gl-0.623600]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:55:49]
2023.04.12-07:26:58:813:[step-87900/113100: 77.72%]--[loss-1.348397: wl-3.041135, gl-0.588114]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:41:37]
2023.04.12-07:27:54:913:[step-88000/113100: 77.81%]--[loss-1.267087: wl-3.035978, gl-0.508093]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:58:07]
2023.04.12-07:28:49:1013:[step-88100/113100: 77.90%]--[loss-1.291436: wl-3.147623, gl-0.504531]--[lr: pb-0.000030, pf-0.000014]--[ETA-3:45:07]
2023.04.12-07:29:47:1113:[step-88200/113100: 77.98%]--[loss-1.281725: wl-2.941907, gl-0.546248]--[lr: pb-0.000030, pf-0.000014]--[ETA-4:00:44]
End of epoch 78 / 100: train_loss: 1.322 	 time: 649 sec
Saving the model at the end of epoch 78, iters 88218
2023.04.12-07:30:56:82:[step-88300/113100: 78.07%]--[loss-1.259249: wl-2.935555, gl-0.525360]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:49:19]
2023.04.12-07:31:52:182:[step-88400/113100: 78.16%]--[loss-1.403728: wl-3.525550, gl-0.522341]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:55:52]
2023.04.12-07:32:50:282:[step-88500/113100: 78.25%]--[loss-1.182874: wl-2.803158, gl-0.482085]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:39:57]
2023.04.12-07:33:47:382:[step-88600/113100: 78.34%]--[loss-1.176243: wl-3.055482, gl-0.412372]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:47:03]
2023.04.12-07:34:43:482:[step-88700/113100: 78.43%]--[loss-1.372427: wl-3.297532, gl-0.548044]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:45:54]
2023.04.12-07:35:40:582:[step-88800/113100: 78.51%]--[loss-1.400268: wl-3.271307, gl-0.582441]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:59:56]
2023.04.12-07:36:37:682:[step-88900/113100: 78.60%]--[loss-1.344586: wl-3.274851, gl-0.525873]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:43:49]
2023.04.12-07:37:32:782:[step-89000/113100: 78.69%]--[loss-1.284109: wl-3.197557, gl-0.484720]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:39:44]
2023.04.12-07:38:27:882:[step-89100/113100: 78.78%]--[loss-1.315168: wl-3.209856, gl-0.512704]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:40:34]
2023.04.12-07:39:24:982:[step-89200/113100: 78.87%]--[loss-1.321409: wl-2.998437, gl-0.571800]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:51:55]
2023.04.12-07:40:20:1082:[step-89300/113100: 78.96%]--[loss-1.420477: wl-3.288227, gl-0.598420]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:42:22]
End of epoch 79 / 100: train_loss: 1.321 	 time: 648 sec
Saving the model at the end of epoch 79, iters 89349
2023.04.12-07:41:28:51:[step-89400/113100: 79.05%]--[loss-1.307061: wl-3.143735, gl-0.521127]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:38:29]
2023.04.12-07:42:26:151:[step-89500/113100: 79.13%]--[loss-1.201940: wl-2.987932, gl-0.454957]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:43:24]
2023.04.12-07:43:23:251:[step-89600/113100: 79.22%]--[loss-1.483433: wl-3.591552, gl-0.585545]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:44:33]
2023.04.12-07:44:20:351:[step-89700/113100: 79.31%]--[loss-1.220111: wl-2.908420, gl-0.493006]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:24:27]
2023.04.12-07:45:15:451:[step-89800/113100: 79.40%]--[loss-1.346095: wl-3.127786, gl-0.564149]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:30:17]
2023.04.12-07:46:12:551:[step-89900/113100: 79.49%]--[loss-1.344592: wl-3.199966, gl-0.544600]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:51:30]
2023.04.12-07:47:08:651:[step-90000/113100: 79.58%]--[loss-1.267013: wl-3.076503, gl-0.497888]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:32:59]
2023.04.12-07:48:04:751:[step-90100/113100: 79.66%]--[loss-1.172541: wl-2.962970, gl-0.431798]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:30:54]
2023.04.12-07:49:01:851:[step-90200/113100: 79.75%]--[loss-1.296007: wl-3.136589, gl-0.511860]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:50:40]
2023.04.12-07:49:57:951:[step-90300/113100: 79.84%]--[loss-1.320300: wl-3.138819, gl-0.535595]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:32:11]
2023.04.12-07:50:52:1051:[step-90400/113100: 79.93%]--[loss-1.368027: wl-3.235794, gl-0.559078]--[lr: pb-0.000030, pf-0.000013]--[ETA-3:33:11]
End of epoch 80 / 100: train_loss: 1.320 	 time: 649 sec
Saving the model at the end of epoch 80, iters 90480
2023.04.12-07:51:58:20:[step-90500/113100: 80.02%]--[loss-1.340079: wl-3.282379, gl-0.519484]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:57:01]
2023.04.12-07:52:57:120:[step-90600/113100: 80.11%]--[loss-1.366416: wl-3.134721, gl-0.582736]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:33:32]
2023.04.12-07:53:54:220:[step-90700/113100: 80.19%]--[loss-1.354715: wl-3.066281, gl-0.588145]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:19:29]
2023.04.12-07:54:50:320:[step-90800/113100: 80.28%]--[loss-1.333794: wl-3.407710, gl-0.481866]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:23:35]
2023.04.12-07:55:47:420:[step-90900/113100: 80.37%]--[loss-1.290349: wl-3.103607, gl-0.514447]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:22:35]
2023.04.12-07:56:43:520:[step-91000/113100: 80.46%]--[loss-1.306861: wl-3.019700, gl-0.551936]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:17:41]
2023.04.12-07:57:39:620:[step-91100/113100: 80.55%]--[loss-1.363339: wl-3.233715, gl-0.554910]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:24:57]
2023.04.12-07:58:35:720:[step-91200/113100: 80.64%]--[loss-1.307276: wl-3.040436, gl-0.547167]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:15:23]
2023.04.12-07:59:32:820:[step-91300/113100: 80.73%]--[loss-1.306041: wl-3.140542, gl-0.520906]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:21:16]
2023.04.12-08:00:28:920:[step-91400/113100: 80.81%]--[loss-1.314120: wl-3.184072, gl-0.518102]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:22:32]
2023.04.12-08:01:23:1020:[step-91500/113100: 80.90%]--[loss-1.296937: wl-3.014858, gl-0.543223]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:17:00]
2023.04.12-08:02:18:1120:[step-91600/113100: 80.99%]--[loss-1.313182: wl-3.108381, gl-0.536086]--[lr: pb-0.000030, pf-0.000012]--[ETA-3:22:55]
End of epoch 81 / 100: train_loss: 1.319 	 time: 647 sec
Saving the model at the end of epoch 81, iters 91611
2023.04.12-08:03:27:89:[step-91700/113100: 81.08%]--[loss-1.296456: wl-2.924105, gl-0.565430]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:21:29]
2023.04.12-08:04:23:189:[step-91800/113100: 81.17%]--[loss-1.442864: wl-3.495360, gl-0.569024]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:14:13]
2023.04.12-08:05:20:289:[step-91900/113100: 81.26%]--[loss-1.386920: wl-3.264602, gl-0.570769]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:47:27]
2023.04.12-08:06:17:389:[step-92000/113100: 81.34%]--[loss-1.260731: wl-3.076561, gl-0.491591]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:10:31]
2023.04.12-08:07:13:489:[step-92100/113100: 81.43%]--[loss-1.242018: wl-2.966932, gl-0.500285]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:04:07]
2023.04.12-08:08:09:589:[step-92200/113100: 81.52%]--[loss-1.293810: wl-3.202251, gl-0.493247]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:11:32]
2023.04.12-08:09:06:689:[step-92300/113100: 81.61%]--[loss-1.386484: wl-3.290266, gl-0.563918]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:12:51]
2023.04.12-08:10:02:789:[step-92400/113100: 81.70%]--[loss-1.410565: wl-3.274821, gl-0.591860]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:02:10]
2023.04.12-08:10:58:889:[step-92500/113100: 81.79%]--[loss-1.561817: wl-3.404515, gl-0.710689]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:10:29]
2023.04.12-08:11:53:989:[step-92600/113100: 81.87%]--[loss-1.266615: wl-3.053799, gl-0.503165]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:08:55]
2023.04.12-08:12:50:1089:[step-92700/113100: 81.96%]--[loss-1.320373: wl-3.170279, gl-0.527803]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:07:40]
End of epoch 82 / 100: train_loss: 1.317 	 time: 648 sec
Saving the model at the end of epoch 82, iters 92742
2023.04.12-08:13:56:58:[step-92800/113100: 82.05%]--[loss-1.264381: wl-3.063251, gl-0.498568]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:20:20]
2023.04.12-08:14:52:158:[step-92900/113100: 82.14%]--[loss-1.534103: wl-3.414216, gl-0.680549]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:16:57]
2023.04.12-08:15:51:258:[step-93000/113100: 82.23%]--[loss-1.392255: wl-3.187799, gl-0.595306]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:31:00]
2023.04.12-08:16:48:358:[step-93100/113100: 82.32%]--[loss-1.369298: wl-3.107416, gl-0.592444]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:06:48]
2023.04.12-08:17:44:458:[step-93200/113100: 82.40%]--[loss-1.309364: wl-3.244168, gl-0.498322]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:02:37]
2023.04.12-08:18:41:558:[step-93300/113100: 82.49%]--[loss-1.251918: wl-3.064545, gl-0.485782]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:02:45]
2023.04.12-08:19:38:658:[step-93400/113100: 82.58%]--[loss-1.222866: wl-2.978688, gl-0.478194]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:10:27]
2023.04.12-08:20:34:758:[step-93500/113100: 82.67%]--[loss-1.172858: wl-2.734509, gl-0.489230]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:01:09]
2023.04.12-08:21:29:858:[step-93600/113100: 82.76%]--[loss-1.170349: wl-2.810530, gl-0.467716]--[lr: pb-0.000030, pf-0.000011]--[ETA-3:06:24]
2023.04.12-08:22:26:958:[step-93700/113100: 82.85%]--[loss-1.326200: wl-3.315499, gl-0.497325]--[lr: pb-0.000030, pf-0.000011]--[ETA-2:54:34]
2023.04.12-08:23:22:1058:[step-93800/113100: 82.94%]--[loss-1.463923: wl-3.229892, gl-0.656450]--[lr: pb-0.000030, pf-0.000011]--[ETA-2:59:15]
End of epoch 83 / 100: train_loss: 1.316 	 time: 649 sec
Saving the model at the end of epoch 83, iters 93873
2023.04.12-08:24:28:27:[step-93900/113100: 83.02%]--[loss-1.327875: wl-3.180487, gl-0.532753]--[lr: pb-0.000030, pf-0.000010]--[ETA-3:01:12]
2023.04.12-08:25:25:127:[step-94000/113100: 83.11%]--[loss-1.388278: wl-3.285805, gl-0.566826]--[lr: pb-0.000030, pf-0.000010]--[ETA-3:01:14]
2023.04.12-08:26:23:227:[step-94100/113100: 83.20%]--[loss-1.247558: wl-3.108989, gl-0.470311]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:58:15]
2023.04.12-08:27:19:327:[step-94200/113100: 83.29%]--[loss-1.412214: wl-3.656331, gl-0.498131]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:55:34]
2023.04.12-08:28:15:427:[step-94300/113100: 83.38%]--[loss-1.373707: wl-3.148083, gl-0.586686]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:56:45]
2023.04.12-08:29:12:527:[step-94400/113100: 83.47%]--[loss-1.362286: wl-3.080889, gl-0.592063]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:53:59]
2023.04.12-08:30:08:627:[step-94500/113100: 83.55%]--[loss-1.339647: wl-3.161519, gl-0.549268]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:45:07]
2023.04.12-08:31:04:727:[step-94600/113100: 83.64%]--[loss-1.282943: wl-3.113076, gl-0.504674]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:49:01]
2023.04.12-08:31:59:827:[step-94700/113100: 83.73%]--[loss-1.329226: wl-3.054817, gl-0.565522]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:48:58]
2023.04.12-08:32:56:927:[step-94800/113100: 83.82%]--[loss-1.262309: wl-3.043783, gl-0.501363]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:54:29]
2023.04.12-08:33:52:1027:[step-94900/113100: 83.91%]--[loss-1.263580: wl-3.176809, gl-0.469378]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:47:54]
2023.04.12-08:34:48:1127:[step-95000/113100: 84.00%]--[loss-1.175012: wl-2.795172, gl-0.476219]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:46:02]
End of epoch 84 / 100: train_loss: 1.315 	 time: 647 sec
Saving the model at the end of epoch 84, iters 95004
2023.04.12-08:35:57:96:[step-95100/113100: 84.08%]--[loss-1.336436: wl-3.151178, gl-0.548641]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:53:30]
2023.04.12-08:36:54:196:[step-95200/113100: 84.17%]--[loss-1.291763: wl-3.349059, gl-0.454498]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:48:02]
2023.04.12-08:37:51:296:[step-95300/113100: 84.26%]--[loss-1.329702: wl-3.191080, gl-0.531933]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:56:29]
2023.04.12-08:38:47:396:[step-95400/113100: 84.35%]--[loss-1.231446: wl-3.032316, gl-0.473367]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:48:32]
2023.04.12-08:39:44:496:[step-95500/113100: 84.44%]--[loss-1.395113: wl-3.153770, gl-0.606671]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:53:06]
2023.04.12-08:40:40:596:[step-95600/113100: 84.53%]--[loss-1.263170: wl-2.989795, gl-0.515721]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:43:02]
2023.04.12-08:41:36:696:[step-95700/113100: 84.62%]--[loss-1.401888: wl-3.277703, gl-0.582463]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:46:10]
2023.04.12-08:42:32:796:[step-95800/113100: 84.70%]--[loss-1.275081: wl-3.060506, gl-0.509954]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:41:25]
2023.04.12-08:43:28:896:[step-95900/113100: 84.79%]--[loss-1.326326: wl-3.166910, gl-0.534598]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:39:05]
2023.04.12-08:44:24:996:[step-96000/113100: 84.88%]--[loss-1.480484: wl-3.632063, gl-0.572469]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:47:33]
2023.04.12-08:45:20:1096:[step-96100/113100: 84.97%]--[loss-1.279810: wl-3.151411, gl-0.491957]--[lr: pb-0.000030, pf-0.000010]--[ETA-2:37:01]
End of epoch 85 / 100: train_loss: 1.314 	 time: 648 sec
Saving the model at the end of epoch 85, iters 96135
2023.04.12-08:46:28:65:[step-96200/113100: 85.06%]--[loss-1.285300: wl-3.091891, gl-0.512328]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:49:34]
2023.04.12-08:47:25:165:[step-96300/113100: 85.15%]--[loss-1.255011: wl-3.117738, gl-0.475577]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:41:09]
2023.04.12-08:48:22:265:[step-96400/113100: 85.23%]--[loss-1.313333: wl-3.154837, gl-0.524624]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:42:11]
2023.04.12-08:49:18:365:[step-96500/113100: 85.32%]--[loss-1.280185: wl-3.134482, gl-0.496565]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:36:51]
2023.04.12-08:50:15:465:[step-96600/113100: 85.41%]--[loss-1.359416: wl-3.101137, gl-0.584132]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:44:31]
2023.04.12-08:51:11:565:[step-96700/113100: 85.50%]--[loss-1.253810: wl-3.114747, gl-0.475123]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:28:01]
2023.04.12-08:52:07:665:[step-96800/113100: 85.59%]--[loss-1.201494: wl-2.940787, gl-0.466297]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:32:30]
2023.04.12-08:53:03:765:[step-96900/113100: 85.68%]--[loss-1.371498: wl-3.204069, gl-0.570480]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:31:08]
2023.04.12-08:53:59:865:[step-97000/113100: 85.76%]--[loss-1.356788: wl-3.171315, gl-0.563959]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:28:05]
2023.04.12-08:54:55:965:[step-97100/113100: 85.85%]--[loss-1.290773: wl-3.223707, gl-0.484847]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:32:41]
2023.04.12-08:55:52:1065:[step-97200/113100: 85.94%]--[loss-1.321437: wl-3.200698, gl-0.521262]--[lr: pb-0.000030, pf-0.000009]--[ETA-2:26:25]
End of epoch 86 / 100: train_loss: 1.315 	 time: 649 sec
Saving the model at the end of epoch 86, iters 97266
2023.04.12-08:56:58:34:[step-97300/113100: 86.03%]--[loss-1.474575: wl-3.559978, gl-0.584580]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:26:24]
2023.04.12-08:57:55:134:[step-97400/113100: 86.12%]--[loss-1.277010: wl-2.938801, gl-0.542310]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:28:02]
2023.04.12-08:58:53:234:[step-97500/113100: 86.21%]--[loss-1.408996: wl-3.260958, gl-0.593756]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:22:48]
2023.04.12-08:59:51:334:[step-97600/113100: 86.30%]--[loss-1.241997: wl-3.122509, gl-0.461370]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:25:35]
2023.04.12-09:00:48:434:[step-97700/113100: 86.38%]--[loss-1.277980: wl-3.067554, gl-0.511091]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:25:22]
2023.04.12-09:01:44:534:[step-97800/113100: 86.47%]--[loss-1.335951: wl-3.292681, gl-0.512780]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:31:00]
2023.04.12-09:02:40:634:[step-97900/113100: 86.56%]--[loss-1.474938: wl-3.304642, gl-0.648778]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:16:57]
2023.04.12-09:03:36:734:[step-98000/113100: 86.65%]--[loss-1.243307: wl-2.937433, gl-0.508949]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:22:52]
2023.04.12-09:04:32:834:[step-98100/113100: 86.74%]--[loss-1.322403: wl-3.308754, gl-0.495215]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:18:18]
2023.04.12-09:05:28:934:[step-98200/113100: 86.83%]--[loss-1.310783: wl-3.296066, gl-0.486766]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:21:41]
2023.04.12-09:06:24:1034:[step-98300/113100: 86.91%]--[loss-1.234795: wl-2.965161, gl-0.493505]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:15:23]
End of epoch 87 / 100: train_loss: 1.313 	 time: 648 sec
Saving the model at the end of epoch 87, iters 98397
2023.04.12-09:07:30:3:[step-98400/113100: 87.00%]--[loss-1.221311: wl-2.940679, gl-0.486142]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:32:07]
2023.04.12-09:08:26:103:[step-98500/113100: 87.09%]--[loss-1.336356: wl-3.045355, gl-0.575017]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:24:30]
2023.04.12-09:09:25:203:[step-98600/113100: 87.18%]--[loss-1.411954: wl-3.115885, gl-0.632983]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:15:15]
2023.04.12-09:10:22:303:[step-98700/113100: 87.27%]--[loss-1.334248: wl-3.168524, gl-0.542117]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:18:08]
2023.04.12-09:11:19:403:[step-98800/113100: 87.36%]--[loss-1.446461: wl-3.261945, gl-0.630975]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:14:06]
2023.04.12-09:12:15:503:[step-98900/113100: 87.44%]--[loss-1.368855: wl-3.188704, gl-0.571679]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:08:46]
2023.04.12-09:13:11:603:[step-99000/113100: 87.53%]--[loss-1.374578: wl-3.091836, gl-0.601619]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:10:26]
2023.04.12-09:14:07:703:[step-99100/113100: 87.62%]--[loss-1.413396: wl-3.254190, gl-0.599848]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:05:59]
2023.04.12-09:15:04:803:[step-99200/113100: 87.71%]--[loss-1.352985: wl-3.250254, gl-0.540422]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:10:22]
2023.04.12-09:16:00:903:[step-99300/113100: 87.80%]--[loss-1.356096: wl-3.271837, gl-0.538136]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:07:46]
2023.04.12-09:16:56:1003:[step-99400/113100: 87.89%]--[loss-1.272424: wl-3.068032, gl-0.505416]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:13:59]
2023.04.12-09:17:52:1103:[step-99500/113100: 87.98%]--[loss-1.336771: wl-3.104190, gl-0.560724]--[lr: pb-0.000030, pf-0.000008]--[ETA-2:00:30]
End of epoch 88 / 100: train_loss: 1.312 	 time: 649 sec
Saving the model at the end of epoch 88, iters 99528
2023.04.12-09:19:01:72:[step-99600/113100: 88.06%]--[loss-1.392981: wl-3.177465, gl-0.598615]--[lr: pb-0.000030, pf-0.000007]--[ETA-2:16:46]
2023.04.12-09:19:58:172:[step-99700/113100: 88.15%]--[loss-1.350125: wl-3.144020, gl-0.564120]--[lr: pb-0.000030, pf-0.000007]--[ETA-2:04:46]
2023.04.12-09:20:55:272:[step-99800/113100: 88.24%]--[loss-1.323866: wl-3.212415, gl-0.520762]--[lr: pb-0.000030, pf-0.000007]--[ETA-2:03:32]
2023.04.12-09:21:51:372:[step-99900/113100: 88.33%]--[loss-1.219846: wl-2.946376, gl-0.483252]--[lr: pb-0.000030, pf-0.000007]--[ETA-2:01:51]
2023.04.12-09:22:47:472:[step-100000/113100: 88.42%]--[loss-1.294724: wl-3.088510, gl-0.522597]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:58:14]
2023.04.12-09:23:44:572:[step-100100/113100: 88.51%]--[loss-1.376155: wl-3.329035, gl-0.543896]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:56:48]
2023.04.12-09:24:40:672:[step-100200/113100: 88.59%]--[loss-1.426075: wl-3.209980, gl-0.623580]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:58:34]
2023.04.12-09:25:36:772:[step-100300/113100: 88.68%]--[loss-1.330393: wl-3.332684, gl-0.497222]--[lr: pb-0.000030, pf-0.000007]--[ETA-2:00:01]
2023.04.12-09:26:32:872:[step-100400/113100: 88.77%]--[loss-1.259005: wl-3.225192, gl-0.452707]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:57:38]
2023.04.12-09:27:28:972:[step-100500/113100: 88.86%]--[loss-1.270598: wl-2.931164, gl-0.537807]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:52:44]
2023.04.12-09:28:24:1072:[step-100600/113100: 88.95%]--[loss-1.416956: wl-3.216137, gl-0.612922]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:51:23]
End of epoch 89 / 100: train_loss: 1.311 	 time: 648 sec
Saving the model at the end of epoch 89, iters 100659
2023.04.12-09:29:30:41:[step-100700/113100: 89.04%]--[loss-1.347407: wl-3.133008, gl-0.564155]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:55:44]
2023.04.12-09:30:27:141:[step-100800/113100: 89.12%]--[loss-1.346894: wl-3.144446, gl-0.560782]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:57:34]
2023.04.12-09:31:24:241:[step-100900/113100: 89.21%]--[loss-1.087501: wl-2.794017, gl-0.388997]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:56:29]
2023.04.12-09:32:21:341:[step-101000/113100: 89.30%]--[loss-1.336893: wl-3.108481, gl-0.559773]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:54:58]
2023.04.12-09:33:17:441:[step-101100/113100: 89.39%]--[loss-1.198297: wl-2.890508, gl-0.475670]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:48:05]
2023.04.12-09:34:14:541:[step-101200/113100: 89.48%]--[loss-1.443195: wl-3.643788, gl-0.532248]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:47:50]
2023.04.12-09:35:10:641:[step-101300/113100: 89.57%]--[loss-1.395103: wl-3.369924, gl-0.552622]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:50:45]
2023.04.12-09:36:06:741:[step-101400/113100: 89.66%]--[loss-1.327224: wl-3.268755, gl-0.510035]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:50:46]
2023.04.12-09:37:02:841:[step-101500/113100: 89.74%]--[loss-1.211611: wl-3.119816, gl-0.431657]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:48:53]
2023.04.12-09:37:58:941:[step-101600/113100: 89.83%]--[loss-1.328814: wl-3.117321, gl-0.549484]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:44:21]
2023.04.12-09:38:54:1041:[step-101700/113100: 89.92%]--[loss-1.299320: wl-3.240479, gl-0.489200]--[lr: pb-0.000030, pf-0.000007]--[ETA-1:52:10]
End of epoch 90 / 100: train_loss: 1.310 	 time: 647 sec
Saving the model at the end of epoch 90, iters 101790
2023.04.12-09:40:01:10:[step-101800/113100: 90.01%]--[loss-1.288785: wl-3.077631, gl-0.519377]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:46:00]
2023.04.12-09:40:57:110:[step-101900/113100: 90.10%]--[loss-1.192824: wl-2.981713, gl-0.447396]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:40:57]
2023.04.12-09:41:54:210:[step-102000/113100: 90.19%]--[loss-1.332035: wl-3.415935, gl-0.478052]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:46:07]
2023.04.12-09:42:53:310:[step-102100/113100: 90.27%]--[loss-1.343569: wl-3.372467, gl-0.500452]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:43:03]
2023.04.12-09:43:51:410:[step-102200/113100: 90.36%]--[loss-1.225628: wl-2.849346, gl-0.513291]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:42:38]
2023.04.12-09:44:49:510:[step-102300/113100: 90.45%]--[loss-1.219356: wl-2.939814, gl-0.484402]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:40:15]
2023.04.12-09:45:48:610:[step-102400/113100: 90.54%]--[loss-1.320503: wl-3.196245, gl-0.521442]--[lr: pb-0.000030, pf-0.000006]--[ETA-2:42:52]
2023.04.12-09:46:48:710:[step-102500/113100: 90.63%]--[loss-1.290112: wl-3.208032, gl-0.488104]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:45:41]
2023.04.12-09:47:47:810:[step-102600/113100: 90.72%]--[loss-1.343120: wl-3.137173, gl-0.558827]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:39:34]
2023.04.12-09:48:46:910:[step-102700/113100: 90.80%]--[loss-1.221530: wl-2.979960, gl-0.476540]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:37:21]
2023.04.12-09:49:45:1010:[step-102800/113100: 90.89%]--[loss-1.275681: wl-3.015828, gl-0.521724]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:39:22]
2023.04.12-09:50:43:1110:[step-102900/113100: 90.98%]--[loss-1.353768: wl-3.158470, gl-0.564150]--[lr: pb-0.000030, pf-0.000006]--[ETA-1:35:32]
End of epoch 91 / 100: train_loss: 1.309 	 time: 670 sec
Saving the model at the end of epoch 91, iters 102921
2023.04.12-09:51:55:79:[step-103000/113100: 91.07%]--[loss-1.343426: wl-3.243645, gl-0.532515]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:38:10]
2023.04.12-09:52:56:179:[step-103100/113100: 91.16%]--[loss-1.078919: wl-2.755721, gl-0.389989]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:38:10]
2023.04.12-09:53:56:279:[step-103200/113100: 91.25%]--[loss-1.224727: wl-2.885746, gl-0.503290]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:41:19]
2023.04.12-09:54:56:379:[step-103300/113100: 91.34%]--[loss-1.359324: wl-3.293278, gl-0.536004]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:56:34]
2023.04.12-09:55:56:479:[step-103400/113100: 91.42%]--[loss-1.246753: wl-3.158215, gl-0.457200]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:35:24]
2023.04.12-09:56:56:579:[step-103500/113100: 91.51%]--[loss-1.329385: wl-3.236262, gl-0.520320]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:29:57]
2023.04.12-09:57:55:679:[step-103600/113100: 91.60%]--[loss-1.275382: wl-2.955174, gl-0.536588]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:26:58]
2023.04.12-09:58:54:779:[step-103700/113100: 91.69%]--[loss-1.421977: wl-3.473225, gl-0.553671]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:29:28]
2023.04.12-09:59:54:879:[step-103800/113100: 91.78%]--[loss-1.504579: wl-3.625840, gl-0.598119]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:28:00]
2023.04.12-10:00:53:979:[step-103900/113100: 91.87%]--[loss-1.139993: wl-2.922432, gl-0.409385]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:24:53]
2023.04.12-10:01:53:1079:[step-104000/113100: 91.95%]--[loss-1.339635: wl-3.135900, gl-0.555660]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:34:15]
End of epoch 92 / 100: train_loss: 1.308 	 time: 687 sec
Saving the model at the end of epoch 92, iters 104052
2023.04.12-10:03:04:48:[step-104100/113100: 92.04%]--[loss-1.197029: wl-2.968959, gl-0.454789]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:30:09]
2023.04.12-10:04:04:148:[step-104200/113100: 92.13%]--[loss-1.412540: wl-3.400338, gl-0.562456]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:29:50]
2023.04.12-10:05:05:248:[step-104300/113100: 92.22%]--[loss-1.420934: wl-3.405232, gl-0.569626]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:28:19]
2023.04.12-10:06:05:348:[step-104400/113100: 92.31%]--[loss-1.204559: wl-2.995260, gl-0.455744]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:23:11]
2023.04.12-10:07:05:448:[step-104500/113100: 92.40%]--[loss-1.351335: wl-3.397838, gl-0.501876]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:17:59]
2023.04.12-10:08:03:548:[step-104600/113100: 92.48%]--[loss-1.307384: wl-3.224405, gl-0.501283]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:19:47]
2023.04.12-10:09:03:648:[step-104700/113100: 92.57%]--[loss-1.447138: wl-3.431051, gl-0.589375]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:18:55]
2023.04.12-10:10:02:748:[step-104800/113100: 92.66%]--[loss-1.507694: wl-3.461564, gl-0.642303]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:32:32]
2023.04.12-10:11:02:848:[step-104900/113100: 92.75%]--[loss-1.286442: wl-3.170592, gl-0.493794]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:21:50]
2023.04.12-10:12:01:948:[step-105000/113100: 92.84%]--[loss-1.259882: wl-2.914222, gl-0.531327]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:20:41]
2023.04.12-10:12:59:1048:[step-105100/113100: 92.93%]--[loss-1.224006: wl-3.075697, gl-0.455081]--[lr: pb-0.000030, pf-0.000005]--[ETA-1:19:04]
End of epoch 93 / 100: train_loss: 1.307 	 time: 684 sec
Saving the model at the end of epoch 93, iters 105183
2023.04.12-10:14:10:17:[step-105200/113100: 93.02%]--[loss-1.202774: wl-2.907866, gl-0.475808]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:16:02]
2023.04.12-10:15:10:117:[step-105300/113100: 93.10%]--[loss-1.336473: wl-3.082182, gl-0.565928]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:23:19]
2023.04.12-10:16:10:217:[step-105400/113100: 93.19%]--[loss-1.232375: wl-3.132540, gl-0.449240]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:16:51]
2023.04.12-10:17:10:317:[step-105500/113100: 93.28%]--[loss-1.346846: wl-3.212283, gl-0.543775]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:14:35]
2023.04.12-10:18:10:417:[step-105600/113100: 93.37%]--[loss-1.236316: wl-3.071759, gl-0.468376]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:15:15]
2023.04.12-10:19:09:517:[step-105700/113100: 93.46%]--[loss-1.204566: wl-2.735462, gl-0.520700]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:22:58]
2023.04.12-10:20:09:617:[step-105800/113100: 93.55%]--[loss-1.174608: wl-2.918190, gl-0.445060]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:21:21]
2023.04.12-10:21:08:717:[step-105900/113100: 93.63%]--[loss-1.424978: wl-3.471341, gl-0.557143]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:07:34]
2023.04.12-10:22:07:817:[step-106000/113100: 93.72%]--[loss-1.361937: wl-3.257646, gl-0.547525]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:06:46]
2023.04.12-10:23:06:917:[step-106100/113100: 93.81%]--[loss-1.313548: wl-3.118682, gl-0.533877]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:07:57]
2023.04.12-10:24:05:1017:[step-106200/113100: 93.90%]--[loss-1.460601: wl-3.232925, gl-0.652369]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:03:39]
2023.04.12-10:25:04:1117:[step-106300/113100: 93.99%]--[loss-1.272674: wl-3.175925, gl-0.478693]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:03:57]
End of epoch 94 / 100: train_loss: 1.306 	 time: 684 sec
Saving the model at the end of epoch 94, iters 106314
2023.04.12-10:26:16:86:[step-106400/113100: 94.08%]--[loss-1.323711: wl-3.268636, gl-0.506552]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:04:52]
2023.04.12-10:27:16:186:[step-106500/113100: 94.16%]--[loss-1.306901: wl-3.198851, gl-0.507188]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:03:56]
2023.04.12-10:28:17:286:[step-106600/113100: 94.25%]--[loss-1.249297: wl-3.047220, gl-0.487492]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:07:19]
2023.04.12-10:29:19:386:[step-106700/113100: 94.34%]--[loss-1.187956: wl-2.920455, gl-0.457843]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:05:23]
2023.04.12-10:30:20:486:[step-106800/113100: 94.43%]--[loss-1.140367: wl-2.874255, gl-0.421803]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:01:50]
2023.04.12-10:31:20:586:[step-106900/113100: 94.52%]--[loss-1.364286: wl-3.196733, gl-0.565103]--[lr: pb-0.000030, pf-0.000004]--[ETA-0:58:37]
2023.04.12-10:32:20:686:[step-107000/113100: 94.61%]--[loss-1.310060: wl-3.021328, gl-0.554728]--[lr: pb-0.000030, pf-0.000004]--[ETA-0:57:48]
2023.04.12-10:33:20:786:[step-107100/113100: 94.69%]--[loss-1.301888: wl-3.120245, gl-0.521827]--[lr: pb-0.000030, pf-0.000004]--[ETA-1:01:06]
2023.04.12-10:34:42:886:[step-107200/113100: 94.78%]--[loss-1.152371: wl-2.858135, gl-0.437837]--[lr: pb-0.000030, pf-0.000004]--[ETA-2:10:41]
2023.04.12-10:35:42:986:[step-107300/113100: 94.87%]--[loss-1.392947: wl-3.266331, gl-0.576365]--[lr: pb-0.000030, pf-0.000004]--[ETA-0:57:20]
2023.04.12-10:36:41:1086:[step-107400/113100: 94.96%]--[loss-1.283632: wl-3.129068, gl-0.501365]--[lr: pb-0.000030, pf-0.000004]--[ETA-0:58:37]
End of epoch 95 / 100: train_loss: 1.307 	 time: 725 sec
Saving the model at the end of epoch 95, iters 107445
2023.04.12-10:38:12:55:[step-107500/113100: 95.05%]--[loss-1.237265: wl-3.122658, gl-0.456600]--[lr: pb-0.000030, pf-0.000003]--[ETA-1:05:14]
2023.04.12-10:39:13:155:[step-107600/113100: 95.14%]--[loss-1.239939: wl-2.906035, gl-0.513430]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:55:57]
2023.04.12-10:40:14:255:[step-107700/113100: 95.23%]--[loss-1.395410: wl-3.178100, gl-0.600885]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:53:23]
2023.04.12-10:41:15:355:[step-107800/113100: 95.31%]--[loss-1.393045: wl-3.330520, gl-0.560415]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:54:12]
2023.04.12-10:42:16:455:[step-107900/113100: 95.40%]--[loss-1.212553: wl-2.934461, gl-0.478938]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:50:57]
2023.04.12-10:43:15:555:[step-108000/113100: 95.49%]--[loss-1.364577: wl-3.415812, gl-0.510624]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:51:57]
2023.04.12-10:44:17:655:[step-108100/113100: 95.58%]--[loss-1.401568: wl-3.290400, gl-0.578968]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:47:44]
2023.04.12-10:45:39:755:[step-108200/113100: 95.67%]--[loss-1.291525: wl-3.093456, gl-0.518161]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:46:20]
2023.04.12-10:46:38:855:[step-108300/113100: 95.76%]--[loss-1.373229: wl-3.445911, gl-0.511751]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:45:53]
2023.04.12-10:47:41:955:[step-108400/113100: 95.84%]--[loss-1.233232: wl-3.052451, gl-0.470120]--[lr: pb-0.000030, pf-0.000003]--[ETA-1:00:12]
2023.04.12-10:48:59:1055:[step-108500/113100: 95.93%]--[loss-1.315042: wl-3.035840, gl-0.556082]--[lr: pb-0.000030, pf-0.000003]--[ETA-0:43:37]
End of epoch 96 / 100: train_loss: 1.305 	 time: 745 sec
Saving the model at the end of epoch 96, iters 108576
2023.04.12-10:50:11:24:[step-108600/113100: 96.02%]--[loss-1.334054: wl-3.238486, gl-0.524432]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:55:23]
2023.04.12-10:51:12:124:[step-108700/113100: 96.11%]--[loss-1.356452: wl-3.287780, gl-0.534507]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:47:57]
2023.04.12-10:52:13:224:[step-108800/113100: 96.20%]--[loss-1.415910: wl-3.601090, gl-0.515638]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:43:00]
2023.04.12-10:53:15:324:[step-108900/113100: 96.29%]--[loss-1.271714: wl-3.131651, gl-0.488801]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:55:32]
2023.04.12-10:54:16:424:[step-109000/113100: 96.37%]--[loss-1.361845: wl-3.300087, gl-0.536823]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:41:02]
2023.04.12-10:55:28:524:[step-109100/113100: 96.46%]--[loss-1.342210: wl-3.201632, gl-0.541802]--[lr: pb-0.000030, pf-0.000002]--[ETA-1:22:09]
2023.04.12-10:56:40:624:[step-109200/113100: 96.55%]--[loss-1.279332: wl-2.974900, gl-0.535607]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:37:06]
2023.04.12-10:57:39:724:[step-109300/113100: 96.64%]--[loss-1.386441: wl-3.450037, gl-0.523932]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:36:51]
2023.04.12-10:59:01:824:[step-109400/113100: 96.73%]--[loss-1.535538: wl-3.437611, gl-0.676136]--[lr: pb-0.000030, pf-0.000002]--[ETA-1:17:26]
2023.04.12-11:00:00:924:[step-109500/113100: 96.82%]--[loss-1.297689: wl-3.146349, gl-0.511102]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:34:22]
2023.04.12-11:01:00:1024:[step-109600/113100: 96.91%]--[loss-1.226914: wl-2.952409, gl-0.488812]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:33:45]
2023.04.12-11:01:59:1124:[step-109700/113100: 96.99%]--[loss-1.287123: wl-2.948290, gl-0.550051]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:31:12]
End of epoch 97 / 100: train_loss: 1.302 	 time: 738 sec
Saving the model at the end of epoch 97, iters 109707
2023.04.12-11:03:12:93:[step-109800/113100: 97.08%]--[loss-1.249734: wl-2.942000, gl-0.514234]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:31:14]
2023.04.12-11:04:13:193:[step-109900/113100: 97.17%]--[loss-1.312011: wl-3.310161, gl-0.484470]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:30:50]
2023.04.12-11:05:14:293:[step-110000/113100: 97.26%]--[loss-1.168266: wl-2.861865, gl-0.452800]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:30:42]
2023.04.12-11:06:36:393:[step-110100/113100: 97.35%]--[loss-1.264630: wl-3.020626, gl-0.509473]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:30:25]
2023.04.12-11:07:36:493:[step-110200/113100: 97.44%]--[loss-1.325931: wl-3.074251, gl-0.557369]--[lr: pb-0.000030, pf-0.000002]--[ETA-0:32:30]
